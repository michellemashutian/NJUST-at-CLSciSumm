 It is faster because the search problem for noisy- channel models is NP-complete (Knight, 1999), and even the fastest dynamic-programming heuristics used in statistical MT (Niessen et al., 1998; Till- mann and Ney, 2000), are polynomial in J —for in p(v1, w2, wm−1, um h, s) = stance O(mJ 4V 3) in (Tillmann and Ney, 2000). 
 Various clues have been considered when computing the similarities
 The other is multilingual parallel and comparable corpora (e.g., Wikipedia1), wherein features such as co- occurrence frequency and context are popularly employed (Cheng et al., 2004; Shao and Ng, 2004; Cao et al., 2007; Lin et al., 2008). 
 Shao and Ng (2004) presented a method to mine new translations from Chinese and English news documents of the same period from different news agencies, combining both transliteration and context information. 
 Much of the work involving comparable corpora has focused on extracting word translations (Fung and Yee, 1998; Rapp, 1999; Diab and Finch, 2000; Koehn and Knight, 2000; Gaussier et al., 2004; Shao and Ng, 2004; Shinyama and Sekine, 2004). 
 Recently, holistic approaches combining such similarities have been studied (Shao and Ng, 2004; You et al., 2010; Kim et al., 2011). 
 Some recent research used comparable corpora to re-score name transliterations (Sproat et al., 2006; Klementiev and Roth, 2006) or mine new word translations (Fung and Yee, 1998; Rapp, 1999; Shao and Ng, 2004; Tao and Zhai, 2005; Hassan et al., 2007; Udupa et al., 2009; Ji, 2009). 
 We lemmatized German articles, adjectives (only positive form), for some pronouns and for nouns in order to remove the lexical redundancy (e.g., Bildes as Bild) by using the fine- grained part-of-speech tags generated by RFTagger (Schmid and Laws, 2008). 
 As for work on Arabic (MSA), results have been reported on the PATB (Kulick, Gabbard, and Marcus 2006; Diab 2007; Green and Manning 2010) 
 We previously showed optimal Berkeley parser (Petrov et al. 2006) pa- rameterizations for both the Arabic (Green and Manning 2010) and French (Green et al. 2011) data sets 
 Recently, Green and Manning (2010) analyzed the PATB for annotation consistency 
 We allow the parser to produce empty elements by means of lattice-parsing (Chappelier et al., 1999), a general processing community (Hall, 2005; Chappelier et al., 1999), and was recently applied to the task of joint clitic-segmentation and syntactic-parsing in Hebrew (Goldberg and Tsarfaty, 2008; Goldberg and Elhadad, 2011) and Arabic (Green and Manning, 2010). 
 The data was pre-processed with packages from the Stanford Arabic parser (Green and Manning, 2010). 
 2 The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008).Examples for similar phenomena in Arabic may be found in Green and Manning (2010). 
 This is inefficient with many copy operations due to unfications of unnecessary features that do not contribute to successful unification [6].Thus treatments such as strategic unification [6] have been developed. 
 As it has been noticed by [Godden 90] and [Kogure 90], the key idea of avoiding "redundant copying" is to do copying lazily.Copying of nodes will be delayed until a destructive change is about to take place.Kogure uses a revised copynode procedure which maintains copy dependency information in order to avoid immediate copying.Similarly, in Kogure&apos;s approach, not all redundant copying is avoided in cases where there exists a feature path (a sequence of nodes connected by arcs) to a node that needs to be copied. 
 Several unsupervised POS induction systems make use of morphological features (Blunsom and Cohn, 2011; Lee et al., 2010; Berg-Kirkpatrick et al., 2010; Clark, 2003; Christodoulopoulos et al., 2011) 
 Second, learning categories has been cast as unsupervised part-of-speech tagging task (recent work includes Ravi and Knight (2009), Lee et al.(2010), Lamar et al. 
 Considering Question Topic
 includingfact-based QA and text summarization (Erkan andRadev, 2004; Mihalcea and Tarau, 2004; Otter-bacher et al., 2005; Wan and Yang, 2008). 
 and sentence retrieval for question answering (Otterbacher et al., 2005). 
 These algorithms are all based on the query-sensitive LexRank (OtterBacher et al., 2005). 
 A topic-sensitiveLexRank is proposed in (Otterbacher et al., 2005).As in LexRank, the set of sentences in a documentcluster is represented as a graph, where nodes aresentences and links between the nodes are inducedby a similarity relation between the sentences.Thenthe system ranked the sentences according to a random walk model defined in terms of both the inter-sentence similarities and the similarities of the sentences to the topic description or question. 
 A topic- sensitive LexRank is proposed in (Otterbacher et al., 2005). 
 To apply LexRank to query-focused context, a topic-sensitive version of LexRank is proposed in (Otterbacher et al., 2005). 
 Afterwards, our approach is evaluated against two existing approaches, which rely on the conventional semantic network and are able to capture binary relations only.The other one is based on topic-sensitive LexRank (Otterbacher et al., 2005), called title-sensitive PageRank here. 
 We report in Section 2 on our experiments on the assignment of part of speech to words in text.The effectiveness of such models is well known (DeRose 1988; Church 1988; Kupiec 1989; Jelinek 1985) 
 Similarly, (Sekine, 2005) improved information retrieval based on pattern recognition by introducing paraphrase generation. 
 To date, the majority of work on dialogue act modeling has addressed spoken dialogue (Samuel et al., 1998; Stolcke et al., 2000; Surendran and Levow, 2006; Bangalore et al., 2008; Sridhar et al., 2009; Di Eugenio et al., 2010). 
 There have also been Dialogue Acts modeling approaches for automatic tagging and recognition of conversational speech (Stolcke et al., 2000) and related work in corpus linguistics where machine learning techniques have been used to find conversational patterns in spoken transcripts of dialogue corpus (Shawar and Atwell, 2005). 
 dialogue acts such as statements, questions, backchannels, ... are detected using a language model based detec­tor trained on Switchboard similar to Stolcke et al.(2000 
 The HMM has been widely used in many tagging problems.Stolcke et al.(Stolcke et al., 2000) used it for dialog act classification, where each utterance (or dialog act) is used as the observation. 
 Chinese word segmentation is the initial stage of many Chinese language processing tasks, and has received a lot of attention in the literature (Sproat et al., 1996; Sun and Tsou, 2001; Zhang et al., 2003; Peng et al., 2004). 
 Chi and Geman (1998) proved that any PCFG estimated from a treebank with the relative frequency estimator is tight. 
 When a PCFG probability distribu­tion is estimated from training data (in our case the Penn tree-bank) PCFGs de.ne a tight (sum­ming to one) probability distribution over strings [5], thus making them appropriate for language models. 
 Chi and Geman(1998) studied the question for Maximum Likelihood (ML) estimation, and showed that ML es 1033 timates are always tight for both the supervisedcase (where the input consists of parse trees) andthe unsupervised case (where the input consists ofyields or terminal strings). 
 Measuring the contextual fitness of a term in its context is a key component in different NLP applications like speech recognition (Inkpen and DeÂ´silets, 2005), optical character recognition (Wick et al., 2007), co-reference resolution (Bean and Riloff, 2004) 
 Bean and Riloff (2004) present a system called BABAR that uses contextual role knowledge to do coreference resolution.They apply an IE component to unannotated texts to generate a set of extraction caseframes.Each caseframe represents a linguistic expression and a syntactic position, e.g. â€œmurder of <NP>â€, â€œkilled <patient>â€.From the case- frames, they derive different types of contextual role knowledge for resolution, for example, whether an anaphor and an antecedent candidate can be filled into co-occurring caseframes, or whether they are substitutable for each other in their caseframes. 
 Finally, several coreference systems have successfully incorporated anaphoricity determination modules (e.g. Ng and Cardie (2002a) and Bean and Riloff (2004)). 
 It has shown promise in improving the performance of many tasks such as name tagging (Miller et al., 2004), semantic class extraction (Lin et al., 2003), chunking (Ando and Zhang, 2005), coreference resolution (Bean and Riloff, 2004) 
 Bean and Riloff (2004) present a system, which uses contextual role knowledge to aid coreference resolution.They used lexical and syntactic heuristics to identify high-confidence coreference relations and used them as training data for learning contextual role knowledge.They got substantial gains on articles in two specific domains, terrorism and natural disasters. 
 Inspired by work of Pang[4] and Su[5], we also use Minimum cut (Mincut) model to optimize the Two-stage SVM result. 
 This follows on from the success of these methods in general NLP (see for example Zhou et al (2005)). 
 In building these systems, researchers used a wide variety of features (Kambhatla, 2004; Zhou et al., 2005; Jiang and Zhai, 2007). 
 The former is Zhou et al.(2005), which uses 51 different features. 
 Relation Extraction is a well-studied problem (Miller et al., 2000; Zhou et al., 2005; Kambhatla, 2004; Min et al., 2012a). 
 In addition, we cherry-picked the following features which were not included in Zhou et al.(2005) but were shown to be quite effective for relation extraction. 
 This follows on from the success of these methods in general NLP (see for example Zhou et al (2005)). 
 Sentences should be translated in consistence with their topics (Zhao and Xing, 2006; Zhao and Xing, 2007; Tam et al., 2007). 
 Topic modeling has received some use in SMT, for instance Bilingual LSA adaptation (Tam et al., 2007), and the BiTAM model (Zhao and Xing, 2006), which uses a bilingual topic model for learning alignment. 
 To avoid the need for hard decisions about domain membership, some have used topic modeling to improve SMT performance, e.g., using latent semantic analysis (Tam et al., 2007) or â€˜biTAMâ€™ (Zhao and Xing, 2006). 
 Levin&apos;s study on diathesis alternations has influenced recent work on word sense disamÂ­ biguation (Dorr and Jones, 1996), machine translaÂ­ tion (Dang et al., 1998), and automatic lexical acÂ­ quisition (McCarthy and Korhonen, 1998; Schulte im Walde, 1998). 
 Halteren et al (1998) compare a number of voting methods including a Majority Vote scheme with other combination methods for part of speech tagging. 
 Most work on anaphora resolution has focused on pronominal anaphora, often achieving good accuracy.Kennedy and Boguraev (1996), Mitkov (1998), and Strube, Rapp, and Mueller (2002), for example, report accuracies of 75.0%, 89.7%, and an F-measure of 82.8% for personal pronouns, respectively. 
 As an alternative to the resource-intensive manual classifications, automatic methods such as classification and clustering are applied to induce verb classes from corpus data, e.g.(Merlo and Stevenson, 2001; Joanis and Stevenson, 2003; Korhonen et al., 2003; Stevenson and Joanis, 2003; Schulte im Walde, 2003; Fer- rer, 2004). 
 Golding (1995) showed how methods used for WSD (decision lists and Bayesian classifiers) could be adapted to detect errors resulting from common spelling confusions among sets such as there, their, and they&apos;re. 
 Take the case of context-sensitive spelling error detection 3, which is equivalent to the homophone problem.For that problem, some statistical methods have been applied and succeeded(Golding, 1995; GoldÂ­ ing and Schabes, 1996). 
 Most methods are trained and tested on Model Alta BNC Model Alta BNC f (t ) 72.98 70.00 f (w1 , t , w2 )/ f (t ) 87.77 76.33 f (w1 , t ) 84.40 83.02 f (w1 , w2 , t )/ f (t ) 86.27 74.47 f (t , w1 ) 84.89 82.74 f (t , w2 , w2 )/ f (t ) 84.94 74.23 f (w1 , t , w2 ) 89.24#*77.13 f (w1 , t , w2 )/ f (w1 , t ) 80.70 73.69 f (t , w1 , w2 ) 84.68 75.08 f (w1 , w2 , t )/ f (w2 , t ) 72.11 69.28 f (w1 , t )/ f (t ) 82.81 77.84 f (t , w1 , w2 )/ f (t , w1 ) 75.65 72.57 f (t , w1 )/ f (t ) 77.49 80.71# Table 5
 For English, a number of methods have been proposed to cope with real-word errors in spelling correction (Golding, 1995; Golding and Roth, 1996; Golding and Schabes, 1993; Tong and Evans, 1996). 
 This general scheme has been used to deÂ­ rive classifiers for a variety of natural lanÂ­ guage applications including speech applicaÂ­ tions (Rab89), pos tagging (Kup92; Sch95), word-sense ambiguation (GCY93) and contextÂ­ sensitive spelling correction (Gol95). 
 Previous work has addressed the problem of CSSC from a machine learning perspective, including Bayesian and Decision List models (Golding, 1995) 
 For CSSC, we tested our system on the identical data from the Brown corpus used by Golding (1995) 
 A different body of work (e.g. Golding, 1995; Golding and Roth, 1996; Mangu and Brill, 1997) focused on resolving a limited number of cognitive substitution errors, in the framework of context sensitive spelling correction (CSSC). 
 More generally, as a precursor to the above- mentioned work, confusable disambiguation has been investigated in a string of papers discussing the application of various machine learning algorithms to the task (Yarowsky, 1994; Golding, 1995; 
 There are also other studies (Yarowsky, 1994; Golding, 1995 or Golding and Roth, 1996) that report the application of decision lists and Bayesian classifiers for spell checking; however, these models cannot be applied to grammar error detection. 
 Golding [1995] has applied a hybrid Bayesian method for real-word error correction and Golding and Schabes [1996] have combined a POS trigram and Bayesian methods for the same purpose. 
 Our module used for spelling correction was developed on the basis of works by Brill [1], Brill and Marcus [2), Golding [3), Golding and Schabes [4], and Powers [5). 
