 The practical effect of this is that Troll implements an exhaustive typing strategy which provides the stronger kind of inferencing over descriptions (Gerdemann and King, 1993, 1994) required by standard HPSG theories. 
 BB task example Ureaplasma parvum is a mycoplasma and a pathogenic biology challenges (Kim et al., 2010) and geographical locations (Zhou et al., 2005). 
 BB task example Ureaplasma parvum is a mycoplasma and a pathogenic biology challenges (Kim et al., 2010) and geographical locations (Zhou et al., 2005). 
 Zhao et al.(2006) assumed that the parallel sentence pairs within a document pair constitute a mixture of hidden topics and each word pair follows a topic-specific bilingual translation model.It shows that the performance of word alignment can be improved with the help of document-level information, which indirectly improves the quality of SMT. 
 Our approach is inspired by the recent studies (Zhao and Xing, 2006; Zhao and Xing, 2007; Tam et al., 2007; Gong and Zhou, 2010; Ruiz and Federico, 2011) which have shown that a particular translation always appears in some specific topical contexts, and the topical context information has a great effect on translation selection. 
 Sentences should be translated in consistence with their topics (Zhao and Xing, 2006; Zhao and Xing, 2007; Tam et al., 2007). 
 Topic modeling has received some use in SMT, for instance Bilingual LSA adaptation (Tam et al., 2007), and the BiTAM model (Zhao and Xing, 2006), which uses a bilingual topic model for learning alignment. 
 To avoid the need for hard decisions about domain membership, some have used topic modeling to improve SMT performance, e.g., using latent semantic analysis (Tam et al., 2007) or â€˜biTAMâ€™ (Zhao and Xing, 2006). 
 This lexicon exploits the systematic link between syntax and semantics that motivates the Levin classes, and thus provides a clear and regular association between syntactic and semantic properties of verbs and verb classes, [Dang, et al, 98, 00, Kipper, et al. 00]. 
 Palmer (2000) and Dang et al.(1998) argue that syntactic frames and verb classes are useful for developing principled classifications of verbs. 
 In many cases, the additional information that VerbNet provides for each class has caused it to subdivide, or use intersections of, Levinâ€™s original classes, adding an additional level to the hierarchy (Dang et al. 1998). 
 Classifications which aim to capture the close relation between the syntax and semantics of verbs have attracted a considerable research interest in both linguistics and computational linguistics (e.g.(Jack- endoff, 1990; Levin, 1993; Pinker, 1989; Dang et al., 1998; Dorr, 1997; Merlo and Stevenson, 2001)). 
 Dang et al.(1998), for example, have refined the current classification by creating intersective classes for those verbs which share membership of more than one Levin class. 
 Lexical-semantic classes which aim to capture the close relationship between the syntax and semantics of verbs have attracted considerable interest in both linguistics and computational linguistics (e.g.(Pinker, 1989; Jackendoff, 1990; Levin, 1993; Dorr, 1997; Dang et al., 1998; Merlo and Stevenson, 2001)). 
 This constraint of having the same semantic roles is further ensured inside the VerbNet lexi con that is constructed based on a more refined version of the Levin classification called Inter- sective Levin classes (Dang et al., 1998). 
 Palmer (1999) and Dang et a!.(1998) argue that the use of syntactic frames and verb classes can simÂ­ plify the definition of different verb senses. 
 (Stevenson and Joanis, 2003) investigate the applicability of this general feature space to unsupervised verb clustering tasks. 
 We have also selected a decision list classifier (DL) which is similar to the classifier used by (Yarowsky, 1994) for words having two senses, and extended for more senses by (Golding, 1995). 
 MBL, by using long and very specialized conjunctions (DBZ99) and decision lists, due to their functional form - a linear function with exponentially decreasing weights - at the cost of predicting with a single feature, rather than a combination (Gol95). 
