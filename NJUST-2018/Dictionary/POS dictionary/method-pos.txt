Under_IN this_DT constraint_NN ,_, many_JJ researchers_NNS had_VBD contributed_VBN algorithms_NNS and_CC associated_VBN pruning_NN strategies_NNS ,_, such_JJ as_IN Berger_NNP et_FW al._FW -LRB-_-LRB- 1996_CD -RRB-_-RRB- ,_, Och_NNP et_FW al._FW -LRB-_-LRB- 2001_CD -RRB-_-RRB- ,_, Wang_NNP and_CC Waibel_NNP -LRB-_-LRB- 1997_CD -RRB-_-RRB- ,_, Tillmann_NNP and_CC Ney_NNP -LRB-_-LRB- 2000_CD -RRB-_-RRB- GarciaVarea_NNP and_CC Casacuberta_NNP -LRB-_-LRB- 2001_CD -RRB-_-RRB- and_CC Germann_NNP et_FW al._FW ._.
There_EX exists_VBZ stack_VB decoding_VBG algorithm_NN -LRB-_-LRB- Berger_NNP et_FW al._FW ,_, 1996_CD -RRB-_-RRB- ,_, A_DT *_SYM search_NN algorithm_NN -LRB-_-LRB- Och_NN et_FW al._FW ,_, 2001_CD ;_: Wang_NNP and_CC Waibel_NNP ,_, 1997_CD -RRB-_-RRB- and_CC dynamic-programming_JJ algorithms_NNS -LRB-_-LRB- Tillmann_NNP and_CC Ney_NNP ,_, 2000_CD ;_: GarciaVarea_NNP and_CC Casacuberta_NNP ,_, 2001_CD -RRB-_-RRB- ,_, and_CC all_DT translate_VB a_DT given_VBN input_NN string_NN word-by-word_JJ and_CC render_VBP the_DT translation_NN in_IN left-to-right_NN ,_, with_IN pruning_NN technologies_NNS assuming_VBG almost_RB linearly_RB aligned_VBN translation_NN source_NN and_CC target_NN texts_NNS ._.
The_DT decoding_VBG methods_NNS presented_VBN in_IN this_DT paper_NN explore_VB the_DT partial_JJ candidate_NN translation_NN hypotheses_NNS greedily_RB ,_, as_IN presented_VBN in_IN Tillmann_NNP and_CC Ney_NNP -LRB-_-LRB- 2000_CD -RRB-_-RRB- and_CC Och_NNP et_FW al._FW ._.
The_DT computational_JJ complexity_NN for_IN the_DT left-to-right_NN and_CC right-to-left_NN is_VBZ the_DT same_JJ ,_, O_NN -LRB-_-LRB- E_NN 3m22m_NN -RRB-_-RRB- ,_, as_IN reported_VBN by_IN Tillmann_NNP and_CC Ney_NNP -LRB-_-LRB- 2000_CD -RRB-_-RRB- ,_, in_IN which_WDT E_NN is_VBZ the_DT size_NN of_IN the_DT vocabulary_NN for_IN output_NN sentences_NNS 3_CD ._.
Tillman_NNP and_CC Ney_NNP showed_VBD how_WRB to_TO improve_VB the_DT complexity_NN of_IN the_DT Held-Karp_JJ algorithm_NN for_IN restricted_JJ word_NN reordering_NN and_CC gave_VBD a_DT O_NN -LRB-_-LRB- l3m4_NN -RRB-_-RRB- ≈_CD O_NN -LRB-_-LRB- m7_NN -RRB-_-RRB- algo_NN rithm_NN for_IN French-English_JJ translation_NN -LRB-_-LRB- Tillman_NN and_CC Ney_NN ,_, 2000_CD -RRB-_-RRB- ._.
â_RB $_$ cents_NNS Conditional_JJ Probability_NNP Given_VBN the_DT model_NN parameters_NNS and_CC a_DT sentence_NN pair_NN -LRB-_-LRB- f_FW ,_, e_LS -RRB-_-RRB- ,_, compute_VB P_NN -LRB-_-LRB- f_FW e_LS -RRB-_-RRB- .1997_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Tillman_NNP ,_, 2000_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Och_NNP et_FW al._FW ,_, 2001_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Germann_NNP et_FW al._FW ,_, 2003_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Udupa_NNP et_FW al._FW ,_, 2004_CD -RRB-_-RRB- ._.
To_TO summarize_VB these_DT experimental_JJ tests_NNS ,_, we_PRP briefly_RB report_VBP experimental_JJ offline_JJ results_NNS for_IN the_DT following_VBG translation_NN approaches_NNS This_DT article_NN will_MD present_VB a_DT DP-based_JJ beam_NN search_NN decoder_NN for_IN the_DT IBM4_NN translation_NN model.A_NN preliminary_JJ version_NN of_IN the_DT work_NN presented_VBN here_RB was_VBD published_VBN in_IN Tillmann_NNP and_CC Ney_NNP -LRB-_-LRB- 2000_CD -RRB-_-RRB- ._.
Many_JJ existing_VBG systems_NNS for_IN statistical_JJ machine_NN translation_NN 1_CD 1_CD -LRB-_-LRB- Garc_NN '_'' ıa-Varea_JJ and_CC Casacuberta_JJ 2001_CD ;_: Germann_NNP et_FW al._FW 2001_CD ;_: Nießen_NNP et_FW al._FW 1998_CD ;_: Och_NNP ,_, Tillmann_NNP ,_, and_CC Ney_NNP 1999_CD -RRB-_-RRB- implement_VBP models_NNS presented_VBN by_IN Brown_NNP ,_, Della_NNP Pietra_NNP ,_, Della_NNP Pietra_NNP ,_, and_CC Mercer_NNP -LRB-_-LRB- 1993_CD -RRB-_-RRB- We_PRP call_VBP this_DT selection_NN of_IN highly_RB probable_JJ words_NNS observation_NN pruning_NN -LRB-_-LRB- Tillmann_NNP and_CC Ney_NNP 2000_CD -RRB-_-RRB- ._.
Och_NNP et_FW al._FW report_NN word_NN error_NN rates_NNS of_IN 68.68_CD %_NN for_IN optimal_JJ search_NN -LRB-_-LRB- based_VBN on_IN a_DT variant_NN of_IN the_DT A_NN *_SYM algorithm_NN -RRB-_-RRB- ,_, and_CC 69.65_CD %_NN for_IN the_DT most_RBS restricted_JJ version_NN of_IN a_DT decoder_NN that_WDT combines_VBZ dynamic_JJ programming_NN with_IN a_DT beam_NN search_NN -LRB-_-LRB- Tillmann_NNP and_CC Ney_NNP ,_, 2000_CD -RRB-_-RRB- ._.
We_PRP use_VBP the_DT top-10_JJ list_NN of_IN hypothesis_NN provided_VBN by_IN the_DT translation_NN system_NN described_VBN in_IN -LRB-_-LRB- Tillmann_NNP and_CC Ney_NNP ,_, 2000_CD -RRB-_-RRB- for_IN rescoring_VBG the_DT hypothesis_NN using_VBG the_DT ME_NN models_NNS and_CC sort_VB them_PRP according_VBG to_TO the_DT new_JJ maximum_NN entropy_JJ score_NN ._.
The_DT decoding_VBG algorithm_NN employed_VBN for_IN this_DT chunk_NN +_CC weight_NN Ã_NN --_: j_FW f_FW req_NN -LRB-_-LRB- EA_NN j_NN ,_, J_NN j_NN -RRB-_-RRB- based_VBN statistical_JJ translation_NN is_VBZ based_VBN on_IN the_DT beam_NN search_NN algorithm_NN for_IN word_NN alignment_NN statistical_JJ in_IN which_WDT Ptm_NN -LRB-_-LRB- J_NN E_NN -RRB-_-RRB- and_CC Plm_NN -LRB-_-LRB- E_NN -RRB-_-RRB- are_VBP translationmodel_NN and_CC language_NN model_NN probability_NN ,_, respec_JJ translation_NN presented_VBN in_IN -LRB-_-LRB- Tillmann_NNP and_CC Ney_NNP ,_, 2000_CD -RRB-_-RRB- ,_, tively1_NN ,_, freq_NN -LRB-_-LRB- EA_NN j_NN ,_, J_NN j_NN -RRB-_-RRB- is_VBZ the_DT frequency_NN for_IN the_DT which_WDT generates_VBZ outputs_NNS in_IN left-to-right_JJ order_NN by_IN consuming_VBG input_NN in_IN an_DT arbitrary_JJ order_NN ._.
The_DT generation_NN of_IN possible_JJ output_NN chunks_NNS is_VBZ estimated_VBN through_IN an_DT inverted_JJ lexicon_NN model_NN and_CC sequences_NNS of_IN inserted_VBN strings_NNS -LRB-_-LRB- Tillmann_NNP and_CC Ney_NNP ,_, 2000_CD -RRB-_-RRB- ._.
We_PRP used_VBD a_DT translation_NN system_NN called_VBN â_RB $_$ œsingle_JJ -_: word_NN based_VBN approachâ_RB $_$ described_VBN in_IN -LRB-_-LRB- Tillmann_NNP and_CC Ney_NNP ,_, 2000_CD -RRB-_-RRB- and_CC compared_VBN to_TO other_JJ approaches_NNS in_IN -LRB-_-LRB- Ney_NNP et_FW al._FW ,_, 2000_CD -RRB-_-RRB- ._.
Search_VB algorithms_NNS We_PRP evaluate_VBP the_DT following_VBG two_CD search_NN algorithms_NNS It_PRP is_VBZ faster_RBR because_IN the_DT search_NN problem_NN for_IN noisy_JJ -_: channel_NN models_NNS is_VBZ NP-complete_JJ -LRB-_-LRB- Knight_NNP ,_, 1999_CD -RRB-_-RRB- ,_, and_CC even_RB the_DT fastest_JJS dynamic-programming_JJ heuristics_NNS used_VBN in_IN statistical_JJ MT_NN -LRB-_-LRB- Niessen_NNP et_FW al._FW ,_, 1998_CD ;_: Till_IN -_: mann_NN and_CC Ney_NN ,_, 2000_CD -RRB-_-RRB- ,_, are_VBP polynomial_JJ in_IN J_NN --_: for_IN in_IN p_NN -LRB-_-LRB- v1_NN ,_, w2_NN ,_, wm_NN −_NN 1_CD ,_, um_NN h_NN ,_, s_NNS -RRB-_-RRB- =_JJ stance_NN O_NN -LRB-_-LRB- mJ_NN 4V_NN 3_CD -RRB-_-RRB- in_IN -LRB-_-LRB- Tillmann_NNP and_CC Ney_NNP ,_, 2000_CD -RRB-_-RRB- ._.
In_IN such_JJ cases_NNS ,_, neither_CC global_JJ features_NNS -LRB-_-LRB- Chieu_NNP and_CC Ng_NNP ,_, 2002_CD -RRB-_-RRB- nor_CC aggregated_JJ contexts_NNS -LRB-_-LRB- Chieu_NNP and_CC Ng_NNP ,_, 2003_CD -RRB-_-RRB- can_MD help_VB ._.
More_JJR details_NNS of_IN this_DT mixed_JJ case_NN NER_NN and_CC its_PRP$ performance_NN are_VBP given_VBN in_IN -LRB-_-LRB- Chieu_NNP and_CC Ng_NNP ,_, 2002_CD -RRB-_-RRB- ._.
Soder_NNP -_: land_NN -LRB-_-LRB- 1999_CD -RRB-_-RRB- and_CC Chieu_NNP and_CC Ng_NNP -LRB-_-LRB- 2002a_JJ -RRB-_-RRB- attempted_VBN machine_NN learning_VBG approaches_NNS for_IN a_DT scaled-down_JJ version_NN of_IN the_DT ST_JJ task_NN ,_, where_WRB it_PRP was_VBD assumed_VBN that_IN the_DT information_NN needed_VBN to_TO fill_VB one_CD template_NN came_VBD from_IN one_CD sentence_NN only_RB ._.
Chieu_NNP and_CC Ng_NNP -LRB-_-LRB- 2002_CD -RRB-_-RRB- propose_VBP a_DT solution_NN to_TO this_DT problem_NN -LRB-_-LRB- Borthwick_NN ,_, 1999_CD -RRB-_-RRB- made_VBD a_DT second_JJ tagging_NN pass_NN which_WDT uses_VBZ information_NN on_IN token_JJ sequences_NNS tagged_VBN in_IN the_DT first_JJ pass_NN ;_: -LRB-_-LRB- Chieu_NNP and_CC Ng_NNP ,_, 2002_CD -RRB-_-RRB- used_VBN as_IN features_NNS information_NN about_IN features_NNS assigned_VBN to_TO other_JJ instances_NNS of_IN the_DT same_JJ token.Recently_NN ,_, in_IN -LRB-_-LRB- Ji_NN and_CC Grishman_NN ,_, 2004_CD -RRB-_-RRB- we_PRP pro_FW posed_VBD a_DT name_NN tagging_VBG method_NN which_WDT applied_VBD an_DT SVM_NN based_VBN on_IN coreference_NN information_NN to_TO filter_NN the_DT names_NNS with_IN low_JJ confidence_NN ,_, and_CC used_VBN coreference_NN rules_NNS to_TO correct_VB and_CC recover_VB some_DT names_NNS ._.
Useful_JJ Unigrams_NNS -LRB-_-LRB- UNI_NN -RRB-_-RRB- For_IN each_DT name_NN class_NN ,_, words_NNS that_WDT precede_VBP the_DT name_NN class_NN are_VBP ranked_VBN using_VBG correlation_NN metric_JJ -LRB-_-LRB- Chieu_NNP and_CC Ng_NNP ,_, 2002a_NN -RRB-_-RRB- ,_, and_CC the_DT top_JJ 20_CD are_VBP compiled_VBN into_IN a_DT list_NN ._.
The_DT basic_JJ features_NNS used_VBN by_IN both_CC ME1_NN and_CC ME2_NN can_MD be_VB divided_VBN into_IN two_CD classes_NNS Token_JJ Information_NN These_DT features_NNS are_VBP based_VBN on_IN the_DT string_NN w_NN ,_, such_JJ as_IN contains-digits_NNS ,_, contains-dollar-sign_NN ,_, etc_NN -LRB-_-LRB- Chieu_NNP and_CC Ng_NNP ,_, 2002b_NN -RRB-_-RRB- ._.
In_IN this_DT paper_NN ,_, w_NN −_NN i_FW refers_VBZ to_TO the_DT ith_NN word_NN before_IN w_NN ,_, and_CC w_NN +_CC i_FW refers_VBZ to_TO the_DT ith_NN word_NN after_IN w_NN ._.
The_DT features_NNS used_VBN are_VBP similar_JJ to_TO those_DT used_VBN in_IN -LRB-_-LRB- Chieu_NNP and_CC Ng_NNP ,_, 2002b_NN -RRB-_-RRB- ._.
Chieu_NNP and_CC Ng_NNP used_VBD global_JJ information_NN such_JJ as_IN the_DT occurrence_NN of_IN the_DT same_JJ word_NN with_IN other_JJ capitalisation_NN in_IN the_DT same_JJ document_NN -LRB-_-LRB- Chieu_NNP and_CC Ng_NNP ,_, 2002a_NN -RRB-_-RRB- ,_, and_CC have_VBP also_RB used_VBN a_DT mixed-case_JJ classifier_NN to_TO teach_VB a_DT â_JJ $_$ œweakerâ_JJ $_$ classifier_JJ that_IN did_VBD not_RB use_VB case_NN information_NN at_IN all_DT -LRB-_-LRB- Chieu_NNP and_CC Ng_NNP ,_, 2002b_NN -RRB-_-RRB- ._.
AMaximum_NNP Entropy_NNP methods_NNS -LRB-_-LRB- Borthwick_NNP et_FW al._FW 1998_CD ,_, Chieu_NNP and_CC Ng_NNP 2002_CD -RRB-_-RRB- Other_JJ systems_NNS have_VBP made_VBN a_DT second_JJ tagging_NN pass_NN which_WDT uses_VBZ information_NN on_IN token_JJ sequences_NNS tagged_VBN in_IN the_DT first_JJ pass_NN -LRB-_-LRB- Borthwick_NN 1999_CD -RRB-_-RRB- ,_, or_CC have_VBP used_VBN as_IN features_NNS information_NN about_IN features_NNS assigned_VBN to_TO other_JJ instances_NNS of_IN the_DT same_JJ token_JJ -LRB-_-LRB- Chieu_NNP and_CC Ng_NNP 2002_CD -RRB-_-RRB- ._.
To_TO our_PRP$ knowledge_NN ,_, this_DT association_NN measure_NN has_VBZ not_RB been_VBN used_VBN yet_RB in_IN translation_NN spotting.It_NN is_VBZ computed_VBN as_IN At_IN present_JJ ,_, the_DT methods_NNS for_IN OOV_NN term_NN translation_NN have_VBP changed_VBN from_IN the_DT basic_JJ pattern_NN based_VBN on_IN bilingual_JJ dictionary_NN ,_, transliteration_NN or_CC parallel_NN corpus_NN to_TO the_DT intermediate_JJ pattern_NN based_VBN on_IN comparable_JJ corpus_NN -LRB-_-LRB- Lee_NNP et_FW al._FW ,_, 2006_CD ;_: Shao_NNP and_CC Ng_NNP ,_, 2004_CD ;_: Virga_NNP and_CC Khudanpur_NNP ,_, 2003_CD -RRB-_-RRB- ,_, and_CC 1435_CD Coling_NNP 2010_CD Various_JJ correlation_NN measures_NNS have_VBP been_VBN used_VBN Various_JJ clues_NNS have_VBP been_VBN considered_VBN when_WRB computing_VBG the_DT similarities_NNS The_DT other_JJ is_VBZ multilingual_JJ parallel_NN and_CC comparable_JJ corpora_NN -LRB-_-LRB- e.g._FW ,_, Wikipedia1_NN -RRB-_-RRB- ,_, wherein_WRB features_NNS such_JJ as_IN co_NN -_: occurrence_NN frequency_NN and_CC context_NN are_VBP popularly_RB employed_VBN -LRB-_-LRB- Cheng_NNP et_FW al._FW ,_, 2004_CD ;_: Shao_NNP and_CC Ng_NNP ,_, 2004_CD ;_: Cao_NNP et_FW al._FW ,_, 2007_CD ;_: Lin_NNP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- ._.
Shao_NNP and_CC Ng_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- presented_VBD a_DT method_NN to_TO mine_VB new_JJ translations_NNS from_IN Chinese_JJ and_CC English_JJ news_NN documents_NNS of_IN the_DT same_JJ period_NN from_IN different_JJ news_NN agencies_NNS ,_, combining_VBG both_CC transliteration_NN and_CC context_NN information_NN ._.
Much_JJ of_IN the_DT work_NN involving_VBG comparable_JJ corpora_NN has_VBZ focused_VBN on_IN extracting_VBG word_NN translations_NNS -LRB-_-LRB- Fung_NNP and_CC Yee_NNP ,_, 1998_CD ;_: Rapp_NNP ,_, 1999_CD ;_: Diab_NNP and_CC Finch_NNP ,_, 2000_CD ;_: Koehn_NNP and_CC Knight_NNP ,_, 2000_CD ;_: Gaussier_NNP et_FW al._FW ,_, 2004_CD ;_: Shao_NNP and_CC Ng_NNP ,_, 2004_CD ;_: Shinyama_NNP and_CC Sekine_NNP ,_, 2004_CD -RRB-_-RRB- ._.
Some_DT recent_JJ research_NN used_VBN comparable_JJ corpora_NN to_TO mine_JJ name_NN translation_NN pairs_NNS -LRB-_-LRB- Feng_NNP et_FW al._FW ,_, 2004_CD ;_: Kutsumi_NNP et_FW al._FW ,_, 2004_CD ;_: Udupa_NNP et_FW al._FW ,_, 2009_CD ;_: Ji_NNP ,_, 2009_CD ;_: Fung_NNP and_CC Yee_NNP ,_, 1998_CD ;_: Rapp_NNP ,_, 1999_CD ;_: Shao_NNP and_CC Ng_NNP ,_, 2004_CD ;_: Lu_NNP and_CC Zhao_NNP ,_, 2006_CD ;_: Hassan_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ._.
Evaluation_NN E_NN C_NN We_PRP processed_VBD news_NN articles_NNS for_IN an_DT entire_JJ year_NN in_IN tion_NN of_IN maximum_NN bipartite_JJ matching_NN -LRB-_-LRB- West_NN ,_, 1999_CD -RRB-_-RRB- on_IN a_DT bipartite_JJ graph_NN GB_NN =_JJ -LRB-_-LRB- VB_NN =_JJ -LRB-_-LRB- Si_NNP ,_, Sj_NNP -RRB-_-RRB- ,_, EB_NNP -RRB-_-RRB- 2008_CD by_IN Xinhua_NNP news_NN who_WP publishes_VBZ news_NN in_IN E_NN C_NN both_CC English_JJ and_CC Chinese_JJ ,_, which_WDT were_VBD also_RB used_VBN with_IN edge_NN weights_NNS that_WDT are_VBP defined_VBN by_IN TS_NN ._.
The_DT maximum_NN bipartite_JJ matching_NN finds_VBZ a_DT subset_NN of_IN by_IN Kim_NNP et_FW al._FW -LRB-_-LRB- 2011_CD -RRB-_-RRB- and_CC Shao_NNP and_CC Ng_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- ._.
Recently_RB ,_, holistic_JJ approaches_NNS combining_VBG such_JJ similarities_NNS have_VBP been_VBN studied_VBN -LRB-_-LRB- Shao_NNP and_CC Ng_NNP ,_, 2004_CD ;_: You_PRP et_FW al._FW ,_, 2010_CD ;_: Kim_NNP et_FW al._FW ,_, 2011_CD -RRB-_-RRB- ._.
-LRB-_-LRB- Shao_NNP and_CC Ng_NNP ,_, 2004_CD -RRB-_-RRB- rank_NN translation_NN candidates_NNS using_VBG PH_NN and_CC CX_NN independently_RB and_CC return_VB results_NNS with_IN the_DT highest_JJS average_JJ rank_NN ._.
Some_DT recent_JJ research_NN used_VBN comparable_JJ corpora_NN to_TO re-score_JJ name_NN transliterations_NNS -LRB-_-LRB- Sproat_NNP et_FW al._FW ,_, 2006_CD ;_: Klementiev_NNP and_CC Roth_NNP ,_, 2006_CD -RRB-_-RRB- or_CC mine_PRP new_JJ word_NN translations_NNS -LRB-_-LRB- Fung_NNP and_CC Yee_NNP ,_, 1998_CD ;_: Rapp_NNP ,_, 1999_CD ;_: Shao_NNP and_CC Ng_NNP ,_, 2004_CD ;_: Tao_NNP and_CC Zhai_NNP ,_, 2005_CD ;_: Hassan_NNP et_FW al._FW ,_, 2007_CD ;_: Udupa_NNP et_FW al._FW ,_, 2009_CD ;_: Ji_NNP ,_, 2009_CD -RRB-_-RRB- ._.
Hybrid_NN methods_NNS exploit_VBP that_IN a_DT term_NN or_CC a_DT named_VBN entity_NN can_MD be_VB translated_VBN in_IN various_JJ ways_NNS across_IN languages_NNS -LRB-_-LRB- Shao_NNP and_CC Ng_NNP ,_, 2004_CD ;_: Feng_NNP et_FW al._FW ,_, 2004_CD ;_: Lu_NNP and_CC Zhao_NNP ,_, 2006_CD -RRB-_-RRB- ._.
For_IN German_JJ ,_, we_PRP obtain_VBP a_DT tagging_VBG accuracy_NN of_IN 97.24_CD ,_, which_WDT is_VBZ close_JJ to_TO the_DT 97.39_CD achieved_VBN by_IN the_DT RFTagger_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- ,_, which_WDT to_TO our_PRP$ knowledge_NN is_VBZ the_DT best_JJS tagger_NN for_IN German_JJ We_PRP use_VBP the_DT following_VBG baselines_NNS For_IN German_JJ ,_, we_PRP show_VBP results_NNS for_IN RFTagger_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- ._.
The_DT decisiontree_NN uses_VBZ different_JJ context_NN features_NNS for_IN the_DT predic_JJ tion_NN of_IN different_JJ attributes_NNS -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- ._.
However_RB ,_, we_PRP found_VBD that_IN we_PRP achieved_VBD better_JJR accuracy_NN by_IN using_VBG RFTagger_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- ,_, which_WDT tags_NNS nouns_NNS with_IN their_PRP$ morphological_JJ case_NN ._.
With_IN respect_NN to_TO morphosyntactic_JJ annotations_NNS -LRB-_-LRB- parts_NNS of_IN speech_NN ,_, pos_NNS -RRB-_-RRB- and_CC morphological_JJ annotations_NNS -LRB-_-LRB- morph_NN -RRB-_-RRB- ,_, five_CD Annotation_NNP Models_NNS for_IN German_JJ are_VBP currently_RB available_JJ Analogously_NNP ,_, the_DT corresponding_JJ RFTagger_NN analysis_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- given_VBN in_IN -LRB-_-LRB- 5_LS -RRB-_-RRB- can_MD be_VB transformed_VBN into_IN a_DT description_NN in_IN terms_NNS of_IN the_DT OLiA_NNP Reference_NNP Model_NNP such_JJ as_IN in_IN -LRB-_-LRB- 6_CD -RRB-_-RRB- ._.
-LRB-_-LRB- iii_LS -RRB-_-RRB- the_DT RFTagger_NN that_WDT performs_VBZ part_NN of_IN speech_NN and_CC morphological_JJ analysis_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- These_DT normalization_NN patterns_NNS use_VBP the_DT lemma_NN information_NN computed_VBN by_IN the_DT TreeTagger_NNP and_CC the_DT fine-grained_JJ POS_NN information_NN computed_VBN by_IN the_DT RFTagger_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- ,_, which_WDT uses_VBZ a_DT tagset_NN containing_VBG approximately_RB 800_CD tags_NNS ._.
For_IN German_JJ ,_, the_DT fine-grained_JJ POS_NN information_NN used_VBN for_IN pre-processing_JJ was_VBD computed_VBN by_IN the_DT RFTagger_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- ._.
All_DT parallel_JJ corpora_NN were_VBD POS-tagged_JJ with_IN the_DT TreeTagger_NNP -LRB-_-LRB- Schmid_NNP ,_, 1994_CD -RRB-_-RRB- ;_: in_IN addition_NN ,_, for_IN German_JJ ,_, fine-grained_JJ POS_NN labels_NNS were_VBD also_RB needed_VBN for_IN pre-processing_JJ and_CC were_VBD obtained_VBN using_VBG the_DT RFTagger_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- ._.
Morphological_JJ information_NN is_VBZ annotated_JJ using_VBG RFTagger_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- ,_, a_DT state-of-the-art_JJ morphological_JJ tagger_NN based_VBN on_IN decision_NN trees_NNS and_CC a_DT large_JJ context_NN window_NN -LRB-_-LRB- which_WDT allows_VBZ it_PRP to_TO model_VB morphological_JJ agreement_NN more_RBR accurately_RB than_IN a_DT normal_JJ trigram-based_JJ sequence_NN tagger_NN -RRB-_-RRB- ._.
All_DT parallel_JJ corpora_NN were_VBD POS-tagged_JJ with_IN the_DT TreeTagger_NNP -LRB-_-LRB- Schmid_NNP ,_, 1994_CD -RRB-_-RRB- ;_: in_IN addition_NN ,_, for_IN German_JJ ,_, fine-grained_JJ POS_NN labels_NNS were_VBD also_RB needed_VBN for_IN pre-processing_JJ and_CC were_VBD obtained_VBN using_VBG the_DT RFTagger_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- ._.
In_IN order_NN to_TO train_VB the_DT POS-based_JJ reordering_NN model_NN ,_, probabilistic_JJ rules_NNS were_VBD learned_VBN based_VBN on_IN the_DT POS_NN tags_NNS from_IN the_DT TreeTagger_NNP -LRB-_-LRB- Schmid_NNP and_CC Laws_NNP ,_, 2008_CD -RRB-_-RRB- of_IN the_DT training_NN corpus_NN and_CC the_DT alignment_NN ._.
The_DT POS_NN tags_NNS are_VBP generated_VBN using_VBG the_DT RFTagger_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- for_IN German_JJ ._.
6.1.1_CD POS_NN Tagging_VBG We_PRP use_VBP RFTagger_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- for_IN POS_NN tagging_NN ._.
In_IN the_DT second_JJ step_NN ,_, the_DT normalized_VBN training_NN data_NNS is_VBZ annotated_JJ with_IN Part-of-Speech_NN tags_NNS -LRB-_-LRB- PoS-tags_NNS -RRB-_-RRB- and_CC word_NN lemmas_NNS using_VBG RFTagger_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- which_WDT was_VBD trained_VBN on_IN the_DT French_JJ tree_NN -_: bank_NN -LRB-_-LRB- AbeilleÂ_NN '_'' et_FW al._FW ,_, 2003_CD -RRB-_-RRB- ._.
Morphological_JJ analysis_NN and_CC resources_NNS The_DT morphological_JJ analysis_NN of_IN the_DT French_JJ training_NN data_NNS is_VBZ obtained_VBN using_VBG RFTagger_NN ,_, which_WDT is_VBZ designed_VBN for_IN annotating_VBG fine-grained_JJ morphological_JJ tags_NNS -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- ._.
Tagging_VBG and_CC tagging_VBG errors_NNS For_IN tagging_VBG ,_, we_PRP use_VBP a_DT version_NN of_IN RFTagger_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- The_DT results_NNS presented_VBN here_RB were_VBD achieved_VBN using_VBG the_DT RFTagger_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- So_RB far_RB ,_, the_DT Complex_NN Concept_NNP Builder_NNP implements_VBZ tokenization_NN -LRB-_-LRB- Schmid_NN ,_, 2009_CD -RRB-_-RRB- ,_, lemmatisation_NN -LRB-_-LRB- Schmid_NN ,_, 1995_CD -RRB-_-RRB- ,_, part-of-speech_JJ tagging_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- Joint_NNP segmentation_NN and_CC parsing_NN was_VBD also_RB investigated_VBN for_IN Arabic_JJ -LRB-_-LRB- Green_NN and_CC Manning_NN ,_, 2010_CD -RRB-_-RRB- ._.
Indeed_RB ,_, we_PRP have_VBP used_VBN it_PRP to_TO solve_VB the_DT problem_NN of_IN parsing_NN while_IN recovering_VBG null_JJ elements_NNS in_IN both_CC English_NNP and_CC Chinese_NNP -LRB-_-LRB- Cai_NNP ,_, Chiang_NNP ,_, and_CC Goldberg_NNP 2011_CD -RRB-_-RRB- ,_, and_CC others_NNS have_VBP used_VBN it_PRP for_IN the_DT joint_JJ segmentation_NN and_CC parsing_NN of_IN Arabic_JJ -LRB-_-LRB- Green_NN and_CC Manning_VBG 2010_CD -RRB-_-RRB- ._.
This_DT is_VBZ by_IN now_RB a_DT fairly_RB standard_JJ representation_NN for_IN multiple_JJ morphological_JJ segmentations_NNS of_IN Hebrew_JJ utterances_NNS -LRB-_-LRB- Adler_NNP 2001_CD ;_: Bar-Haim_NNP ,_, Simaâ_NNP $_$ ™_CD an_DT ,_, and_CC Winter_NNP 2005_CD ;_: Adler_NNP 2007_CD ;_: Cohen_NNP and_CC Smith_NNP 2007_CD ;_: Goldberg_NNP ,_, Adler_NNP ,_, and_CC Elhadad_NNP 2008_CD ;_: Goldberg_NNP and_CC Tsarfaty_NNP 2008_CD ;_: Goldberg_NNP and_CC Elhadad_NNP 2011_CD -RRB-_-RRB- ._.
It_PRP is_VBZ also_RB used_VBN for_IN Arabic_JJ -LRB-_-LRB- Green_NN and_CC Manning_VBG 2010_CD -RRB-_-RRB- Recently_RB ,_, Green_NNP and_CC Manning_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- report_NN on_IN an_DT extensive_JJ set_NN of_IN experiments_NNS with_IN several_JJ kinds_NNS of_IN tree_NN annotations_NNS and_CC refinements_NNS ,_, and_CC report_NN parsing_NN accuracies_NNS of_IN 79_CD %_NN F1_NN using_VBG the_DT Stanford-parser_NN and_CC 82_CD %_NN F1_NN using_VBG the_DT PCFG-LA_NN BerkeleyParser_NNP ,_, both_DT when_WRB assuming_VBG gold_NN word_NN segmentation_NN ._.
Recently_RB ,_, Green_NNP and_CC Manning_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- analyzed_VBD the_DT PATB_NN for_IN annotation_NN consistency_NN ,_, and_CC introduced_VBD an_DT enhanced_VBN split-state_JJ constituency_NN grammar_NN ,_, including_VBG labels_NNS for_IN short_JJ idafa_NN constructions_NNS and_CC verbal_JJ or_CC equational_JJ clauses_NNS ._.
For_IN better_JJR comparison_NN with_IN work_NN of_IN others_NNS ,_, we_PRP adopt_VBP the_DT suggestion_NN made_VBN by_IN Green_NNP and_CC Manning_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- to_TO evaluate_VB the_DT parsing_VBG quality_NN on_IN sentences_NNS up_IN to_TO 70_CD tokens_NNS long_RB ._.
The_DT Arabic_JJ grammar_NN features_NNS come_VBP from_IN Green_NNP and_CC Manning_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- ,_, which_WDT contains_VBZ an_DT ablation_NN study_NN similar_JJ to_TO Table_NNP 2_CD ._.
Recently_RB ,_, Green_NNP and_CC Manning_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- demonstrated_VBD the_DT effectiveness_NN of_IN lattice-parsing_NN for_IN parsing_VBG Arabic_JJ ._.
One_PRP can_MD either_RB select_VB a_DT segmentation_NN path_NN prior_RB to_TO parsing_NN ,_, or_CC ,_, as_IN has_VBZ been_VBN recently_RB argued_VBN ,_, one_PRP can_MD let_VB the_DT parser_NN pick_VB a_DT segmentation_NN jointly_RB with_IN decoding_NN -LRB-_-LRB- Tsarfaty_NNP ,_, 2006_CD ;_: Cohen_NNP and_CC Smith_NNP ,_, 2007_CD ;_: Goldberg_NNP and_CC Tsarfaty_NNP ,_, 2008_CD ;_: Green_NNP and_CC Manning_NNP ,_, 2010_CD -RRB-_-RRB- ._.
In_IN practice_NN ,_, a_DT statistical_JJ component_NN is_VBZ required_VBN to_TO decide_VB on_IN the_DT correct_JJ morphological_JJ segmentation_NN ,_, that_WDT is_VBZ ,_, to_TO pick_VB out_RP the_DT correct_JJ path_NN through_IN the_DT lattice.This_NN may_MD be_VB done_VBN based_VBN on_IN linear_JJ local_JJ context_NN -LRB-_-LRB- Adler_NNP and_CC Elhadad_NNP ,_, 2006_CD ;_: Shacham_NNP and_CC Wintner_NNP ,_, 2007_CD ;_: Bar-haim_JJ et_FW al._FW ,_, 2008_CD ;_: Habash_NNP and_CC Rambow_NNP ,_, 2005_CD -RRB-_-RRB- ,_, or_CC jointly_RB with_IN parsing_NN -LRB-_-LRB- Tsarfaty_NNP ,_, 2006_CD ;_: Goldberg_NNP and_CC Tsarfaty_NNP ,_, 2008_CD ;_: Green_NNP and_CC Manning_NNP ,_, 2010_CD -RRB-_-RRB- ._.
Following_VBG Green_NNP and_CC Manning_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- and_CC others_NNS ,_, sentences_NNS headed_VBN by_IN X_NN nodes_NNS are_VBP deleted_VBN The_DT Stanford_NNP Arabic_NNP Phrase_NNP Structure_NN Treebank_NNP In_IN order_NN to_TO stay_VB compatible_JJ with_IN the_DT state_NN of_IN the_DT art_NN ,_, we_PRP provide_VBP the_DT constituency_NN data_NNS set_VBN with_IN most_JJS of_IN the_DT pre-processing_JJ steps_NNS of_IN Green_NNP and_CC Manning_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- We_PRP finally_RB remove_VB all_DT traces_NNS ,_, but_CC ,_, unlike_IN Green_NNP and_CC Manning_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- ,_, we_PRP keep_VBP all_DT function_NN tags_NNS ._.
Data_NNS Sets_NNS The_DT Arabic_JJ data_NN set_NN contains_VBZ two_CD tree_NN -_: banks_NNS derived_VBN from_IN the_DT LDC_NNP Penn_NNP Arabic_NNP Treebanks_NNPS -LRB-_-LRB- PATB_NN -RRB-_-RRB- -LRB-_-LRB- Maamouri_NNP et_FW al._FW ,_, 2004b_NN -RRB-_-RRB- Thus_RB for_IN any_DT automatic_JJ counting_NN scheme_NN some_DT constant_JJ shuffling_NN and_CC reshuffling_NN of_IN the_DT conjunct_NN order_NN needs_VBZ to_TO be_VB applied_VBN until_IN the_DT order_NN stabilizes_VBZ -LRB-_-LRB- see_VB also_RB -LSB-_-LRB- Kogure_NNP 1990_CD -RSB-_-RRB- -RRB-_-RRB- ._.
The_DT lazy_JJ copying_NN approach_NN -LRB-_-LRB- -LSB-_-LRB- Kogure_NNP ,_, 1990_CD -RSB-_-RRB- ,_, and_CC -LSB-_-LRB- Emele_NNP ,_, 1991_CD -RSB-_-RRB- for_IN lazy_JJ copying_NN in_IN TFS_NN with_IN historical_JJ backtracking_NN -RRB-_-RRB- copies_NNS only_RB overlapping_VBG parts_NNS of_IN the_DT structure_NN ._.
•_NN Data-Structure_NN Sharing_VBG A_NN more_RBR eNcient_JJ unification_NN algorithm_NN would_MD avoid_VB this_DT redundant_JJ copying_NN -LRB-_-LRB- copying_NN structures_NNS that_WDT can_MD be_VB shared_VBN by_IN the_DT input_NN and_CC resultant_JJ graphs_NNS -RRB-_-RRB- -LRB-_-LRB- Kogure_NNP ,_, 1990_CD -RRB-_-RRB- ._.
Kogure_NNP -LRB-_-LRB- 1990_CD -RRB-_-RRB- proposed_VBD a_DT lazy_JJ incremental_JJ copy_NN graph_NN -LRB-_-LRB- LING_NN -RRB-_-RRB- unification_NN that_WDT uses_VBZ dependency-directed_JJ eol_NN -RRB-_-RRB- yiug_NN PM_NN can_MD also_RB choose_VB among_IN different_JJ unification_NN algorithms_NNS that_WDT have_VBP been_VBN designed_VBN to_TO This_DT test_NN -_: grammar_NN is_VBZ based_VBN on_IN the_DT implementation_NN of_IN an_DT analysis_NN of_IN partial_JJ vP_NN topicalization_NN in_IN German_JJ -LRB-_-LRB- Hinrichs_NNP et_FW al._FW ,_, 1994_CD -RRB-_-RRB- in_IN the_DT Troll_NN system_NN -LRB-_-LRB- Gerdemann_NNP and_CC King_NNP ,_, 1994_CD -RRB-_-RRB- ._.
Gerdemann_NNP and_CC G6tz_NNP 's_POS Troll_NN system_NN -LRB-_-LRB- see_VB -LSB-_-LRB- G6Tz_NN 1993_CD -RSB-_-RRB- ,_, -LSB-_-LRB- GFRDEIVIANN_NNP AND_CC KING_NNP 1994_CD -RSB-_-RRB- and_CC -LSB-_-LRB- GERDEMANN_NNP -LRB-_-LRB- FC_NNP -RRB-_-RRB- -RSB-_-RRB- -RRB-_-RRB- employs_VBZ an_DT efficient_JJ refinement_NN of_IN RES_NN to_TO test_VB the_DT satisfiability_NN of_IN feature_NN structures.In_NN fact_NN ,_, Troll_NN represents_VBZ each_DT feature_NN structure_NN as_IN a_DT disjunction_NN of_IN the_DT resolvants_NNS of_IN the_DT feature_NN structure.Loosely_NN speaking_NN ,_, the_DT resolvants_NNS of_IN a_DT feature_NN structure_NN have_VBP the_DT same_JJ underlying_VBG finite_JJ state_NN automaton_NN as_IN the_DT feature_NN structure_NN ,_, and_CC differ_VBP only_RB in_IN their_PRP$ output_NN fllnction.Troll_NN exploits_VBZ this_DT property_NN to_TO represent_VB each_DT feature_NN structure_NN as_IN a_DT finite_JJ state_NN automaton_NN and_CC a_DT set_NN of_IN output_NN flmctions.The_NN '_'' 1_CD ¥_CD oll_NN unifier_NN is_VBZ closed_VBN on_IN these_DT representations.Thus_NN ,_, though_IN RES_NNP is_VBZ computationally_RB expensive_JJ ,_, Troll_NNP uses_VBZ RES_NNP only_RB during_IN compilation_NN ,_, never_RB during_IN run_NN time_NN ._.
449_CD PIION_NN ~_NN lleben_NN ,_, liebt_NN /_: -LSB-_-LRB- dl_NN VFORM_NN ~_CD bse_NN ,_, fill_NN -RCB-_-RRB- I_PRP ,_, el_FW SUBJ_FW -LSB-_-LRB- -RSB-_-RRB- f_LS rVFORM_NN bse_NN -RSB-_-RRB- -RSB-_-RRB- -RRB-_-RRB- -LSB-_-LRB- lieben_NN -_: -RSB-_-RRB- -LSB-_-LRB- AaG_NN ~_CD 2t_NN !_. -RSB-_-RRB- -RSB-_-RRB-
-LCB-_-LRB- rv_NN ,_, ,_, `_`` OaMbsol_NNP -RCB-_-RRB- s_NNS ,_, ,_, ,_, ,_, s_NNS ,_, ,_, d2_NN Another_DT example_NN of_IN where_WRB modularization_NN might_MD prove_VB useful_JJ is_VBZ in_IN the_DT treatment_NN of_IN typed_VBN feature_NN structures_NNS presented_VBN in_IN -LRB-_-LRB- Gerdemann_NNP and_CC King_NNP ,_, 1994_CD -RRB-_-RRB- ._.
Their_PRP$ approach_NN produces_VBZ a_DT set_NN of_IN feature_NN structures_NNS from_IN a_DT satisfiability_NN algorithm_NN such_JJ that_IN all_DT of_IN the_DT feature_NN structures_NNS have_VBP the_DT same_JJ shape_NN but_CC the_DT nodes_NNS may_MD be_VB labeled_VBN by_IN different_JJ types.They_NN then_RB collapse_NN this_DT set_VBN down_RP to_TO a_DT single_JJ feature_NN structure_NN where_WRB nodes_NNS are_VBP labeled_VBN with_IN dependent_JJ disjunctions_NNS of_IN types.Many_NN of_IN the_DT groups_NNS of_IN disjunctions_NNS in_IN their_PRP$ feature_NN structures_NNS can_MD be_VB made_VBN more_RBR efficient_JJ via_IN modularization_NN ._.
Hybrid_NN systems_NNS that_WDT combine_VBP the_DT approaches_NNS we_PRP have_VBP presented_VBN were_VBD also_RB developed_VBN and_CC illustrated_VBD the_DT interest_NN of_IN such_PDT a_DT combination_NN Thus_RB ,_, Table_NNP 1_CD confirms_VBZ the_DT fact_NN reported_VBN in_IN -LRB-_-LRB- Jobbins_NNP and_CC Evett_NNP ,_, 1998_CD -RRB-_-RRB- that_WDT using_VBG collocations_NNS together_RB with_IN word_NN recurrence_NN is_VBZ an_DT interesting_JJ approach_NN for_IN text_NN segmentation_NN ._.
In_IN earlier_JJR work_NN -LSB-_-LRB- 11_CD -RSB-_-RRB- a_DT text_NN segmentation_NN algorithm_NN was_VBD described_VBN that_IN captured_VBN all_DT types_NNS of_IN lexical_JJ cohesion_NN ties.To_NN automatically_RB find_VB ties_NNS between_IN pairwise_JJ words_NNS three_CD features_NNS were_VBD developed_VBN Hybrid_NN systems_NNS that_WDT combine_VBP the_DT approaches_NNS we_PRP have_VBP presented_VBN were_VBD also_RB developed_VBN and_CC illustrated_VBD the_DT interest_NN of_IN such_PDT a_DT combination_NN When_WRB no_DT external_JJ knowledge_NN is_VBZ used_VBN ,_, this_DT similarity_NN is_VBZ only_RB based_VBN on_IN the_DT strict_JJ reiteration_NN of_IN words.But_NN it_PRP can_MD be_VB enhanced_VBN by_IN taking_VBG into_IN account_NN semantic_JJ relations_NNS between_IN words.This_NNP was_VBD done_VBN for_IN instance_NN in_IN -LRB-_-LRB- Jobbins_NNP and_CC Evett_NNP ,_, 1998_CD -RRB-_-RRB- by_IN taking_VBG semantic_JJ relations_NNS from_IN Rogets_NNPS Thesaurus_NNP ._.
The_DT cohesion_NN in_IN the_DT part_NN of_IN text_NN delimited_VBN by_IN this_DT window_NN is_VBZ evaluated_VBN by_IN measuring_VBG the_DT word_NN reiteration_NN between_IN its_PRP$ two_CD sides.This_NN is_VBZ done_VBN in_IN our_PRP$ case_NN by_IN applying_VBG the_DT Dice_NNP coefficient_NN between_IN the_DT two_CD sides_NNS of_IN the_DT focus_NN window_NN ,_, following_VBG -LRB-_-LRB- Jobbins_NNP and_CC Evett_NNP ,_, 1998_CD -RRB-_-RRB- ._.
This_DT evaluation_NN is_VBZ also_RB a_DT weak_JJ point_NN as_IN card_NN -LRB-_-LRB- Wl_NN Wr_NN -RRB-_-RRB- only_RB relies_VBZ on_IN word_NN reiteration.As_NNS a_DT consequence_NN ,_, two_CD different_JJ words_NNS that_WDT respectively_RB belongs_VBZ to_TO Wl_NN and_CC Wr_NN but_CC also_RB belong_VBP to_TO the_DT same_JJ text_NN topic_NN can_MD not_RB contribute_VB l_NN r_NN to_TO the_DT identification_NN of_IN a_DT possible_JJ topical_JJ similarity_NN This_DT measure_NN was_VBD adopted_VBN instead_RB of_IN the_DT Cosine_NNP measure_NN used_VBN in_IN TextTiling_NN because_IN its_PRP$ definition_NN in_IN terms_NNS of_IN sets_NNS makes_VBZ it_PRP easier_JJR to_TO extend_VB for_IN taking_VBG into_IN account_NN other_JJ types_NNS of_IN relations_NNS ,_, as_IN in_IN -LRB-_-LRB- Jobbins_NNP and_CC Evett_NNP ,_, 1998_CD -RRB-_-RRB- ._.
In_IN fact_NN ,_, the_DT way_NN we_PRP use_VBP relations_NNS between_IN words_NNS is_VBZ closer_JJR to_TO -LRB-_-LRB- Jobbins_NNP and_CC Evett_NNP ,_, 1998_CD -RRB-_-RRB- ,_, even_RB if_IN the_DT relations_NNS in_IN this_DT work_NN come_VBN from_IN a_DT network_NN of_IN co-occurrences_NNS or_CC a_DT thesaurus_NN rather_RB than_IN from_IN text_NN topics.In_NN both_CC cases_NNS the_DT similarity_NN of_IN two_CD text_NN units_NNS is_VBZ determined_VBN by_IN the_DT proportion_NN of_IN their_PRP$ words_NNS that_WDT are_VBP part_NN of_IN a_DT relation_NN across_IN the_DT two_CD units_NNS ._.
This_DT network_NN could_MD also_RB be_VB used_VBN more_RBR directly_RB for_IN topic_NN segmentation_NN as_IN in_IN -LRB-_-LRB- Job_NNP -_: bins_NNS and_CC Evett_NNP ,_, 1998_CD -RRB-_-RRB- ._.
In_IN other_JJ words_NNS ,_, meaning_NN of_IN UW_NNP can_MD be_VB found_VBN generally_RB through_IN co_NN -_: occurrence_NN words_NNS -LSB-_-LRB- 5_CD -RSB-_-RRB- ._.
In_IN information_NN retrieval_NN ,_, to_TO segment_NN a_DT long_JJ document_NN into_IN distinct_JJ topics_NNS is_VBZ useful_JJ because_IN only_RB the_DT topical_JJ segments_NNS relevant_JJ to_TO the_DT users_NNS needs_NNS are_VBP retrieved_VBN -LSB-_-LRB- 1_CD -RSB-_-RRB- ._.
Indeed_RB ,_, the_DT primary_JJ goal_NN of_IN semantic_JJ relations_NNS is_VBZ obviously_RB to_TO ensure_VB that_IN two_CD semantically_RB related_JJ words_NNS ,_, e.g._FW ,_, car_NN and_CC drive_NN ,_, contribute_VBP to_TO the_DT lexical_JJ cohesion_NN ,_, thus_RB avoiding_VBG erroneous_JJ topic_NN boundaries_NNS between_IN two_CD such_JJ words.These_NN different_JJ methods_NNS can_MD use_VB semantic_JJ relations_NNS that_WDT are_VBP manually_RB defined_VBN by_IN experts_NNS ,_, as_IN in_IN Morris_NNP and_CC Hirst_NNP -LRB-_-LRB- 1991_CD -RRB-_-RRB- ,_, or_CC extracted_VBN automatically_RB from_IN corpora_NN -LRB-_-LRB- Ferret_NN ,_, 2006_CD ;_: Jobbins_NNP and_CC Evett_NNP ,_, 1998_CD -RRB-_-RRB- ._.
In_IN that_DT paper_NN ,_, QG_NN was_VBD applied_VBN to_TO word_NN alignment_NN and_CC has_VBZ since_IN found_VBN applications_NNS in_IN question_NN answering_NN -LRB-_-LRB- Wang_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ,_, paraphrase_NN detection_NN -LRB-_-LRB- Das_NN and_CC Smith_NNP ,_, 2009_CD -RRB-_-RRB- ,_, and_CC machine_NN translation_NN -LRB-_-LRB- Gimpel_NN and_CC Smith_NNP ,_, 2009_CD -RRB-_-RRB- ._.
We_PRP present_VBP a_DT quasi-synchronous_JJ dependency_NN grammar_NN -LRB-_-LRB- Smith_NNP and_CC Eisner_NNP ,_, 2006_CD -RRB-_-RRB- for_IN machine_NN translation_NN in_IN which_WDT the_DT leaves_NNS of_IN the_DT tree_NN are_VBP phrases_NNS rather_RB than_IN words_NNS as_IN in_IN previous_JJ work_NN -LRB-_-LRB- Gimpel_NN and_CC Smith_NNP ,_, 2009_CD -RRB-_-RRB- ._.
We_PRP previously_RB applied_VBD quasi-synchronous_JJ grammar_NN to_TO machine_NN translation_NN -LRB-_-LRB- Gimpel_NN and_CC Smith_NNP ,_, 2009_CD -RRB-_-RRB- ,_, but_CC that_DT system_NN performed_VBN translation_NN fundamentally_RB at_IN the_DT word_NN level_NN ._.
We_PRP denote_VBP this_DT grammar_NN by_IN Gs_NN ,_, s_NNS ;_: its_PRP$ -LRB-_-LRB- weighted_JJ -RRB-_-RRB- language_NN is_VBZ the_DT set_NN of_IN translations_NNS of_IN s._NN Quasi-synchronous_JJ grammar_NN makes_VBZ no_DT restrictions_NNS on_IN the_DT form_NN of_IN the_DT target_NN monolingual_JJ grammar_NN ,_, though_IN dependency_NN grammars_NNS have_VBP been_VBN used_VBN in_IN most_JJS previous_JJ applications_NNS of_IN QG_NN -LRB-_-LRB- Wang_NNP et_FW al._FW ,_, 2007_CD ;_: Das_NNP and_CC Smith_NNP ,_, 2009_CD ;_: Smith_NNP and_CC Eisner_NNP ,_, 2009_CD -RRB-_-RRB- ,_, including_VBG previous_JJ work_NN in_IN MT_NNP -LRB-_-LRB- Smith_NNP and_CC Eisner_NNP ,_, 2006_CD ;_: Gimpel_NNP and_CC Smith_NNP ,_, 2009_CD -RRB-_-RRB- ._.
For_IN a_DT QPDG_NNP model_NN ,_, decoding_VBG consists_VBZ of_IN finding_VBG the_DT highest-scoring_JJ tuple_NN -LRB-_-LRB- t_NN ,_, ,_, ,_, ,_, a_DT -RRB-_-RRB- for_IN an_DT in_IN put_JJ sentence_NN s_NNS and_CC its_PRP$ parse_NN s_NNS ,_, i.e._FW ,_, finding_VBG the_DT most_RBS probable_JJ derivation_NN under_IN the_DT s/s-specific_JJ grammar_NN Gs_NN ,_, s_NNS ._.
We_PRP follow_VBP Gimpel_NNP and_CC Smith_NNP -LRB-_-LRB- 2009_CD -RRB-_-RRB- in_IN constructing_VBG a_DT lattice_NN to_TO represent_VB Gs_NN ,_, s_NNS and_CC using_VBG lattice_NN parsing_NN to_TO search_VB for_IN the_DT best_JJS derivation_NN ,_, but_CC we_PRP construct_VBP the_DT lattice_NN differently_RB and_CC employ_VB a_DT coarse-to_NN -_: fine_JJ strategy_NN -LRB-_-LRB- Petrov_NNP ,_, 2009_CD -RRB-_-RRB- to_TO speed_VB up_RP decoding_NN ._.
-LRB-_-LRB- 2007_CD -RRB-_-RRB- ArEn_NN -LSB-_-LRB- UN_NNP ,_, NIST_NNP 06_CD -RSB-_-RRB- -LSB-_-LRB- L_NN -RSB-_-RRB- SL_NNP Gimpel_NNP and_CC Smith_NNP -LRB-_-LRB- 2009_CD -RRB-_-RRB- present_VBP an_DT MT_NN framework_NN based_VBN on_IN lattice_NN parsing_VBG with_IN a_DT quasi-synchronous_JJ grammar_NN that_WDT can_MD incorporate_VB arbitrary_JJ features_NNS from_IN both_DT source_NN and_CC target_NN sentences_NNS -LRB-_-LRB- Table_NNP 5_CD -RRB-_-RRB- ._.
Gimpel_NNP &_CC Smith_NNP -LRB-_-LRB- 2009_CD ;_: 2011_CD -RRB-_-RRB- treat_NN translation_NN as_IN a_DT monolingual_JJ dependency_NN parsing_NN problem_NN ,_, creating_VBG a_DT dependency_NN structure_NN over_IN the_DT translation_NN during_IN decoding_NN ._.
Log-linear_JJ translation_NN models_NNS -LRB-_-LRB- instead_RB of_IN MLE_NN -RRB-_-RRB- with_IN rich_JJ feature_NN sets_NNS are_VBP used_VBN also_RB in_IN -LRB-_-LRB- Ittycheriah_NN and_CC Roukos_NNP ,_, 2007_CD -RRB-_-RRB- and_CC -LRB-_-LRB- Gimpel_NNP andSmith_NNP ,_, 2009_CD -RRB-_-RRB- ;_: the_DT idea_NN can_MD be_VB traced_VBN back_RB to_TO -LRB-_-LRB- Pap_NN ineni_NNS et_FW al._FW ,_, 1997_CD -RRB-_-RRB- ._.
Many_JJ translation_NN models_NNS use_VBP such_JJ knowledge_NN before_IN decoding_VBG -LRB-_-LRB- Xia_NNP and_CC McCord_NNP ,_, 2004_CD -RRB-_-RRB- and_CC during_IN decoding_NN -LRB-_-LRB- Birch_NNP et_FW al._FW ,_, 2007_CD ;_: Gimpel_NNP and_CC Smith_NNP ,_, 2009_CD ;_: Koehn_NNP and_CC Hoang_NNP ,_, 2007_CD ;_: Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ,_, but_CC they_PRP are_VBP limited_VBN to_TO simpler_JJR features_NNS for_IN practical_JJ reasons_NNS ,_, often_RB restricted_JJ to_TO conditioning_NN left-to_NN -_: right_NN on_IN the_DT target_NN sentence_NN ._.
Zhao_NNP and_CC Gildea_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- explored_VBD a_DT model_NN with_IN a_DT word_NN order_NN and_CC fertility_NN model_NN as_IN described_VBN above_IN ,_, but_CC based_VBN their_PRP$ work_NN on_IN the_DT EM_NNP algorithm_NN ,_, using_VBG Gibbs_NNP sampling_NN only_RB for_IN approximating_VBG the_DT expectations_NNS ._.
Recent_JJ work_NN -LRB-_-LRB- Zhao_NNP and_CC Gildea_NNP ,_, 2010_CD -RRB-_-RRB- described_VBD an_DT extension_NN to_TO the_DT HMM_NN with_IN a_DT fertility_NN model_NN ,_, using_VBG MCMC_NN techniques_NNS for_IN parameter_NN estimation_NN ._.
,_, fJ_NN and_CC word_NN alignment_NN vectors_NNS a_DT =_JJ estimate_NN the_DT posterior_JJ distribution_NN using_VBG Markov_NNP chain_NN Monte_NNP Carlo_NNP methods_NNS such_JJ as_IN Gibbs_NNP sampling_NN -LRB-_-LRB- Zhao_NNP and_CC Gildea_NNP ,_, 2010_CD -RRB-_-RRB- ._.
Following_VBG prior_JJ work_NN -LRB-_-LRB- Zhao_NNP and_CC Gildea_NNP ,_, 2010_CD -RRB-_-RRB- ,_, we_PRP augment_VBP the_DT standard_JJ HMM_NN with_IN a_DT fertility_NN distribution_NN ._.
Prior_JJ work_NN addressed_VBD this_DT by_IN using_VBG the_DT single_JJ parameter_NN Poisson_NNP distribution_NN ,_, forcing_VBG infrequent_JJ words_NNS to_TO share_VB a_DT global_JJ parameter_NN estimated_VBN from_IN the_DT fertility_NN of_IN all_DT words_NNS in_IN the_DT corpus_NN -LRB-_-LRB- Zhao_NNP and_CC Gildea_NNP ,_, 2010_CD -RRB-_-RRB- ._.
The_DT prior_JJ work_NN compared_VBN Viterbi_NNP with_IN a_DT form_NN of_IN local_JJ search_NN -LRB-_-LRB- sampling_NN repeatedly_RB and_CC keeping_VBG the_DT max_NN -RRB-_-RRB- ,_, finding_VBG little_JJ difference_NN between_IN the_DT two_CD -LRB-_-LRB- Zhao_NNP and_CC Gildea_NNP ,_, 2010_CD -RRB-_-RRB- ._.
Zhao_NNP and_CC Gildea_NNP -LSB-_-LRB- 15_CD -RSB-_-RRB- use_NN sampling_NN in_IN their_PRP$ proposed_VBN fertility_NN extensions_NNS to_TO IBM_NNP Model_NNP 1_CD and_CC HMM_NNP ,_, but_CC they_PRP do_VBP not_RB place_VB any_DT prior_JJ on_IN the_DT parameters_NNS ._.
Zhao_NNP proposes_VBZ a_DT brief_JJ fertility_NN based_VBN HMM_NNP model_NN ,8_CD which_WDT also_RB decreases_VBZ the_DT complexity_NN of_IN Model_NNP A_NNP Fully_RB Bayesian_JJ Inference_NN for_IN Word_NNP Alignment_NN 93_CD Table_NNP 2_CD ._.
For_IN models_NNS with_IN fertility_NN computing_VBG the_DT expectations_NNS instead_RB becomes_VBZ intractable_JJ ,_, and_CC previous_JJ authors_NNS have_VBP solved_VBN this_DT by_IN using_VBG approximative_NN 2_CD The_DT approximation_NN consists_VBZ of_IN ignoring_VBG the_DT dependence_NN between_IN the_DT two_CD draws_VBZ from_IN the_DT word_NN order_NN jump_NN distribution_NN -LRB-_-LRB- second_JJ and_CC third_JJ factors_NNS -RRB-_-RRB- .134_CD R._NNP stling_VBG ,_, J._NNP Tiedemann_NNP Ecient_NNP Word_NNP Alignment_NN with_IN MCMC_NN -LRB-_-LRB- 125146_CD -RRB-_-RRB- greedy_JJ optimization_NN techniques_NNS -LRB-_-LRB- Brown_NNP et_FW al._FW ,_, 1993_CD -RRB-_-RRB- or_CC local_JJ Gibbs_NNP sampling_NN -LRB-_-LRB- Zhao_NNP and_CC Gildea_NNP ,_, 2010_CD -RRB-_-RRB- ._.
Zhao_NNP and_CC Gildea_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- instead_RB chose_VBD to_TO use_VB Gibbs_NNP sampling_NN to_TO approximate_JJ these_DT expectations_NNS ,_, which_WDT allowed_VBD them_PRP to_TO perform_VB efficient_JJ inference_NN with_IN EM_NN for_IN a_DT HMM_NNP model_NN with_IN fertility_NN ._.
Another_DT interesting_JJ extension_NN of_IN the_DT HMM_NNP alignment_NN is_VBZ presented_VBN in_IN Zhao_NNP and_CC Gildea_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- who_WP added_VBD a_DT fertility_NN distribution_NN to_TO the_DT HMM_NNP ._.
Recent_JJ work_NN -LRB-_-LRB- Zhao_NNP and_CC Gildea_NNP ,_, 2010_CD -RRB-_-RRB- described_VBD an_DT extension_NN to_TO the_DT HMM_NN with_IN a_DT fertility_NN model_NN ,_, using_VBG MCMC_NN techniques_NNS for_IN parameter_NN es_VBZ timation_NN ._.
Following_VBG prior_JJ work_NN -LRB-_-LRB- Zhao_NNP and_CC Gildea_NNP ,_, 2010_CD -RRB-_-RRB- ,_, we_PRP augment_VBP the_DT standard_JJ HMM_NN with_IN a_DT fertility_NN dis_NN tribution_NN ._.
I_PRP Pr_VBP -LRB-_-LRB- f_FW ,_, ale_NN -RRB-_-RRB- =p_NN -LRB-_-LRB- JII_NN -RRB-_-RRB- ITP_NN -LRB-_-LRB- cPilei_NN -RRB-_-RRB- estimate_VBP the_DT posterior_JJ distribution_NN using_VBG Markov_NNP chain_NN Monte_NNP Carlo_NNP methods_NNS such_JJ as_IN Gibbs_NNP sam_NN pling_NN -LRB-_-LRB- Zhao_NNP and_CC Gildea_NNP ,_, 2010_CD -RRB-_-RRB- ._.
Prior_JJ work_NN addressed_VBD this_DT by_IN using_VBG the_DT single_JJ parameter_NN Pois_NNP son_NN distribution_NN ,_, forcing_VBG infrequent_JJ words_NNS to_TO share_VB a_DT global_JJ parameter_NN estimated_VBN from_IN the_DT fertility_NN of_IN all_DT words_NNS in_IN the_DT corpus_NN -LRB-_-LRB- Zhao_NNP and_CC Gildea_NNP ,_, 2010_CD -RRB-_-RRB- ._.
The_DT prior_JJ work_NN compared_VBN Viterbi_NNP with_IN a_DT form_NN of_IN local_JJ search_NN -LRB-_-LRB- sampling_NN repeatedly_RB and_CC keeping_VBG the_DT max_NN -RRB-_-RRB- ,_, finding_VBG little_JJ difference_NN between_IN the_DT two_CD -LRB-_-LRB- Zhao_NNP and_CC Gildea_NNP ,_, 2010_CD -RRB-_-RRB- ._.
The_DT sequence-based_JJ model_NN is_VBZ easier_JJR to_TO implement_VB ,_, and_CC recent_JJ experiments_NNS have_VBP shown_VBN that_IN appropriately_RB modified_VBN sequence-based_JJ model_NN can_MD produce_VB comparable_JJ performance_NN with_IN fertility-based_JJ models_NNS -LRB-_-LRB- Lopez_NNP and_CC Resnik_NNP ,_, 2005_CD ;_: Liang_NNP et_FW al._FW ,_, 2006_CD ;_: DeNero_NNP and_CC Klein_NNP ,_, 2007_CD ;_: Zhao_NNP and_CC Gildea_NNP ,_, 2010_CD ;_: Bansal_NNP et_FW al._FW ,_, 2011_CD -RRB-_-RRB- ._.
Our_PRP$ Gibbs_NNP sampler_NN is_VBZ similar_JJ to_TO the_DT MCMC_NNP algorithm_NN in_IN Zhao_NNP and_CC Gildea_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- ,_, but_CC we_PRP assume_VBP Dirichlet_JJ priors_NNS when_WRB sampling_NN model_NN parameters_NNS and_CC take_VB a_DT different_JJ sampling_NN approach_NN based_VBN on_IN the_DT source_NN side_NN dependency_NN tree_NN ._.
More_RBR recently_RB ,_, Lee_NNP et_FW al._FW -LRB-_-LRB- 2010_CD -RRB-_-RRB- presented_VBD a_DT new_JJ type-based_JJ model_NN ,_, and_CC also_RB reported_VBD very_RB good_JJ results_NNS ._.
As_IN in_IN previous_JJ work_NN -LRB-_-LRB- Lee_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- ,_, we_PRP find_VBP that_IN the_DT one-class-per-type_JJ restriction_NN boosts_VBZ performance_NN considerably_RB over_IN a_DT comparable_JJ token_JJ -_: based_VBN model_NN and_CC yields_NNS results_VBZ that_DT are_VBP comparable_JJ to_TO state-of-the-art_JJ even_RB without_IN the_DT use_NN of_IN morphology_NN or_CC alignment_NN features_NNS ._.
2_CD One_CD could_MD approximate_JJ this_DT likelihood_NN term_NN by_IN assuming_VBG independence_NN between_IN all_DT nj_NN feature_NN tokens_NNS of_IN word_NN type_NN j_NN ._.
This_DT is_VBZ the_DT approach_NN taken_VBN by_IN Lee_NNP et_FW al._FW -LRB-_-LRB- 2010_CD -RRB-_-RRB- ._.
vised_VBN POS_NN induction_NN algorithm_NN -LRB-_-LRB- Lee_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- Unsupervised_JJ induction_NN of_IN POS_NN taggers_NNS offers_VBZ the_DT possibility_NN of_IN avoiding_VBG costly_JJ annotation_NN ,_, but_CC despite_IN recent_JJ progress_NN ,_, the_DT accuracy_NN of_IN unsupervised_JJ POS_NN taggers_NNS still_RB falls_VBZ far_RB behind_IN supervised_JJ systems_NNS ,_, and_CC is_VBZ not_RB suitable_JJ for_IN most_JJS applications_NNS -LRB-_-LRB- Berg_NN -_: Kirkpatrick_NNP et_FW al._FW ,_, 2010_CD ;_: GracÂ_NN ¸_CD a_DT et_FW al._FW ,_, 2011_CD ;_: Lee_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- ._.
Systems_NNPS for_IN inducing_VBG syntactic_JJ categories_NNS often_RB make_VBP use_NN of_IN morpheme-like_JJ features_NNS ,_, such_JJ as_IN word-final_JJ characters_NNS -LRB-_-LRB- Smith_NNP and_CC Eisner_NNP ,_, 2005_CD ;_: Haghighi_NNP and_CC Klein_NNP ,_, 2006_CD ;_: Berg-Kirkpatrick_NNP et_FW al._FW ,_, 2010_CD ;_: Lee_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- Recently_RB Lee_NNP et_FW al._FW -LRB-_-LRB- 2010_CD -RRB-_-RRB- combined_VBN the_DT one_CD class_NN per_IN word_NN type_NN constraint_NN -LRB-_-LRB- Brown_JJ et_FW al._FW ,_, 1992_CD -RRB-_-RRB- in_IN a_DT HMM_NN with_IN a_DT Dirichlet_NNP prior_RB to_TO achieve_VB both_DT forms_NNS of_IN sparsity.However_NN this_DT work_NN approximated_VBD the_DT derivation_NN of_IN the_DT Gibbs_NNP sampler_NN -LRB-_-LRB- omitting_VBG the_DT interdependence_NN between_IN events_NNS when_WRB sampling_NN from_IN a_DT collapsed_JJ model_NN -RRB-_-RRB- ,_, resulting_VBG in_IN a_DT model_NN which_WDT underperformed_VBD Brown_NNP et_FW al._FW -LRB-_-LRB- 1992_CD -RRB-_-RRB- â_RB $_$ ™_CD s_NNS one-class_JJ HMM_NNP ._.
Similar_JJ constraints_NNS have_VBP been_VBN developed_VBN for_IN part-of-speech_JJ tagging_NN -LRB-_-LRB- Lee_NNP et_FW al._FW ,_, 2010_CD ;_: Christodoulopoulos_NNP et_FW al._FW ,_, 2011_CD -RRB-_-RRB- Here_RB ,_, W_NN t_NN refers_VBZ to_TO the_DT set_NN of_IN word_NN types_NNS that_WDT are_VBP generated_VBN by_IN tag_NN t_NN ._.
In_IN other_JJ words_NNS ,_, conditioned_VBN on_IN tag_NN t_NN ,_, we_PRP can_MD only_RB generate_VB word_NN w_NN from_IN the_DT set_NN of_IN word_NN types_NNS in_IN W_NNP t_NN which_WDT is_VBZ generated_VBN earlier_JJR -LRB-_-LRB- Lee_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- ._.
Second_RB ,_, learning_VBG categories_NNS has_VBZ been_VBN cast_VBN as_IN unsupervised_JJ part-of-speech_JJ tagging_NN task_NN -LRB-_-LRB- recent_JJ work_NN includes_VBZ Ravi_NNP and_CC Knight_NNP -LRB-_-LRB- 2009_CD -RRB-_-RRB- ,_, Lee_NNP et_FW al._FW -LRB-_-LRB- 2010_CD -RRB-_-RRB- ,_, Lamar_NNP et_FW al._FW ._.
Current_JJ approaches_NNS have_VBP used_VBN clustering_NN -LRB-_-LRB- Dorow_NN and_CC Widdows_NNP ,_, 2003_CD ;_: Klapaftis_NNP and_CC Manandhar_NNP ,_, 2008_CD -RRB-_-RRB- or_CC statistical_JJ graph_NN models_NNS -LRB-_-LRB- Klapaftis_NN and_CC Manandhar_NNP ,_, 2010_CD -RRB-_-RRB- to_TO identify_VB sense-specific_JJ subgraphs_NNS ._.
Dorow_NNP and_CC Widdows_NNP -LRB-_-LRB- 2003_CD -RRB-_-RRB- use_VBP the_DT BNC_NN to_TO build_VB a_DT cooccurrencegraph_NN for_IN nouns_NNS ,_, based_VBN on_IN a_DT co-occurrence_NN frequency_NN threshold.They_NN perform_VB Markov_NNP clustering_NN on_IN this_DT graph_NN ._.
The_DT algorithm_NN in_IN -LRB-_-LRB- Dorow_NNP and_CC Widdows_NNP ,_, 2003_CD -RRB-_-RRB- represented_VBN target_NN noun_NN word_NN ,_, its_PRP$ neighbors_NNS and_CC their_PRP$ relationships_NNS using_VBG a_DT graph_NN in_IN which_WDT each_DT node_NN denoted_VBD a_DT noun_NN and_CC two_CD nodes_NNS had_VBD an_DT edge_NN between_IN them_PRP if_IN they_PRP co-occurred_VBD with_IN more_JJR than_IN a_DT given_VBN number_NN of_IN times_NNS ._.
Then_RB senses_NNS of_IN target_NN word_NN were_VBD iteratively_RB learned_VBN by_IN clustering_VBG the_DT local_JJ graph_NN of_IN similar_JJ words_NNS around_IN target_NN word.Their_NN algorithm_NN required_VBD a_DT threshold_NN as_IN input_NN ,_, which_WDT controlled_VBD the_DT number_NN of_IN senses_NNS ._.
Another_DT graph-based_JJ method_NN is_VBZ presented_VBN in_IN -LRB-_-LRB- Dorow_NNP and_CC Widdows_NNP ,_, 2003_CD -RRB-_-RRB- ._.
They_PRP extract_VBP onlynoun_JJ neighbours_NNS that_WDT appear_VBP in_IN conjunctions_NNS or_CC dis-junctions_NNS with_IN the_DT target_NN word.Additionally_RB ,_, theyextract_JJ second-order_NN co-occurrences_NNS ._.
The_DT last_JJ trend_NN ,_, explored_VBN by_IN -LRB-_-LRB- Véronis_NNP ,_, 2003_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Dorow_NNP and_CC Widdows_NNP ,_, 2003_CD -RRB-_-RRB- and_CC -LRB-_-LRB- Rapp_NNP ,_, 2003_CD -RRB-_-RRB- ,_, starts_VBZ from_IN the_DT cooccurrents_NNS of_IN a_DT word_NN recorded_VBN from_IN a_DT corpus_NN and_CC builds_VBZ its_PRP$ senses_NNS by_IN gathering_VBG its_PRP$ cooccurrents_NNS according_VBG to_TO their_PRP$ similarity_NN or_CC their_PRP$ dissimilarity_NN ._.
This_DT method_NN ,_, as_IN the_DT ones_NNS presented_VBN in_IN -LRB-_-LRB- Véronis_NNP ,_, 2003_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Dorow_NNP and_CC Widdows_NNP ,_, 2003_CD -RRB-_-RRB- and_CC -LRB-_-LRB- Rapp_NNP ,_, 2003_CD -RRB-_-RRB- ,_, relies_VBZ on_IN the_DT following_VBG hypothesis_NN In_IN our_PRP$ case_NN ,_, we_PRP chose_VBD a_DT more_RBR general_JJ approach_NN by_IN working_VBG at_IN the_DT level_NN of_IN a_DT similarity_NN graph_NN From_IN a_DT global_JJ viewpoint_NN ,_, these_DT two_CD differences_NNS lead_VBP -LRB-_-LRB- Véronis_NNP ,_, 2003_CD -RRB-_-RRB- and_CC -LRB-_-LRB- Dorow_NNP and_CC Widdows_NNP ,_, 2003_CD -RRB-_-RRB- to_TO build_VB finer_JJR senses_NNS than_IN ours_JJ ._.
The_DT methodology_NN of_IN Dorow_NNP and_CC Widdows_NNP -LRB-_-LRB- 2003_CD -RRB-_-RRB- was_VBD adopted_VBN This_DT unsupervised_JJ discovery_NN process_NN produces_VBZ a_DT sense_NN inventory_NN where_WRB the_DT number_NN of_IN senses_NNS is_VBZ corpus-driven_JJ and_CC where_WRB senses_NNS may_MD reflect_VB additional_JJ usages_NNS not_RB present_VB in_IN a_DT predefined_JJ sense_NN inventory_NN ,_, such_JJ as_IN those_DT for_IN medicine_NN or_CC law_NN -LRB-_-LRB- Dorow_NN and_CC Widdows_NNP ,_, 2003_CD -RRB-_-RRB- ._.
Similar_JJ to_TO the_DT approach_NN as_IN presented_VBN in_IN -LRB-_-LRB- Dorow_NNP and_CC Widdows_NNP ,_, 2003_CD -RRB-_-RRB- we_PRP construct_VBP a_DT word_NN graph.Dorow_NN and_CC Widdows_NNS construct_VBP a_DT graph_NN for_IN a_DT target_NN word_NN w_NN by_IN taking_VBG the_DT sub-graph_NN induced_VBN by_IN the_DT neighborhood_NN of_IN w_NN -LRB-_-LRB- without_IN w_NN -RRB-_-RRB- and_CC clustering_NN it_PRP with_IN MCL_NN ._.
Recently_RB ,_, open-source_NN tools_NNS have_VBP been_VBN released_VBN The_DT rules_NNS that_WDT are_VBP learned_VBN are_VBP in_IN the_DT format_NN of_IN so-called_JJ phonological_JJ replacement_NN rules_NNS -LRB-_-LRB- Beesley_NNP and_CC Karttunen_NNP ,_, 2002_CD -RRB-_-RRB- which_WDT we_PRP have_VBP later_RB converted_VBN into_IN equivalent_JJ finite-state_JJ transducers_NNS using_VBG the_DT freely_RB available_JJ foma_NN toolkit_NN -LRB-_-LRB- Hulden_NNP ,_, 2009a_NN -RRB-_-RRB- ._.
The_DT syllable_JJ counter_NN is_VBZ implemented_VBN using_VBG the_DT foma_NN software_NN -LRB-_-LRB- Hulden_NNP ,_, 2009_CD -RRB-_-RRB- ,_, and_CC the_DT implementation_NN -LRB-_-LRB- Hulden_NNP ,_, 2006_CD -RRB-_-RRB- can_MD be_VB found_VBN on_IN the_DT homepage_NN of_IN Figure_NNP 1_CD Since_IN the_DT question_NN of_IN transducer_NN functionality_NN is_VBZ known_VBN to_TO be_VB decidable_JJ -LRB-_-LRB- Blattner_NNP and_CC Head_NNP ,_, 1977_CD -RRB-_-RRB- ,_, and_CC an_DT efficient_JJ algorithm_NN is_VBZ given_VBN in_IN Hulden_NN -LRB-_-LRB- 2009a_NN -RRB-_-RRB- ,_, which_WDT is_VBZ included_VBN in_IN foma_NN -LRB-_-LRB- with_IN the_DT command_NN test_NN functional_JJ -RRB-_-RRB- we_PRP can_MD address_VB this_DT question_NN by_IN calculating_VBG the_DT above_JJ for_IN each_DT constraint_NN ,_, if_IN necessary_JJ ,_, and_CC then_RB permute_VB the_DT violation_NN markers_NNS until_IN the_DT above_JJ transducer_NN is_VBZ functional_JJ ._.
Foma_NN -LRB-_-LRB- Hulden_NNP ,_, 2009_CD -RRB-_-RRB- is_VBZ a_DT freely_RB available2_NN toolkit_NN that_WDT allows_VBZ to_TO both_DT build_VB and_CC parse_VB FS_NNP automata_NN and_CC transducers_NNS ._.
This_DT verb_VBP chain_NN transfer_NN module_NN is_VBZ implemented_VBN as_IN a_DT series_NN of_IN ordered_VBN replacement_NN rules_NNS -LRB-_-LRB- Beesley_NNP and_CC Karttunen_NNP ,_, 2003_CD -RRB-_-RRB- using_VBG the_DT foma_NN finite-state_JJ toolkit_NN -LRB-_-LRB- Hulden_NNP ,_, 2009_CD -RRB-_-RRB- ._.
In_IN the_DT work_NN presented_VBN here_RB ,_, we_PRP have_VBP reimplemented_VBN and_CC expanded_VBN the_DT original_JJ rules_NNS written_VBN for_IN XFST_NN with_IN the_DT foma2_NN toolkit_NN -LRB-_-LRB- Hulden_NNP ,_, 2009_CD -RRB-_-RRB- ._.
This_DT can_MD be_VB then_RB be_VB used_VBN in_IN spell_NN checking_NN applications_NNS ,_, for_IN example_NN ,_, by_IN integrating_VBG the_DT lexicon_NN with_IN weighted_JJ transduc_NN ers_NNPS reflecting_VBG frequency_NN information_NN and_CC error_NN models_NNS -LRB-_-LRB- Hulden_NNP ,_, 2009a_NN ;_: Pirinen_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- ._.
Its_PRP$ weight_NN twij_NN is_VBZ calculated_VBN by_IN tf_NN ·_NN idf_NN -LRB-_-LRB- Otterbacher_NN et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ._.
Component_NN relevance_NN scores_NNS are_VBP calculated_VBN using_VBG Term_NNP Frequency_NNP ×_NNP Inverse_NNP Sentence_NNP Frequency_NNP -LRB-_-LRB- TF_NN ×_CD ISF_NN -RRB-_-RRB- -LRB-_-LRB- Otterbacher_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- To_TO apply_VB LexRank_NNP to_TO query-focused_JJ context_NN ,_, a_DT topic-sensitive_JJ version_NN of_IN LexRank_NNP isproposed_VBN in_IN -LRB-_-LRB- Otterbacher_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ._.
This_DT approach_NN is_VBZ similar_JJ in_IN spirit_NN to_TO the_DT iterative_JJ computational_JJ approaches_NNS of_IN the_DT Hidden_NNP Markov_NNP Models_NNS -LRB-_-LRB- Kupiec_NNP ,_, 1989_CD In_IN -LSB-_-LRB- Kupiec_NNP ,_, 1989a_NN -RSB-_-RRB- ,_, networks_NNS are_VBP used_VBN to_TO selectively_RB augment_VB the_DT context_NN in_IN a_DT basic_JJ first_JJ -_: order_NN model_NN ,_, rather_RB than_IN using_VBG uniformly_RB second-order_JJ dependencies_NNS ._.
adequate_JJ training_NN requires_VBZ processing_NN from_IN tens_NNS of_IN thousands_NNS to_TO hundreds_NNS of_IN thousands_NNS of_IN tokens_NNS -LSB-_-LRB- Kupiec_NNP ,_, 1989a_NN -RSB-_-RRB- ._.
Kupiec_NN -LRB-_-LRB- 1989_CD -RRB-_-RRB- has_VBZ experimented_VBN with_IN the_DT inclusion_NN of_IN networks_NNS to_TO model_NN mixed-order_NN dependencies_NNS ._.
The_DT vocabulary_NN entry_NN may_MD be_VB a_DT word_NN or_CC an_DT equivalence_JJ class_NN based_VBN on_IN categories_NNS -LRB-_-LRB- Kupiec_NNP ,_, 1989_CD -RRB-_-RRB- ._.
In_IN a_DT practical_JJ tagger_NN -LRB-_-LRB- Kupiec_NNP ,_, 1989_CD -RRB-_-RRB- ,_, only_RB the_DT most_RBS frequent_JJ 100_CD words_NNS are_VBP lexicalized_VBN ._.
One_CD area_NN in_IN which_WDT the_DT statistical_JJ approach_NN has_VBZ done_VBN par_JJ ticularly_RB well_RB is_VBZ automatic_JJ part_NN of_IN speech_NN tagging_NN ,_, as_IN signing_VBG each_DT word_NN in_IN an_DT input_NN sentence_NN its_PRP$ proper_JJ part_NN of_IN speech_NN -LRB-_-LRB- 1_CD ,_, 2_CD ,_, 3_CD ,_, 4_CD ,_, 6_CD ,_, 9_CD ,_, 11_CD ,_, 12_CD -RSB-_-RRB- ._.
Instead_RB ,_, only_RB common_JJ words_NNS are_VBP represented_VBN individually_RB ;_: the_DT rest_NN of_IN the_DT words_NNS in_IN the_DT dictionary_NN are_VBP partitioned_VBN into_IN word_NN equivalence_JJ classes_NNS -LRB-_-LRB- Kupiec_NNP ,_, 1989_CD -RRB-_-RRB- This_DT sparked_VBD intensive_JJ research_NN on_IN unsupervised_JJ acquisition_NN of_IN entailment_NN rules_NNS -LRB-_-LRB- and_CC similarly_RB paraphrases_VBZ -RRB-_-RRB- e.g._FW -LRB-_-LRB- Lin_NNP and_CC Pantel_NNP ,_, 2001_CD ;_: Szpektor_NNP et_FW al._FW ,_, 2004_CD ;_: Sekine_NNP ,_, 2005_CD -RRB-_-RRB- ._.
In_IN the_DT same_JJ way_NN ,_, most_JJS NLP_NNS systems_NNS like_IN information_NN retrieval_NN -LRB-_-LRB- Sekine_NN ,_, 2005_CD -RRB-_-RRB- or_CC question_NN answering_NN -LRB-_-LRB- Duclaye_NNP et_FW al._FW ,_, 2003_CD -RRB-_-RRB- ,_, based_VBN on_IN pattern_NN recognition_NN ,_, can_MD be_VB improved_VBN by_IN a_DT paraphrase_NN generator_NN ._.
Data-driven_JJ paraphrase_NN discovery_NN methods_NNS -LRB-_-LRB- Lin_NNP and_CC Pantel_NNP ,_, 2001_CD ;_: Pasca_NNP and_CC Dienes_NNP ,_, 2005_CD ;_: Wu_NNP and_CC Zhou_NNP ,_, 2003_CD ;_: Sekine_NNP ,_, 2005_CD -RRB-_-RRB- extends_VBZ the_DT idea_NN of_IN distributional_JJ similarity_NN to_TO phrases_NNS ._.
A_DT number_NN of_IN automatically_RB acquired_VBN inference_NN rule/paraphrase_NN collections_NNS are_VBP available_JJ ,_, such_JJ as_IN -LRB-_-LRB- Szpektor_NNP et_FW al._FW ,_, 2004_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Sekine_NNP ,_, 2005_CD -RRB-_-RRB- ._.
To_TO avoid_VB the_DT drawback_NN ,_, several_JJ linguistic_JJ clues_NNS ,_, such_JJ as_IN fine-grained_JJ classification_NN of_IN named_VBN entities_NNS and_CC coordinated_VBN sentences_NNS ,_, have_VBP been_VBN utilized_VBN -LRB-_-LRB- Sekine_NNP ,_, 2005_CD ;_: Torisawa_NNP ,_, 2006_CD -RRB-_-RRB- ._.
As_IN a_DT later_JJ reﬁnement_NN ,_, Sekine_NNP -LRB-_-LRB- 2005_CD -RRB-_-RRB- makes_VBZ a_DT similar_JJ attempt_NN at_IN using_VBG distributional_JJ similarity_NN over_IN named_VBN entity_NN pairs_NNS in_IN order_NN to_TO produce_VB a_DT list_NN of_IN fully_RB lexicalized_VBN phrasal_JJ paraphrases_NNS for_IN speciﬁc_NN concepts_NNS represented_VBN by_IN keywords_NNS ._.
We_PRP also_RB proposed_VBD a_DT method_NN to_TO find_VB paraphrases_NNS in_IN the_DT context_NN of_IN two_CD Named_VBN Entity_NN instances_NNS in_IN a_DT large_JJ un-annotated_JJ corpus_NN -LRB-_-LRB- Sekine_NN 05_CD -RRB-_-RRB- ._.
Some_DT existing_VBG entailment_NN acquisition_NN algorithms_NNS can_MD add_VB contextual_JJ constraints_NNS to_TO the_DT learned_VBN rules_NNS -LRB-_-LRB- Sekine_NNP ,_, 2005_CD -RRB-_-RRB- ,_, but_CC most_JJS donâ_JJ $_$ ™_CD t_NN ._.
Many_JJ methods_NNS for_IN automatic_JJ acquisition_NN of_IN rules_NNS have_VBP been_VBN suggested_VBN in_IN recent_JJ years_NNS ,_, ranging_VBG from_IN distributional_JJ similarity_NN to_TO finding_VBG shared_JJ contexts_NNS -LRB-_-LRB- Lin_NNP and_CC Pantel_NNP ,_, 2001_CD ;_: Ravichandran_NNP and_CC Hovy_NNP ,_, 2002_CD ;_: Shinyama_NNP et_FW al._FW ,_, 2002_CD ;_: Barzilay_NNP and_CC Lee_NNP ,_, 2003_CD ;_: Szpektor_NNP et_FW al._FW ,_, 2004_CD ;_: Sekine_NNP ,_, 2005_CD -RRB-_-RRB- ._.
Similarly_RB ,_, -LRB-_-LRB- Sekine_NNP ,_, 2005_CD -RRB-_-RRB- improved_VBN information_NN retrieval_NN based_VBN on_IN pattern_NN recognition_NN by_IN introducing_VBG paraphrase_NN generation_NN ._.
Following_VBG Sekine_NNP -LRB-_-LRB- 2005_CD -RRB-_-RRB- ,_, we_PRP clustered_VBD templates_NNS that_WDT share_VBP their_PRP$ main_JJ verb_VB predicate_NN in_IN order_NN to_TO scale_VB down_RP the_DT number_NN of_IN different_JJ predicates_NNS in_IN the_DT corpus_NN and_CC collect_VB richer_JJR word_NN co_SYM -_: occurrence_NN statistics_NNS per_IN predicate_NN ._.
Some_DT existing_VBG paraphrase_NN and_CC entailment_NN acquisition_NN algorithms_NNS add_VBP constraints_NNS to_TO the_DT learned_VBN rules_NNS -LRB-_-LRB- e.g._FW -LRB-_-LRB- Sekine_NNP ,_, 2005_CD -RRB-_-RRB- ,_, -LRB-_-LRB- CallisonBurch_NNP ,_, 2008_CD -RRB-_-RRB- -RRB-_-RRB- ,_, but_CC most_JJS do_VBP not_RB ._.
As_IN for_IN paraphrase_NN ,_, Sekineâ_NNP $_$ ™_CD s_NNS Paraphrase_NNP Database_NNP -LRB-_-LRB- Sekine_NNP ,_, 2005_CD -RRB-_-RRB- is_VBZ collected_VBN using_VBG an_DT unsupervised_JJ method_NN ,_, and_CC focuses_VBZ on_IN phrases_NNS connecting_VBG two_CD Named_VBN Entities_NNS ._.
-LRB-_-LRB- Stolcke_NNP et_FW al._FW ,_, 2000_CD -RRB-_-RRB- use_VBP HMMs_NNS for_IN dialogue_NN modelling_NN ,_, where_WRB sequences_NNS of_IN observations_NNS correspond_VBP to_TO sequences_NNS of_IN dialogue_NN act_VBP types.They_NN also_RB explore_VB the_DT performance_NN with_IN decision_NN trees_NNS and_CC neural_JJ networks_NNS and_CC report_VB their_PRP$ highest_JJS accuracy_NN at_IN 65_CD %_NN on_IN the_DT Switchboard_NN corpus_NN ._.
Previous_JJ research_NN has_VBZ leveraged_VBN prosodic_JJ cues_NNS -LRB-_-LRB- Sridhar_NNP et_FW al._FW ,_, 2009_CD ;_: Stolcke_NNP et_FW al._FW ,_, 2000_CD -RRB-_-RRB- and_CC facial_JJ expressions_NNS -LRB-_-LRB- Boyer_NNP et_FW al._FW ,_, 2011_CD -RRB-_-RRB- for_IN automatic_JJ dialogue_NN act_NN classification_NN ,_, but_CC other_JJ types_NNS of_IN nonverbal_JJ cues_NNS remain_VBP unexplored_JJ ._.
Conversational_JJ feedback_NN is_VBZ mostly_RB performedthrough_JJ short_JJ utterances_NNS such_JJ as_IN yeah_NN ,_, mh_NN ,_, okaynot_NN produced_VBN by_IN the_DT main_JJ speaker_NN but_CC by_IN one_CD ofthe_NN other_JJ participants_NNS of_IN a_DT conversation.Such_NN utterances_NNS are_VBP among_IN the_DT most_RBS frequent_JJ in_IN conversational_JJ data_NNS -LRB-_-LRB- Stolcke_NNP et_FW al._FW ,_, 2000_CD -RRB-_-RRB- ._.
Previous_JJ research_NN has_VBZ leveraged_VBN prosodic_JJ cues_NNS -LRB-_-LRB- Sridhar_NNP et_FW al._FW ,_, 2009_CD ;_: Stolcke_NNP et_FW al._FW ,_, 2000_CD -RRB-_-RRB- and_CC facial_JJ expressions_NNS -LRB-_-LRB- Boyer_NNP et_FW al._FW ,_, 2011_CD -RRB-_-RRB- for_IN automatic_JJ dialogue_NN act_NN classification_NN ,_, but_CC other_JJ types_NNS of_IN nonverbal_JJ cues_NNS remain_VBP unexplored_JJ ._.
Dialog_NN act_NN -LRB-_-LRB- DA_NN -RRB-_-RRB- annotations_NNS and_CC tagging_VBG ,_, inspiredby_VB the_DT speech_NN act_NN theory_NN of_IN Austin_NNP -LRB-_-LRB- 1975_CD -RRB-_-RRB- and_CC Searle_NNP -LRB-_-LRB- 1976_CD -RRB-_-RRB- ,_, have_VBP been_VBN used_VBN in_IN the_DT NLP_NNP community_NN to_TO understand_VB and_CC model_VB dialog.Initial_JJ work_NN was_VBD done_VBN onspoken_JJ interactions_NNS -LRB-_-LRB- see_VB for_IN example_NN -LRB-_-LRB- Stolcke_NNP et_FW al._FW ,2000_CD -RRB-_-RRB- -RRB-_-RRB- ._.
By_IN representing_VBG a_DT higher_JJR level_NN intention_NN of_IN utterancesduring_VBG human_JJ conversation_NN ,_, dialogue_NN act_VBP labels_NNS arebeing_VBG used_VBN to_TO enrich_VB the_DT information_NN provided_VBD byspoken_JJ words_NNS -LRB-_-LRB- Stolcke_NNP et_FW al._FW ,_, 2000_CD -RRB-_-RRB- ._.
Chinese_JJ According_VBG to_TO Sproat_NNP et_FW al._FW -LRB-_-LRB- 1996_CD -RRB-_-RRB- ,_, most_JJS prior_JJ work_NN in_IN Chinese_JJ segmentation_NN has_VBZ exploited_VBN lexical_JJ knowledge_NN bases_NNS ;_: indeed_RB ,_, the_DT authors_NNS assert_VBP that_IN they_PRP were_VBD aware_JJ of_IN only_RB one_CD previously_RB pubÂ_NN lished_VBD instance_NN -LRB-_-LRB- the_DT mutual-information_NN method_NN of_IN Sproat_NNP and_CC Shih_NNP -LRB-_-LRB- 1990_CD -RRB-_-RRB- -RRB-_-RRB- of_IN a_DT purely_RB statistical_JJ apÂ_NN proach_NN ._.
Conventionally_RB a_DT word_NN segmentation_NN process_NN identifies_VBZ the_DT words_NNS in_IN input_NN text_NN by_IN matching_VBG lexical_JJ entries_NNS and_CC resolving_VBG the_DT ambiguous_JJ matching_NN -LRB-_-LRB- Chen_NNP &_CC Liu_NNP ,_, 1992_CD ,_, Sproat_NNP et_FW al_FW ,_, 1996_CD -RRB-_-RRB- ._.
Mutu_NNP al_NNP infor_NNP matio_NN n-like_JJ statist_JJ ics_NNS are_VBP very_RB often_RB adopt_VB ed_VBN in_IN meas_NNS uring_VBG assoc_NN iation_NN stren_NN gth_NN msi_NN -LRB-_-LRB- ?_. -RRB-_-RRB-
dsi_NN +1_NN -LRB-_-LRB- -RRB-_-RRB- combine_VBP -LRB-_-LRB- i_FW ,_, i_FW +_CC 1_LS -RRB-_-RRB- 1993_CD ,_, Sproat_NNP et_FW al_FW ,_, 1996_CD -RRB-_-RRB- Chinese_JJ NE_NN recognition_NN is_VBZ much_RB more_RBR difficult_JJ than_IN that_DT in_IN English_NNP due_JJ to_TO two_CD major_JJ problems.The_NN first_JJ is_VBZ the_DT word_NN segmentation_NN problem_NN -LRB-_-LRB- Sproat_NNP et_FW al._FW 96_CD ,_, Palmer_NNP 97_CD -RRB-_-RRB- ._.
We_PRP used_VBD a_DT maximum_NN -_: matching_VBG algorithm_NN and_CC a_DT dictionary_NN compiled_VBN from_IN the_DT CTB_NNP -LRB-_-LRB- Sproat_NNP et_FW al._FW ,_, 1996_CD ;_: Xue_NNP ,_, 2001_CD -RRB-_-RRB- to_TO do_VB segmentation_NN The_DT Chinese_NNPS word_NN segmentation_NN is_VBZ a_DT nontrivial_JJ task_NN because_IN no_DT explicit_JJ delimiters_NNS -LRB-_-LRB- like_IN spaces_NNS in_IN English_NNP -RRB-_-RRB- are_VBP used_VBN for_IN word_NN separation.As_NNS the_DT task_NN is_VBZ an_DT important_JJ precursor_NN to_TO many_JJ natural_JJ language_NN processing_NN systems_NNS ,_, it_PRP receives_VBZ a_DT lot_NN of_IN attentions_NNS in_IN the_DT literature_NN for_IN the_DT past_JJ decade_NN -LRB-_-LRB- Wu_NNP and_CC Tseng_NNP ,_, 1993_CD ;_: Sproat_NNP et_FW al._FW ,_, 1996_CD -RRB-_-RRB- ._.
Sproat_NNP et_FW al._FW -LRB-_-LRB- 1996_CD -RRB-_-RRB- implement_VBP special_JJ recognizers_NNS not_RB only_RB for_IN Chinese_JJ names_NNS and_CC transliterated_VBD foreign_JJ names_NNS ,_, but_CC for_IN components_NNS of_IN morphologically_RB obtained_VBN words_NNS as_RB well_RB ._.
There_EX are_VBP several_JJ commonly_RB used_VBN segmentation_NN methods_NNS such_JJ as_IN forward_RB maximum_JJ matching_NN and_CC backward_RB maximum_JJ matching_NN -LRB-_-LRB- Teahan_NNP et_FW al._FW 2000_CD ;_: Dai_NNP ,_, Loh_NNP ,_, and_CC Khoo_NNP 1999_CD ;_: Sproat_NNP et_FW al._FW 1996_CD -RRB-_-RRB- ._.
A_DT previous_JJ work_NN along_IN this_DT line_NN is_VBZ Sproat_NNP et_FW al._FW -LRB-_-LRB- 1996_CD -RRB-_-RRB- ,_, which_WDT is_VBZ based_VBN on_IN weighted_JJ finite-state_JJ transducers_NNS -LRB-_-LRB- FSTs_NNS -RRB-_-RRB- ._.
The_DT Chinese_JJ person-name_NN model_NN is_VBZ a_DT modified_VBN version_NN of_IN that_DT described_VBN in_IN Sproat_NNP et_FW al._FW -LRB-_-LRB- 1996_CD -RRB-_-RRB- ._.
Since_IN in_IN written_VBN Chinese_JJ there_EX is_VBZ no_DT explicit_JJ word_NN delimiter_NN -LRB-_-LRB- equivalent_JJ to_TO the_DT blank_JJ space_NN in_IN written_VBN English_NNP -RRB-_-RRB- ,_, the_DT problem_NN of_IN Chinese_JJ sentence_NN tokenization_NN has_VBZ been_VBN the_DT focus_NN of_IN considerable_JJ research_NN efforts_NNS ,_, and_CC significant_JJ advancements_NNS have_VBP been_VBN made_VBN -LRB-_-LRB- e.g._FW ,_, Bai_NNP 1995_CD ;_: Zhang_NNP et_FW al._FW 1994_CD ;_: Chen_NNP and_CC Liu_NNP 1992_CD ;_: Chiang_NNP et_FW al._FW 1992_CD ;_: Fan_NN and_CC Tsai_NNP 1988_CD ;_: Gan_NNP 1995_CD ;_: Gan_NNP ,_, Palmer_NNP ,_, and_CC Lua_NNP 1996_CD ;_: Guo_NNP 1993_CD ;_: He_PRP ,_, Xu_NNP ,_, and_CC Sun_NNP 1991_CD ;_: Huang_NNP 1989_CD ;_: Huang_NNP and_CC Xia_NNP 1996_CD ;_: Jie_NNP 1989_CD ;_: Jie_NNP ,_, Liu_NNP ,_, and_CC Liang_NNP 1991a_NN ,_, 1991b_NN ;_: Jin_NNP and_CC Chen_NNP 1995_CD ;_: Lai_NNP et_FW al._FW 1992_CD ;_: Li_NNP et_FW al._FW 1995_CD ;_: Liang_NNP 1986_CD ,_, 1987_CD ,_, 1990_CD ;_: Liu_NNP 1986a_NNP ,_, 1986b_CD ;_: Liu_NNP ,_, Tan_NNP ,_, and_CC Shen_NNP 1994_CD ;_: Lua_NNP 1990_CD ,_, 1994_CD ,_, and_CC 1995_CD ;_: Ma_NNP 1996_CD ;_: Nie_NNP ,_, Jin_NNP ,_, and_CC Hannan_NNP 1994_CD ;_: Sproat_NNP and_CC Shih_NNP 1990_CD ;_: Sproat_NNP et_FW al._FW 1996_CD ;_: The_DT weighted_JJ finite-state_NN transducer_NN model_NN developed_VBN by_IN Sproat_NNP et_FW al._FW -LRB-_-LRB- 1996_CD -RRB-_-RRB- is_VBZ another_DT excellent_JJ representative_NN example_NN ._.
While_IN it_PRP may_MD not_RB be_VB totally_RB impossible_JJ to_TO fully_RB incorporate_VB such_JJ knowledge_NN and_CC heuristics_NNS into_IN the_DT general_JJ framework_NN of_IN path_NN evaluation_NN and_CC searching_VBG ,_, they_PRP are_VBP apÂ_NN parently_RB employed_VBN neither_CC in_IN Sproat_NNP et_FW al._FW -LRB-_-LRB- 1996_CD -RRB-_-RRB- nor_CC in_IN Ma_NNP -LRB-_-LRB- 1996_CD -RRB-_-RRB- ._.
Many_JJ natural_JJ language_NN models_NNS can_MD be_VB captured_VBN by_IN weighted_JJ finite-state_JJ transducers_NNS -LRB-_-LRB- Pereira_NNP et_FW al._FW ,_, 1994_CD ;_: Sproat_NNP et_FW al._FW ,_, 1996_CD ;_: Knight_NNP and_CC AlOnaizan_NNP ,_, 1998_CD ;_: Clark_NNP ,_, 2002_CD ;_: Kolak_NNP et_FW al._FW ,_, 2003_CD ;_: Mathias_NNP and_CC Byrne_NNP ,_, 2006_CD -RRB-_-RRB- ,_, which_WDT offer_VBP several_JJ benefits_NNS One_CD example_NN of_IN such_JJ approaches_NNS is_VBZ Sproat_NNP et_FW al._FW -LRB-_-LRB- 1996_CD -RRB-_-RRB- ,_, which_WDT is_VBZ based_VBN on_IN weighted_JJ finite-state_JJ transducers_NNS -LRB-_-LRB- FSTs_NNS -RRB-_-RRB- ._.
Because_IN any_DT character_NN strings_NNS can_MD be_VB in_IN principle_NN named_VBN entities_NNS of_IN one_CD or_CC more_JJR types_NNS ,_, to_TO limit_VB the_DT number_NN of_IN candidates_NNS for_IN a_DT more_RBR effective_JJ search_NN ,_, we_PRP generate_VBP named_VBN entity_NN candidates_NNS ,_, given_VBN an_DT input_NN string_NN ,_, in_IN two_CD steps_NNS 5.2.4_CD Transliterations_NNS of_IN foreign_JJ names_NNS As_IN described_VBN in_IN Sproat_NNP et_FW al._FW -LRB-_-LRB- 1996_CD -RRB-_-RRB- Candidate_NNP Chinese_NNP transliterations_NNS are_VBP generated_VBN by_IN consulting_VBG a_DT list_NN of_IN characters_NNS that_WDT are_VBP frequently_RB used_VBN for_IN transliterating_VBG foreign_JJ names.As_NNS discussed_VBN elsewhere_RB -LRB-_-LRB- Sproat_NNP et_FW al._FW ,_, 1996_CD -RRB-_-RRB- ,_, a_DT subset_NN of_IN a_DT few_JJ hundred_CD characters_NNS -LRB-_-LRB- out_IN of_IN several_JJ thousand_CD -RRB-_-RRB- tends_VBZ to_TO be_VB used_VBN overwhelmingly_RB for_IN transliterating_VBG foreign_JJ names_NNS into_IN Chinese_JJ ._.
Using_VBG the_DT 495_CD characters_NNS that_WDT are_VBP frequently_RB used_VBN for_IN transliterating_VBG foreign_JJ names_NNS -LRB-_-LRB- Sproat_NNP et_FW al._FW ,_, 1996_CD -RRB-_-RRB- ,_, a_DT sequence_NN of_IN three_CD of_IN more_JJR characters_NNS from_IN the_DT list_NN was_VBD taken_VBN as_IN a_DT possible_JJ candidate_NN for_IN Chinese_JJ ._.
As_IN discussed_VBN elsewhere_RB -LRB-_-LRB- Sproat_NNP et_FW al._FW ,_, 1996_CD -RRB-_-RRB- ,_, out_IN of_IN several_JJ thousand_CD common_JJ Chinese_JJ characters_NNS ,_, a_DT subset_NN of_IN a_DT few_JJ hundred_CD characters_NNS tends_VBZ to_TO be_VB used_VBN overwhelmingly_RB for_IN transliterating_VBG English_NNP names_NNS to_TO Chinese_JJ ,_, e.g._FW only_RB 731_CD Chinese_JJ characters_NNS are_VBP adopted_VBN in_IN the_DT E-C_NN corpus_NN ._.
3.3.1_CD Dictionary_NNP features_NNS Because_IN segmentation_NN using_VBG a_DT dictionary_NN alone_RB can_MD serve_VB as_IN a_DT strong_JJ baseline_NN in_IN Chinese_JJ word_NN segmentation_NN -LRB-_-LRB- Sproat_NNP et_FW al._FW ,_, 1996_CD -RRB-_-RRB- ,_, the_DT use_NN of_IN dictionaries_NNS is_VBZ expected_VBN to_TO make_VB our_PRP$ joint_JJ model_NN more_RBR robust_JJ and_CC enables_VBZ us_PRP to_TO investigate_VB the_DT contribution_NN of_IN the_DT syntactic_JJ dependency_NN in_IN a_DT more_RBR realistic_JJ setting_NN ._.
In_IN early_JJ work_NN ,_, rule-based_JJ models_NNS find_VBP words_NNS one_CD by_IN one_CD based_VBN on_IN heuristics_NNS such_JJ as_IN forward_RB maximum_JJ match_NN -LRB-_-LRB- Sproat_NNP et_FW al._FW ,_, 1996_CD -RRB-_-RRB- ._.
For_IN a_DT discussion_NN of_IN recent_JJ Chinese_JJ segmentation_NN work_NN ,_, see_VB Sproat_NNP et_FW al._FW -LCB-_-LRB- 1996_CD -RRB-_-RRB- ._.
utilizing_VBG local_JJ and_CC sentential_JJ constraints_NNS ,_, what_WDT Sproat_NNP et_FW al._FW -LRB-_-LRB- 1996_CD -RRB-_-RRB- implemented_VBD was_VBD simply_RB a_DT token_JJ unigram_JJ scoring_VBG function_NN ._.
To_TO improve_VB word_NN segmentaÂ_NN tion_NN accuracy_NN ,_, -LRB-_-LRB- Nagata_NNP ,_, 1996_CD -RRB-_-RRB- used_VBD a_DT single_JJ general_JJ purpose_NN unknown_JJ word_NN model_NN ,_, while_IN -LRB-_-LRB- Sproat_NNP et_FW al._FW ,_, 1996_CD -RRB-_-RRB- used_VBD a_DT set_NN of_IN specific_JJ word_NN models_NNS such_JJ as_IN for_IN plurals_NNS ,_, personal_JJ names_NNS ,_, and_CC transliterated_VBD foreign_JJ words_NNS ._.
Word_NN segmentation_NN accuracy_NN is_VBZ expressed_VBN in_IN terms_NNS of_IN recall_NN and_CC precision_NN as_RB is_VBZ done_VBN in_IN the_DT previous_JJ research_NN -LRB-_-LRB- Sproat_NNP et_FW al._FW ,_, 1996_CD -RRB-_-RRB- ._.
Segmentation_NN rutd_NN morphological_JJ analysis_NN related_JJ issues_NNS of_IN both_DT Chinese_JJ and_CC Japanese_JJ are_VBP intensively_RB addressed_VBN elsewhere_RB -LRB-_-LRB- Sproat_NNP et_FW al._FW ,_, 1996_CD ;_: MatsUIIt_NN -LRB-_-LRB- ltO_NN et_FW al._FW ,_, 1997_CD and_CC many_JJ others_NNS -RRB-_-RRB- ._.
For_IN examples_NNS Statistical_JJ approaches_NNS involve_VBP language_NN mod_NN els_NNS mostly_RB finite-state_JJ ones_NNS trained_VBN on_IN some_DT large-scale_JJ corpora_NN as_IN showed_VBN in_IN Fan_NN and_CC Tsai_NN -LRB-_-LRB- 1988_CD -RRB-_-RRB- Chang_NNP et_FW al_FW -LRB-_-LRB- 1991_CD -RRB-_-RRB- Chiang_NNP et_FW al_FW -LRB-_-LRB- 1992_CD -RRB-_-RRB- Sproat_NNP et_FW al_FW -LRB-_-LRB- 1996_CD -RRB-_-RRB- Sproat_NNP et_FW al._FW -LRB-_-LRB- 1996_CD -RRB-_-RRB- employs_VBZ stochastic_JJ finite_JJ state_NN machines_NNS to_TO find_VB word_NN boundaries_NNS ._.
This_DT may_MD sound_VB simple_JJ enough_JJ but_CC in_IN reality_NN identifying_VBG words_NNS in_IN Chinese_NNP is_VBZ a_DT nontrivial_JJ problem_NN that_WDT has_VBZ drawn_VBN a_DT large_JJ body_NN of_IN research_NN in_IN the_DT Chinese_JJ language_NN processing_NN community_NN -LRB-_-LRB- Fan_NN and_CC Tsai_NNP ,_, 1988_CD ;_: Gan_NNP et_FW al._FW ,_, 1996_CD ;_: Sproat_NNP et_FW al._FW ,_, 1996_CD ;_: Wu_NNP ,_, 2003_CD ;_: Xue_NNP ,_, 2003_CD -RRB-_-RRB- ._.
In_IN addition_NN to_TO the_DT model_NN based_VBN upon_IN a_DT dictionary_NN of_IN stems_VBZ and_CC words_NNS ,_, we_PRP also_RB experimented_VBD with_IN models_NNS based_VBN upon_IN character_NN n-grams_NNS ,_, similar_JJ to_TO those_DT used_VBN for_IN Chinese_JJ segmentation_NN -LRB-_-LRB- Sproat_NNP et_FW al._FW ,_, 1996_CD -RRB-_-RRB- ._.
The_DT words_NNS were_VBD stemmed_VBN all_DT possible_JJ ways_NNS using_VBG simple_JJ hand-developed_JJ affix_NN lists_NNS In_IN such_JJ languages_NNS ,_, words_NNS are_VBP segmented_JJ using_VBG more_RBR advanced_JJ techniques_NNS ,_, which_WDT can_MD be_VB categorized_VBN into_IN three_CD methods_NNS There_EX are_VBP a_DT number_NN of_IN popular_JJ dictionary-based_JJ solutions_NNS such_JJ as_IN Cha_NNP Sen10_NNP and_CC Juman_NNP .11_CD Sproat_NNP et_FW al_FW -LRB-_-LRB- 1996_CD -RRB-_-RRB- proposed_VBD an_DT alternative_JJ solution_NN based_VBN on_IN distributional_JJ statistics_NNS such_JJ as_IN mutual_JJ information_NN ._.
An_DT extension_NN of_IN this_DT approach_NN is_VBZ the_DT dynamic_JJ programming_NN search_NN of_IN the_DT most_RBS probable_JJ word_NN combination_NN on_IN the_DT word_NN lattice_NN ,_, such_JJ as_IN Ma_NNP -LRB-_-LRB- 1996_CD -RRB-_-RRB- and_CC Sproat_NNP et_FW al._FW -LRB-_-LRB- 1996_CD -RRB-_-RRB- ,_, which_WDT utilize_VBP information_NN such_JJ as_IN word_NN frequency_NN statistics_NNS in_IN a_DT corpus_NN to_TO build_VB the_DT model_NN and_CC are_VBP less_RBR efficient_JJ but_CC more_RBR accurate_JJ ._.
One_CD of_IN the_DT major_JJ problems_NNS in_IN unsupervised_JJ word_NN segmentation_NN is_VBZ the_DT treatment_NN of_IN unseen_JJ word_NN -LSB-_-LRB- Sproat_NNP et_FW al._FW ,_, 1996_CD -RSB-_-RRB- wrote_VBD lexical_JJ rules_NNS for_IN each_DT productive_JJ morphological_JJ process_NN ,_, such_JJ as_IN plur_NN noun_NN formation_NN ,_, Chinese_JJ personal_JJ names_NNS ,_, and_CC transliterations_NNS of_IN foreign_JJ words_NNS ._.
We_PRP used_VBD a_DT simple_JJ greedy_JJ algorithm_NN described_VBN in_IN -LSB-_-LRB- Sproat_NNP et_FW al._FW ,_, 1996_CD -RSB-_-RRB- ._.
-LSB-_-LRB- Sproat_NNP et_FW al._FW ,_, 1996_CD -RSB-_-RRB- also_RB proposed_VBD another_DT method_NN to_TO estimate_VB a_DT set_NN of_IN initial_JJ word_NN frequencies_NNS without_IN segmenting_VBG the_DT corpus_NN ._.
The_DT problem_NN of_IN the_DT longest_JJS match_NN string_NN frequency_NN method_NN is_VBZ that_IN if_IN a_DT word_NN W1_NN is_VBZ a_DT substring_NN of_IN other_JJ word_NN w2_NN and_CC if_IN wl_NN always_RB appears_VBZ as_IN a_DT substring_NN of_IN w2_NN in_IN the_DT training_NN text_NN ,_, just_RB like_IN m_NN 1Although_NN -LRB-_-LRB- Sproat_NNP et_FW al._FW ,_, 1996_CD -RSB-_-RRB- calls_VBZ it_PRP ``_`` maximum_JJ matching_NN ''_'' ,_, we_PRP call_VBP this_DT method_NN ``_`` longest_JJS match_NN ''_'' according_VBG to_TO a_DT review_NN on_IN Chinese_JJ word_NN segmentation_NN -LSB-_-LRB- Wu_NNP and_CC Tseng_NNP ,_, 1993_CD -RRB-_-RRB- and_CC the_DT literal_JJ translation_NN of_IN the_DT Japanese_JJ name_NN of_IN the_DT method_NN Hi_NN !_.
Word_NN Segmentation_NN accuracy_NN is_VBZ expressed_VBN in_IN terms_NNS of_IN recall_NN and_CC precision_NN as_RB is_VBZ done_VBN for_IN bracketing_NN of_IN partial_JJ parses_VBZ -LSB-_-LRB- Nagata_NNP ,_, 1994_CD ,_, Sproat_NNP et_FW al._FW ,_, 1996_CD -RRB-_-RRB- ._.
Automatic_NNP methods_NNS for_IN correctly_RB isolating_VBG words_NNS in_IN a_DT sentence_NN --_: a_DT process_NN called_VBN word_NN segmentation_NN --_: is_VBZ therefore_RB an_DT important_JJ and_CC necessary_JJ first_JJ step_NN to_TO be_VB taken_VBN before_IN other_JJ analysis_NN can_MD begin.Many_NNP researchers_NNS have_VBP proposed_VBN practical_JJ methods_NNS to_TO resolve_VB this_DT problem_NN such_JJ as_IN -LRB-_-LRB- Nie_NN et_FW al._FW ,_, 1995_CD ,_, Wu_NNP and_CC Tsang_NNP ,_, 1995_CD ,_, Jin_NNP &_CC Chen_NNP ,_, 1996_CD ,_, Ponte_NNP &_CC Croft_NNP ,_, 1996_CD ,_, Sproat_NNP et_FW al._FW ,_, 1996_CD ,_, Sun_NNP et_FW al._FW ,_, 1997_CD -RRB-_-RRB- ._.
Chi_NNP and_CC Geman_NNP -LRB-_-LRB- 1998_CD -RRB-_-RRB- proved_VBD that_IN this_DT condition_NN is_VBZ met_VBN if_IN the_DT rule_NN probabilities_NNS are_VBP estimated_VBN using_VBG relative_JJ frequency_NN estimation_NN from_IN a_DT corpus_NN ._.
The_DT frustration_NN with_IN models_NNS that_WDT lack_VBP an_DT intuitive_JJ interpretation_NN led_VBD to_TO the_DT development_NN of_IN decision_NN trees_NNS based_VBN on_IN bigram_NN features_NNS -LRB-_-LRB- Pedersen_NNP ,_, 2001a_NN -RRB-_-RRB- ._.
This_DT is_VBZ quite_RB similar_JJ to_TO the_DT bagged_JJ decision_NN trees_NNS of_IN bigrams_NNS -LRB-_-LRB- B_NN -RRB-_-RRB- presented_VBN here_RB ,_, except_IN that_IN the_DT earlier_JJR work_NN learns_VBZ a_DT single_JJ decision_NN tree_NN where_WRB training_NN examples_NNS are_VBP represented_VBN by_IN the_DT top_JJ 100_CD ranked_VBD bi-grams_NNS ,_, according_VBG to_TO the_DT log_NN --_: likelihood_NN ratio.This_NN earlier_RBR approach_NN was_VBD evaluated_VBN on_IN the_DT SENSEVAL1_NN data_NNS and_CC achieved_VBD an_DT overall_JJ accuracy_NN of_IN 64_CD %_NN ,_, whereas_IN the_DT bagged_JJ decision_NN tree_NN presented_VBN here_RB achieves_VBZ an_DT accuracy_NN of_IN 68_CD %_NN on_IN that_DT data_NNS ._.
We_PRP also_RB obtain_VB salient_JJ bigrams_NNS in_IN the_DT context_NN ,_, with_IN the_DT methods_NNS and_CC the_DT software_NN described_VBN in_IN -LRB-_-LRB- Pedersen_NNP ,_, 2001_CD -RRB-_-RRB- ._.
•_NN Salient_JJ bigrams_NNS Recently_RB Bean_NNP and_CC Riloff_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- have_VBP sought_VBN to_TO acquire_VB automatically_RB some_DT semantic_JJ patterns_NNS that_WDT can_MD be_VB used_VBN as_IN contextual_JJ information_NN to_TO improve_VB reference_NN resolution_NN ,_, using_VBG techniques_NNS adapted_VBN from_IN information_NN extraction.Their_NN experiments_NNS were_VBD conducted_VBN on_IN collections_NNS of_IN texts_NNS in_IN two_CD topic_NN areas_NNS -LRB-_-LRB- terrorism_NN and_CC natural_JJ disasters_NNS -RRB-_-RRB- ._.
the_DT dependency_NN from_IN the_DT event_NN head_NN to_TO an_DT event_NN argument_NN depi_NN ,_, j_NN ,_, our_PRP$ model_NN instead_RB emits_VBZ the_DT pair_NN of_IN event_NN head_NN and_CC dependency_NN relation_NN ,_, which_WDT we_PRP call_VBP a_DT caseframe_NN following_VBG Bean_NNP and_CC Riloff_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- ._.
Another_DT source_NN of_IN inspiration_NN is_VBZ the_DT work_NN by_IN Bean_NNP and_CC Riloff_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- ._.
They_PRP use_VBP contextual_JJ roles_NNS -LRB-_-LRB- i.e._FW ,_, the_DT role_NN that_IN an_DT NP_NN plays_VBZ in_IN an_DT event_NN -RRB-_-RRB- for_IN extracting_VBG patterns_NNS that_WDT can_MD be_VB used_VBN in_IN coreference_NN resolution_NN ,_, showing_VBG the_DT relevance_NN of_IN verbs_NNS in_IN deciding_VBG on_IN coreference_NN between_IN their_PRP$ arguments.However_NN ,_, they_PRP use_VBP a_DT very_RB small_JJ corpus_NN -LRB-_-LRB- two_CD domains_NNS -RRB-_-RRB- and_CC do_VBP not_RB aim_VB to_TO build_VB a_DT dictionary_NN ._.
-LRB-_-LRB- 2001_CD -RRB-_-RRB- -RRB-_-RRB- and_CC unsupervised_JJ approaches_NNS -LRB-_-LRB- e.g._FW ,_, Cardie_NNP and_CC Wagstaff_NNP -LRB-_-LRB- 1999_CD -RRB-_-RRB- ,_, Bean_NNP and_CC Riloff_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Since_IN no_DT such_JJ corpus_NN exists_VBZ ,_, researchers_NNS have_VBP used_VBN coarser_JJR features_NNS learned_VBD from_IN smaller_JJR sets_NNS through_IN supervised_VBN learning_NN -LRB-_-LRB- Soon_RB et_FW al._FW ,_, 2001_CD ;_: Ng_NN and_CC Cardie_NNP ,_, 2002_CD -RRB-_-RRB- ,_, manually-defined_JJ coreference_NN patterns_NNS to_TO mine_VB specific_JJ kinds_NNS of_IN data_NNS -LRB-_-LRB- Bean_NNP and_CC Riloff_NNP ,_, 2004_CD ;_: Bergsma_NNP ,_, 2005_CD -RRB-_-RRB- Bean_NNP and_CC Riloff_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- used_VBN bootstrapping_VBG to_TO extend_VB their_PRP$ semantic_JJ compatibility_NN model_NN ,_, which_WDT they_PRP called_VBD contextual-role_JJ knowledge_NN ,_, by_IN identifying_VBG certain_JJ cases_NNS of_IN easily-resolved_JJ anaphors_NNS and_CC antecedents.They_NN give_VBP the_DT example_NN â_VBD $_$ œMr.Bush_JJ disclosed_VBD the_DT policy_NN by_IN reading_VBG it.â_RB $_$ Once_IN we_PRP identify_VBP that_IN it_PRP and_CC policy_NN are_VBP coreferent_JJ ,_, we_PRP include_VBP read_VBN Bean_NNP and_CC Riloff_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- present_VBP a_DT system_NN called_VBN BABAR_NNP that_WDT uses_VBZ contextual_JJ role_NN knowledge_NN to_TO do_VB coreference_NN resolution.They_NN apply_VB an_DT IE_JJ component_NN to_TO unannotated_JJ texts_NNS to_TO generate_VB a_DT set_NN of_IN extraction_NN caseframes.Each_NN caseframe_NN represents_VBZ a_DT linguistic_JJ expression_NN and_CC a_DT syntactic_JJ position_NN ,_, e.g._FW â_FW $_$ œmurder_CD of_IN <NP>_NN â_NN $_$ ,_, â_VB $_$ œkilled_JJ <patient>_NN â_NN $_$ ._.
From_IN the_DT case_NN -_: frames_NNS ,_, they_PRP derive_VBP different_JJ types_NNS of_IN contextual_JJ role_NN knowledge_NN for_IN resolution_NN ,_, for_IN example_NN ,_, whether_IN an_DT anaphor_NN and_CC an_DT antecedent_JJ candidate_NN can_MD be_VB filled_VBN into_IN co-occurring_VBG caseframes_NNS ,_, or_CC whether_IN they_PRP are_VBP substitutable_JJ for_IN each_DT other_JJ in_IN their_PRP$ caseframes_NNS ._.
Bean_NNP and_CC Riloff_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- proposed_VBD the_DT use_NN of_IN caseframe_NN networks_NNS as_IN a_DT kind_NN of_IN contextual_JJ role_NN knoweldge_NN for_IN anaphora_NN resolution.Bean_NN and_CC Riloff_NN learn_VBP these_DT networks_NNS from_IN two_CD topic-specific_JJ texts_NNS and_CC apply_VB them_PRP to_TO the_DT problem_NN of_IN anaphora_NN resolution_NN ._.
In_IN this_DT paper_NN we_PRP extend_VBP this_DT work_NN to_TO represent_VB sets_NNS of_IN situation-specific_JJ events_NNS not_RB unlike_IN scripts_NNS ,_, caseframes_NNS -LRB-_-LRB- Bean_NNP and_CC Riloff_NNP ,_, 2004_CD -RRB-_-RRB- The_DT DempsterShafer_NN rule_NN -LRB-_-LRB- Dempster_NN ,_, 1968_CD -RRB-_-RRB- ,_, which_WDT combines_VBZ the_DT positive_JJ and_CC negative_JJ pairwise_JJ decisions_NNS to_TO score_VB a_DT partition_NN ,_, is_VBZ used_VBN by_IN Kehler_NNP -LRB-_-LRB- 1997_CD -RRB-_-RRB- and_CC Bean_NNP and_CC Riloff_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- to_TO identify_VB the_DT most_RBS probable_JJ NP_NN partition_NN ._.
However_RB ,_, the_DT use_NN of_IN related_JJ verbs_NNS is_VBZ similar_JJ in_IN spirit_NN to_TO Bean_NNP and_CC Riloffâ_NNP $_$ ™_CD s_NNS -LRB-_-LRB- 2004_CD -RRB-_-RRB- use_NN of_IN patterns_NNS for_IN inducing_VBG contextual_JJ role_NN knowledge_NN ,_, and_CC the_DT use_NN of_IN semantic_JJ roles_NNS is_VBZ also_RB discussed_VBN in_IN Ponzetto_NNP and_CC Strube_NNP -LRB-_-LRB- 2006_CD -RRB-_-RRB- ._.
Caseframes_NNS do_VBP not_RB consider_VB the_DT dependents_NNS of_IN the_DT semantic_JJ role_NN approximations.The_NN use_NN of_IN caseframes_NNS is_VBZ well_RB grounded_VBN in_IN a_DT va_NN riety_NN of_IN NLP_NN tasks_NNS relevant_JJ to_TO summarization_NN such_JJ as_IN coreference_NN resolution_NN -LRB-_-LRB- Bean_NNP and_CC Riloff_NNP ,_, 2004_CD -RRB-_-RRB- In_IN addition_NN ,_, BABAR_NN -LRB-_-LRB- Bean_NNP and_CC Riloff_NNP ,_, 2004_CD -RRB-_-RRB- used_VBN contextual_JJ role_NN knowledge_NN for_IN coreference_NN resolution_NN in_IN the_DT domains_NNS of_IN terrorism_NN and_CC natural_JJ disasters.But_NN BABAR_NNP acquired_VBD and_CC used_VBD lexical_JJ information_NN to_TO match_VB the_DT compatibility_NN of_IN contexts_NNS surrounding_VBG NPs_NNS ,_, not_RB the_DT NPs_NNS themselves_PRP ._.
There_EX are_VBP also_RB approaches_VBZ to_TO anaphora_NN resolution_NN using_VBG unsupervised_JJ methods_NNS to_TO extract_VB useful_JJ information_NN ,_, such_JJ as_IN gender_NN and_CC number_NN -LRB-_-LRB- Ge_NNP et_FW al._FW ,_, 1998_CD -RRB-_-RRB- ,_, or_CC contextual_JJ role-knowledge_NN -LRB-_-LRB- Bean_NNP and_CC Riloff_NNP ,_, 2004_CD -RRB-_-RRB- ._.
Bean_NNP and_CC Riloff_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- used_VBN information_NN extraction_NN patterns_NNS to_TO identify_VB contextual_JJ clues_NNS that_WDT would_MD determine_VB the_DT compatibility_NN between_IN NPs_NNS ._.
Methods_NNS for_IN acquiring_VBG and_CC using_VBG such_JJ knowledge_NN are_VBP receiving_VBG increasing_VBG attention_NN in_IN 60_CD Proceedings_NNP of_IN the_DT Second_JJ Workshop_NNP on_IN NLP_NNP Challenges_NNS in_IN the_DT Information_NN Explosion_NNP Era_NNP -LRB-_-LRB- NLPIX_NNP 2010_CD -RRB-_-RRB- ,_, pages_NNS 60â_VBP $_$ ``_`` 68_CD ,_, Beijing_NNP ,_, August_NNP 2010_CD recent_JJ work_NN on_IN anaphora_NN resolution.Dagan_NN and_CC Itai_NN -LRB-_-LRB- 1990_CD -RRB-_-RRB- ,_, Bean_NNP and_CC Riloff_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- ,_, Yang_NNP and_CC Su_NNP -LRB-_-LRB- 2007_CD -RRB-_-RRB- ,_, and_CC Ponzetto_NNP and_CC Strube_NNP -LRB-_-LRB- 2006_CD -RRB-_-RRB- all_DT explored_VBN this_DT task_NN ._.
Bean_NNP and_CC Riloff_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- used_VBN high-precision_JJ hand-coded_JJ rules_NNS to_TO identify_VB coreferent_JJ mention_NN pairs_NNS ,_, which_WDT are_VBP then_RB used_VBN to_TO acquire_VB role_NN pairs_NNS that_IN they_PRP refer_VBP to_TO as_IN Caseframe_NNP Network_NNP features.They_NNP use_VB these_DT features_NNS to_TO improve_VB coreference_NN resolution_NN for_IN two_CD domain-specific_JJ corpora_NN involving_VBG terrorism_NN and_CC natural_JJ disasters_NNS ._.
CRF_NN +_CC Rule_NN system_NN represents_VBZ a_DT combination_NN of_IN CRF_NNP model_NN and_CC rule_NN based_VBN model_NN presented_VBN in_IN Zhang_NNP et_FW al._FW -LRB-_-LRB- 2006_CD -RRB-_-RRB- ._.
According_VBG to_TO the_DT results_NNS reported_VBN in_IN -LRB-_-LRB- R._NNP Zhang_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- ,_, CRF_NN performs_VBZ relatively_RB better_RBR on_IN Out-of-Vocabulary_JJ -LRB-_-LRB- OOV_NN -RRB-_-RRB- words_NNS while_IN Maximum_NNP Probability_NNP performs_VBZ well_RB on_IN IV_CD words_NNS ,_, so_RB a_DT model_NN combining_VBG the_DT advantages_NNS of_IN these_DT two_CD methods_NNS is_VBZ appealing_VBG ._.
We_PRP chose_VBD the_DT three_CD models_NNS that_WDT achieved_VBD at_IN least_JJS one_CD best_JJS score_NN in_IN the_DT closed_JJ tests_NNS from_IN Emerson_NNP -LRB-_-LRB- 2005_CD -RRB-_-RRB- ,_, as_RB well_RB as_IN the_DT sub-word-based_JJ model_NN of_IN Zhang_NNP ,_, Kikui_NNP ,_, and_CC Sumita_NNP -LRB-_-LRB- 2006_CD -RRB-_-RRB- for_IN comparison_NN ._.
Z06-a_NN and_CC Z06-b_NN represents_VBZ the_DT pure_JJ sub_NN -_: word_NN CRF_NN model_NN and_CC the_DT conﬁdence-based_JJ combination_NN of_IN CRF_NN and_CC rule-based_JJ models_NNS ,_, respectively_RB -LRB-_-LRB- Zhang_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- ;_: One_CD existing_VBG method_NN that_WDT is_VBZ based_VBN on_IN sub-word_JJ information_NN ,_, Zhang_NNP et_FW al._FW -LRB-_-LRB- 2006_CD -RRB-_-RRB- ,_, combines_VBZ a_DT C_NN R_NN F_NN and_CC a_DT rule-based_JJ model_NN ._.
We_PRP chose_VBD the_DT three_CD models_NNS that_WDT achieved_VBD at_IN least_JJS one_CD best_JJS score_NN in_IN the_DT closed_JJ tests_NNS from_IN Emerson_NNP -LRB-_-LRB- 2005_CD -RRB-_-RRB- ,_, as_RB well_RB as_IN the_DT sub-word-based_JJ model_NN of_IN Zhang_NNP et_FW al._FW -LRB-_-LRB- 2006_CD -RRB-_-RRB- for_IN comparison_NN ._.
Best05_NN represents_VBZ the_DT best_JJS system_NN of_IN the_DT Second_NNP International_NNP Chinese_NNP Word_NNP Segmentation_NNP Bakeoff_NNP on_IN the_DT corresponding_JJ data_NNS ;_: CRF_NN +_CC rule-system_NN represents_VBZ confidence_NN -_: based_VBN combination_NN of_IN CRF_NN and_CC rule-based_JJ models_NNS ,_, presented_VBN in_IN Zhang_NNP et_FW al._FW -LRB-_-LRB- 2006_CD -RRB-_-RRB- ._.
Also_RB ,_, the_DT CRF_NNP model_NN using_VBG maximum_NN subword-based_JJ tagging_NN -LRB-_-LRB- Zhang_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- Recently_RB -LRB-_-LRB- Zhang_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- proposed_VBD a_DT maximum_NN subword-based_JJ IOB_NN tagger_NN for_IN Chinese_JJ word_NN segmentation_NN ,_, and_CC our_PRP$ system_NN applies_VBZ their_PRP$ approach_NN which_WDT obtains_VBZ a_DT very_RB high_JJ accuracy_NN on_IN the_DT shared_JJ task_NN data_NNS from_IN previous_JJ SIGHAN_NNP competitions_NNS ._.
Part_NN of_IN the_DT work_NN using_VBG this_DT tool_NN was_VBD described_VBN by_IN -LRB-_-LRB- Zhang_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- ._.
The_DT approach_NN was_VBD reported_VBN to_TO achieve_VB the_DT highest_JJS word_NN segmentation_NN accuracy_NN using_VBG the_DT data_NNS from_IN the_DT second_JJ Sighan_NNP Bakeoff_NNP ._.
Note_VB a_DT lexicon_NN and_CC a_DT LM_NNP are_VBP the_DT only_JJ needed_JJ resources_NNS for_IN building_VBG a_DT dictionary-based_JJ CWS_NN ,_, like_IN the_DT â_NN $_$ œdict-hybrid_JJ ._.
â_RB $_$ -LRB-_-LRB- Zhang_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- We_PRP used_VBD the_DT â_JJ $_$ œdict-hybridâ_JJ $_$ to_TO segment_NN the_DT SMT_NN training_NN corpus_NN and_CC test_NN data_NNS ._.
Some_DT previous_JJ work_NN -LRB-_-LRB- Peng_NNP et_FW al._FW ,_, 2004_CD ;_: Tseng_NNP et_FW al._FW ,_, 2005_CD ;_: Low_JJ et_FW al._FW ,_, 2005_CD -RRB-_-RRB- illustrated_VBD the_DT effectiveness_NN of_IN using_VBG characters_NNS as_IN tagging_VBG units_NNS ,_, while_IN literatures_NNS -LRB-_-LRB- Zhang_NNP et_FW al._FW ,_, 2006_CD ;_: Zhao_NNP and_CC Kit_NN ,_, 2007a_NN ;_: Zhang_NNP and_CC Clark_NNP ,_, 2007_CD -RRB-_-RRB- focus_NN on_IN employing_VBG lexical_JJ words_NNS or_CC subwords_NNS as_IN tagging_VBG units_NNS ._.
For_IN this_DT purpose_NN ,_, our_PRP$ system_NN is_VBZ based_VBN on_IN a_DT combination_NN of_IN subword-based_JJ tagging_NN method_NN -LRB-_-LRB- Zhang_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- and_CC accessor_NN variety-based_JJ new_JJ word_NN recognition_NN method_NN -LRB-_-LRB- Feng_NNP et_FW al._FW ,_, 2004_CD -RRB-_-RRB- ._.
Feature_NNP Template_NNP Description_NN f_LS -RRB-_-RRB- in_IN -LRB-_-LRB- str_NN ,_, subword-list_JJ -RRB-_-RRB- is_VBZ str_NN in_IN subword_JJ list_NN g_NN -RRB-_-RRB- in_IN -LRB-_-LRB- str_NN ,_, confident-word-list_NN -RRB-_-RRB- is_VBZ str_NN in_IN confident-word_JJ list_NN Table_NNP 2_CD See_VB the_DT details_NNS of_IN subword-based_JJ Chinese_JJ word_NN segmentation_NN in_IN -LRB-_-LRB- Zhang_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- Although_IN it_PRP can_MD be_VB used_VBN in_IN its_PRP$ current_JJ form_NN for_IN data-driven_JJ Sentiment_NN Analysis_NN -LRB-_-LRB- Pang_NNP et_FW al._FW ,_, 2002_CD ;_: Pang_NNP and_CC Lee_NNP ,_, 2004_CD ;_: Kim_NNP and_CC Hovy_NNP ,_, 2004_CD ;_: Popescu_NNP and_CC Etzioni_NNP ,_, 2005_CD ;_: Su_NNP and_CC Markert_NNP ,_, 2009_CD ;_: DanescuNiculescu_NNP -_: Mizil_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ,_, or_CC for_IN lexical_JJ sentiment_NN analysis_NN tasks_NNS -LRB-_-LRB- Strapparava_NN and_CC Mihalcea_NNP ,_, 2007_CD ;_: Su_NNP and_CC Markert_NNP ,_, 2009_CD -RRB-_-RRB- ,_, it_PRP could_MD also_RB be_VB used_VBN as_IN a_DT training_NN set_VBN for_IN supervised_JJ classifiers_NNS that_WDT would_MD subsequently_RB be_VB applied_VBN for_IN the_DT improvement_NN of_IN Q-WordNet_NN ._.
Although_IN it_PRP can_MD be_VB used_VBN in_IN its_PRP$ current_JJ form_NN for_IN data-driven_JJ Sentiment_NN Analysis_NN -LRB-_-LRB- Pang_NNP et_FW al._FW ,_, 2002_CD ;_: Pang_NNP and_CC Lee_NNP ,_, 2004_CD ;_: Kim_NNP and_CC Hovy_NNP ,_, 2004_CD ;_: Popescu_NNP and_CC Etzioni_NNP ,_, 2005_CD ;_: Su_NNP and_CC Markert_NNP ,_, 2009_CD ;_: DanescuNiculescu_NNP -_: Mizil_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ,_, or_CC for_IN lexical_JJ sentiment_NN analysis_NN tasks_NNS -LRB-_-LRB- Strapparava_NN and_CC Mihalcea_NNP ,_, 2007_CD ;_: Su_NNP and_CC Markert_NNP ,_, 2009_CD -RRB-_-RRB- ,_, it_PRP could_MD also_RB be_VB used_VBN as_IN a_DT training_NN set_VBN for_IN supervised_JJ classifiers_NNS that_WDT would_MD subsequently_RB be_VB applied_VBN for_IN the_DT improvement_NN of_IN Q-WordNet_NN ._.
Pang_NN -LSB-_-LRB- 4_CD -RSB-_-RRB- and_CC Su_FW -LSB-_-LRB- 5_CD -RSB-_-RRB- both_CC optimized_VBD their_PRP$ multi-classification_JJ results_NNS using_VBG the_DT Mincut_NNP model_NN ._.
The_DT MWE_NNP productions_NNS seem_VBP to_TO overlap_VB with_IN well_RB -_: known_JJ linguistic_JJ phenomena_NNS consider_VBP Fahrni_NNP and_CC Klenner_NNP -LRB-_-LRB- 2008_CD -RRB-_-RRB- and_CC their_PRP$ claim_NN that_IN most_JJS adjectives_NNS have_VBP a_DT polarity_NN that_WDT is_VBZ dependent_JJ on_IN the_DT target_NN they_PRP modify_VBP instead_RB of_IN having_VBG a_DT prior_JJ polarity_NN that_WDT holds_VBZ independently_RB of_IN the_DT target_NN ,_, or_CC the_DT observation_NN of_IN Su_NNP and_CC Markert_NNP -LRB-_-LRB- 2009_CD -RRB-_-RRB- that_WDT sentiment_NN should_MD be_VB dependent_JJ on_IN word_NN senses_NNS instead_RB of_IN word_NN forms_NNS -LRB-_-LRB- which_WDT would_MD capture_VB a_DT large_JJ number_NN of_IN examples_NNS within_IN the_DT expression_NN strengthening_VBG category_NN -RRB-_-RRB- ._.
Su_FW and_CC Markert_NNP -LRB-_-LRB- 2009_CD -RRB-_-RRB- propose_VBP a_DT semi-supervised_JJ minimum_NN cut_NN framework_NN to_TO label_VB word_NN sense_NN entries_NNS in_IN WordNet_NNP with_IN subjectivity_NN information_NN ._.
In_IN more_JJR recent_JJ work_NN it_PRP has_VBZ been_VBN argued_VBN that_IN the_DT classification_NN of_IN subjectivity_NN vs._CC objectivity_NN needs_VBZ to_TO be_VB done_VBN independently_RB from_IN the_DT polarity_NN identification_NN -LRB-_-LRB- Gyamfi_NNP et_FW al._FW ,_, 2009_CD ;_: Su_NNP and_CC Markert_NNP ,_, 2009_CD -RRB-_-RRB- ._.
For_IN example_NN ,_, Su_NNP and_CC Markert_NNP -LRB-_-LRB- 2009_CD -RRB-_-RRB- make_VBP use_NN of_IN both_CC Wordnet_JJ definitions_NNS and_CC Wordnet_JJ relations_NNS and_CC achieve_VB an_DT accuracy_NN of_IN 84.6_CD %_NN on_IN all_DT parts-of-speech_NN ._.
Semi-supervised_JJ techniques_NNS on_IN text_NN mining_NN were_VBD applied_VBN by_IN Fangzhong_NNP and_CC Markert_NNP -LRB-_-LRB- 2009_CD -RRB-_-RRB- ._.
The_DT antonymous_JJ classes_NNS of_IN each_DT are_VBP -_: effect_NN events_NNS Su_NNP and_CC Markert_NNP -LRB-_-LRB- 2009_CD -RRB-_-RRB- adopt_VB a_DT semi-supervised_JJ mincut_NN method_NN to_TO recognize_VB the_DT subjectivity_NN of_IN word_NN senses_NNS ._.
One_CD related_JJ line_NN of_IN research_NN is_VBZ to_TO automatically_RB assign_VB subjectivity_NN and/or_CC polarity_NN labels_NNS to_TO word_NN senses_NNS in_IN a_DT dictionary_NN -LRB-_-LRB- Valitutti_NNP et_FW al._FW ,_, 2004_CD ;_: An_DT -_: dreevskaia_NN and_CC Bergler_NNP ,_, 2006_CD ;_: Wiebe_NNP and_CC Mihalcea_NNP ,_, 2006_CD ;_: Esuli_NNP and_CC Sebastiani_NNP ,_, 2007_CD ;_: Su_NNP and_CC Markert_NNP ,_, 2009_CD -RRB-_-RRB- ._.
We_PRP explore_VBP the_DT different_JJ options_NNS for_IN context_NN and_CC feature_NN se_FW 1_CD See_VB -LRB-_-LRB- Chan_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- for_IN the_DT relevance_NN of_IN word_NN sense_NN disambiguation_NN and_CC -LRB-_-LRB- Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- for_IN the_DT role_NN of_IN prepositions_NNS in_IN MT._NNP 454_CD Coling_JJ 2010_CD Recent_JJ work_NN have_VBP shown_VBN that_IN SMT_NNP benefits_NNS a_DT lot_NN from_IN exploiting_VBG large_JJ amount_NN of_IN features_NNS -LRB-_-LRB- Liang_NNP et_FW al._FW ,_, 2006_CD ;_: Tillmann_NNP and_CC Zhang_NNP ,_, 2006_CD ;_: Watanabe_NNP et_FW al._FW ,_, 2007_CD ;_: Blunsom_NNP et_FW al._FW ,_, 2008_CD ;_: Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ._.
Overfitting_JJ problem_NN often_RB comes_VBZ when_WRB training_VBG many_JJ features_NNS on_IN a_DT small_JJ data_NNS -LRB-_-LRB- Watanabe_NNP et_FW al._FW ,_, 880_CD 2007_CD ;_: Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ._.
-LRB-_-LRB- 3_LS -RRB-_-RRB- Removing_VBG e1_NN and_CC e5_NN in_IN t1_NN and_CC adding_VBG e2_NN leads_VBZ to_TO another_DT reference_NN derivation_NN t3_NN ._.
Generally_RB ,_, this_DT is_VBZ done_VBN by_IN deleting_VBG a_DT node_NN X0_NN ,1_CD ._.
ing_VBG to_TO constructing_VBG the_DT oracle_NN reference_NN -LRB-_-LRB- Liang_NNP et_FW al._FW ,_, 2006_CD ;_: Watanabe_NNP et_FW al._FW ,_, 2007_CD ;_: Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ,_, which_WDT is_VBZ nontrivial_JJ for_IN SMT_NNP and_CC needs_VBZ to_TO be_VB determined_VBN experimentally_RB ._.
Following_VBG -LRB-_-LRB- Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ,_, we_PRP only_RB use_VBP 100_CD most_RBS frequent_JJ words_NNS for_IN word_NN context_NN feature_NN ._.
Lexicalize_NN operator_NN is_VBZ used_VBN more_RBR frequently_RB mainly_RB dues_NNS to_TO that_IN the_DT reference_NN derivations_NNS are_VBP initialized_VBN with_IN reusable_JJ -LRB-_-LRB- thus_RB Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ,_, gradient_NN descent_NN -LRB-_-LRB- Blunsom_NN et_FW al._FW ,_, 2008_CD ;_: Blunsom_NNP and_CC Osborne_NNP ,_, 2008_CD -RRB-_-RRB- ._.
The_DT MIRA_NNP technique_NN of_IN Chiang_NNP et_FW al._FW has_VBZ been_VBN shown_VBN to_TO perform_VB well_RB on_IN large-scale_JJ tasks_NNS with_IN hundreds_NNS or_CC thousands_NNS of_IN features_NNS -LRB-_-LRB- 2009_CD -RRB-_-RRB- ._.
The_DT most_RBS prominent_JJ example_NN of_IN a_DT tuning_NN method_NN that_WDT performs_VBZ well_RB on_IN high-dimensionality_JJ candidate_NN spaces_NNS is_VBZ the_DT MIRA-based_JJ approach_NN used_VBN by_IN Watanabe_NNP et_FW al._FW -LRB-_-LRB- 2007_CD -RRB-_-RRB- and_CC Chiang_NNP et_FW al._FW -LRB-_-LRB- 2008b_NN ;_: 2009_CD -RRB-_-RRB- ._.
We_PRP used_VBD the_DT following_VBG feature_NN classes_NNS in_IN SBMT_NNP and_CC PBMT_NNP extended_VBD scenarios_NNS Chiang_NNP et_FW al._FW -LRB-_-LRB- 2009_CD -RRB-_-RRB- ,_, Section_NN 4.1_CD -RRB-_-RRB- 5.4.1_CD MERT_NNP We_PRP used_VBD David_NNP Chiangs_NNP CMERT_NNP implementation_NN We_PRP for_IN the_DT most_JJS part_NN follow_VBP the_DT MIRA_NNP algorithm_NN for_IN machine_NN translation_NN as_IN described_VBN by_IN Chiang_NNP et_FW al._FW -LRB-_-LRB- 2009_CD -RRB-_-RRB- 12_CD but_CC instead_RB of_IN using_VBG the_DT 10-best_JJS of_IN each_DT of_IN the_DT best_JJS hw_NN ,_, hw_NN +_CC g_NN ,_, and_CC hw_SYM -_: g_NN ,_, we_PRP use_VBP the_DT 30-best_JJ according_VBG to_TO hw_VB .13_CD We_PRP use_VBP the_DT same_JJ sentence-level_JJ BLEU_NN calculated_VBN in_IN the_DT context_NN of_IN previous_JJ 1-best_JJ translations_NNS as_IN Chiang_NNP et_FW al._FW -LRB-_-LRB- 2008b_NN ;_: 2009_CD -RRB-_-RRB- ._.
Additionally_RB ,_, we_PRP used_VBD 50,000_CD sparse_JJ ,_, binary-valued_JJ source_NN and_CC target_NN features_NNS based_VBN on_IN Chiang_NNP et_FW al._FW -LRB-_-LRB- 2009_CD -RRB-_-RRB- Alternatively_RB ,_, by_IN using_VBG the_DT large_JJ -_: margin_NN optimizer_NN in_IN -LRB-_-LRB- Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- and_CC moving_VBG it_PRP into_IN the_DT for-each_JJ loop_NN -LRB-_-LRB- lines_NNS 49_CD -RRB-_-RRB- ,_, one_PRP can_MD get_VB an_DT online_JJ algorithm_NN such_JJ PMOMIRA_NN ._.
Online_JJ large-margin_JJ algorithms_NNS ,_, such_JJ as_IN MIRA_NNP ,_, have_VBP also_RB gained_VBN prominence_NN in_IN SMT_NNP ,_, thanks_NNS to_TO their_PRP$ ability_NN to_TO learn_VB models_NNS in_IN high-dimensional_JJ feature_NN spaces_NNS -LRB-_-LRB- Watanabe_NNP et_FW al._FW ,_, 2007_CD ;_: Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ._.
task_NN Corpus_NNP Sentences_NNS Tokens_NNS En_IN Zh/Ar_NN MT05_NN 1082_CD 35k_CD 33k_NN training_NN 1M_NN 23.7_CD M_NN 22.8_CD M_NN tune_NN -LRB-_-LRB- MT06_NN -RRB-_-RRB- 1797_CD 55k_JJ 49k_NN baselines_NNS The_DT bound_VBN constraint_NN B_NN was_VBD set_VBN to_TO 1.4_CD The_DT approximate_JJ sentence-level_JJ BLEU_NN cost_NN i_FW is_VBZ computed_VBN in_IN a_DT manner_NN similar_JJ to_TO -LRB-_-LRB- Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ,_, namely_RB ,_, in_IN the_DT context_NN of_IN previous_JJ 1-best_JJ translations_NNS of_IN the_DT tuning_NN set_NN ._.
For_IN experiments_NNS with_IN a_DT larger_JJR feature_NN set_NN ,_, we_PRP introduced_VBD additional_JJ lexical_JJ and_CC non-lexical_JJ sparse_JJ Boolean_NN features_NNS of_IN the_DT form_NN commonly_RB found_VBN in_IN the_DT literature_NN -LRB-_-LRB- Chiang_NNP et_FW al._FW ,_, 2009_CD ;_: Watan_NNP 4_CD We_PRP also_RB conducted_VBD an_DT investigation_NN into_IN the_DT setting_NN of_IN the_DT B_NN parameter_NN ._.
Recently_RB ,_, a_DT simple_JJ method_NN was_VBD presented_VBN in_IN -LRB-_-LRB- Chiang_NNP eta_NN !_. ._.
,_, 2009_CD -RRB-_-RRB- ,_, which_WDT keeps_VBZ partial_JJ English_NNP and_CC Urdu_NNP words_NNS in_IN the_DT training_NN data_NNS for_IN alignment_NN training_NN ._.
First_RB ,_, we_PRP used_VBD features_NNS proposed_VBN by_IN Chiang_NNP et_FW al._FW -LRB-_-LRB- 2009_CD -RRB-_-RRB- These_DT challenges_NNS have_VBP prompted_VBN some_DT researchers_NNS to_TO move_VB away_RB from_IN MERT_NNP ,_, in_IN favor_NN of_IN linearly_RB decomposable_JJ approximations_NNS of_IN the_DT evaluation_NN metric_JJ -LRB-_-LRB- Chiang_NNP et_FW al._FW ,_, 2009_CD ;_: Hopkins_NNP and_CC May_NNP ,_, 2011_CD ;_: Cherry_NNP and_CC Foster_NNP ,_, 2012_CD -RRB-_-RRB- ,_, which_WDT correspond_VBP to_TO easier_JJR optimization_NN problems_NNS and_CC which_WDT naturally_RB incorporate_VB regularization_NN ._.
In_IN particular_JJ ,_, recent_JJ work_NN -LRB-_-LRB- Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- has_VBZ shown_VBN that_IN adding_VBG thousands_NNS or_CC tens_NNS of_IN thousands_NNS of_IN features_NNS can_MD improve_VB MT_NNP quality_NN when_WRB weights_NNS are_VBP optimized_VBN using_VBG a_DT margin-based_JJ approximation_NN ._.
This_DT observation_NN conrms_NNS previous_JJ ndings_NNS -LRB-_-LRB- Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- regarding_VBG the_DT inability_NN of_IN the_DT MERT_NNP algorithm_NN to_TO converge_VB on_IN an_DT optimal_JJ set_NN of_IN weights_NNS for_IN a_DT reasonably_RB large_JJ number_NN of_IN parameters_NNS ._.
The_DT MERT_NNP algorithm_NN is_VBZ known_VBN to_TO be_VB unable_JJ to_TO learn_VB optimal_JJ weights_NNS for_IN large_JJ parameter_NN settings_NNS -LRB-_-LRB- Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ._.
We_PRP would_MD also_RB like_VB to_TO look_VB into_IN alternative_JJ tuning_NN techniques_NNS ,_, especially_RB ones_NNS based_VBN on_IN the_DT MIRA_NNP algorithm_NN to_TO improve_VB the_DT quality_NN of_IN log-linear_JJ mixture_NN adaptation_NN in_IN large_JJ parameter_NN settings_NNS -LRB-_-LRB- Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ._.
Chiang_NNP et_FW w_FW -LRB-_-LRB- X_NN -LRB-_-LRB- ,_, ,_, -RRB-_-RRB- -RRB-_-RRB- =_JJ ii_LS -LRB-_-LRB- 2_LS -RRB-_-RRB- i_FW al._FW 2009_CD -RRB-_-RRB- define_VBP new_JJ translational_JJ features_NNS using_VBG neighbouring_JJ word_NN contexts_NNS of_IN the_DT source_NN phrase_NN ,_, which_WDT are_VBP directly_RB integrated_VBN into_IN the_DT translation_NN model_NN of_IN Hiero_NN system_NN ._.
For_IN example_NN ,_, Chiang_NNP et_FW al._FW -LSB-_-LRB- 3_CD -RSB-_-RRB- designed_VBN many_JJ target-side_JJ syntax_NN features_NNS to_TO improve_VB the_DT string-to-tree_JJ translation_NN ._.
Moreover_RB ,_, to_TO establish_VB a_DT strong_JJ baseline_NN ,_, we_PRP also_RB include_VBP the_DT discount_NN feature_NN used_VBN by_IN Chiang_NNP et_FW al._FW -LSB-_-LRB- 3_CD -RSB-_-RRB- in_IN our_PRP$ baseline_NN string-to-tree_NN model_NN ._.
When_WRB the_DT number_NN of_IN features_NNS is_VBZ too_RB large_JJ ,_, even_RB popular_JJ reranking_VBG algorithms_NNS such_JJ as_IN SVM_NN -LRB-_-LRB- Shen_NNP et_FW al._FW ,_, 2004_CD -RRB-_-RRB- and_CC MIRA_NN -LRB-_-LRB- Watanabe_NNP et_FW al._FW ,_, 2007_CD ;_: Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- may_MD fail_VB ._.
Recent_JJ work_NN by_IN -LRB-_-LRB- Chiang_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- describes_VBZ new_JJ features_NNS for_IN hierarchical_JJ phrase-based_JJ MT_NN ,_, while_IN -LRB-_-LRB- Collins_NNP and_CC Koo_NNP ,_, 2005_CD -RRB-_-RRB- describes_VBZ features_NNS for_IN parsing_NN ._.
Chiang_NNP et_FW al._FW -LRB-_-LRB- 2009_CD -RRB-_-RRB- added_VBD thousands_NNS of_IN linguistically-motivated_JJ features_NNS to_TO hierarchical_JJ and_CC syntax_NN systems_NNS ,_, however_RB ,_, the_DT source_NN syntax_NN features_NNS are_VBP derived_VBN from_IN the_DT research_NN above_IN ._.
A_DT non-exhaustive_JJ sample_NN is_VBZ given_VBN below_IN The_DT model_NN also_RB differs_VBZ from_IN -LRB-_-LRB- Marton_NNP and_CC Resnik_NNP ,_, 2008_CD ;_: Chiang_NNP et_FW al._FW ,_, 2008_CD ,_, 2009_CD -RRB-_-RRB- by_IN adding_VBG informative_JJ labels_NNS to_TO rule_VB non-terminals_NNS and_CC requiring_VBG them_PRP to_TO match_VB the_DT source_NN span_NN label_NN ._.
Beesley_NNP and_CC Karttunen_NNP -LRB-_-LRB- 2000_CD -RRB-_-RRB- describe_VBP a_DT technique_NN ,_, called_VBN compile-replace_NN ,_, for_IN constructing_VBG FSTs_NNS ,_, which_WDT involves_VBZ reapplying_VBG the_DT regular-expression_NN compiler_NN to_TO its_PRP$ own_JJ output_NN ._.
Beesleyl7l_NN presents_VBZ a_DT finite-state_JJ morphological_JJ analyzer_NN for_IN Arabic_NNP ,_, which_WDT displays_VBZ the_DT root_NN ,_, pattern_NN and_CC prefixes/suffixes_NNS ._.
Thus_RB ,_, we_PRP employ_VBP the_DT com_NN pile-replace_NN feature_NN in_IN xfst_NN -LRB-_-LRB- Beesley_NNP &_CC Karttunen_NNP ,_, 2000_CD -RRB-_-RRB- ._.
This_DT feature_NN allows_VBZ the_DT repetition_NN of_IN arbi_NN trarily_RB complex_JJ sublanguages_NNS by_IN specifying_VBG the_DT brackets_NNS '_POS ''_'' '_'' -LSB-_-LRB- ''_'' and_CC ``_`` A_DT 1_CD ''_'' to_TO mark_VB the_DT domain_NN of_IN re_NN duplication_NN ._.
Beesley_NNP and_CC Karttunen_NNP -LRB-_-LRB- 2000_CD -RRB-_-RRB- describe_VBP a_DT technique_NN ,_, called_VBN compile-replace_NN ,_, for_IN constructing_VBG FSTs_NNS ,_, which_WDT involves_VBZ reapplying_VBG the_DT regular-expression_NN compiler_NN to_TO its_PRP$ own_JJ output_NN ._.
Even_RB total_JJ reduplication_NN can_MD be_VB characterized_VBN without_IN going_VBG outside_IN the_DT regular_JJ languages_NNS -LRB-_-LRB- Beesley_NNP and_CC Karttunen_NNP 2000_CD -RRB-_-RRB- ._.
In_IN this_DT section_NN we_PRP will_MD show_VB in_IN detail_NN how_WRB Realizational_NNP Morphology_NNP can_MD be_VB expressed_VBN in_IN terms_NNS of_IN the_DT parc/xrce_NN regular_JJ expression_NN calculus_NN as_IN dened_VBN in_IN Beesley_NNP and_CC Karttunen_NNP -LSB-_-LRB- 4_CD -RSB-_-RRB- ._.
The_DT application_NN of_IN the_DT merge_VBP algorithm_NN to_TO the_DT lower-side_NN of_IN the_DT relation_NN is_VBZ performed_VBN by_IN the_DT COMPILER_NNP EPL_NN ACE_NN algorithm_NN -LRB-_-LRB- Beesley_NN and_CC Karttunen_NNP ,_, 2000_CD -RRB-_-RRB- ,11_CD and_CC the_DT result_NN is_VBZ shown_VBN in_IN Figure_NN 7_CD ._.
Beesley_NNP and_CC Karttunen_NNP -LRB-_-LRB- 2000_CD -RRB-_-RRB- described_VBD a_DT new_JJ technique_NN for_IN constructing_VBG finite-state_JJ transducers_NNS that_WDT involves_VBZ reapplying_VBG a_DT regular-expression_NN compiler_NN to_TO its_PRP$ own_JJ output_NN ._.
A_DT large-scale_JJ implementation_NN of_IN the_DT Arabic_JJ morphological_JJ system_NN is_VBZ the_DT Xerox_NNP Arabic_NNP Morphologi_NNP cal_NNP Analyzer_NNP and_CC Generator_NNP -LRB-_-LRB- Beesley_NNP and_CC Karttunen_NNP ,2000_CD ;_: Beesley_NNP ,_, 2001_CD -RRB-_-RRB- ._.
In_IN the_DT last_JJ decade_NN ,_, finite-state_JJ approaches_NNS to_TO phonology_NN -LRB-_-LRB- Gildea_NNP and_CC Jurafsky_NNP ,_, 1996_CD ;_: Beesley_NNP and_CC Karttunen_NNP ,_, 2000_CD -RRB-_-RRB- have_VBP effectively_RB brought_VBN theoretical_JJ linguistic_JJ work_NN on_IN rewrite_VB rules_NNS into_IN the_DT computational_JJ realm_NN ._.
The_DT interdigitation_NN is_VBZ handled_VBN using_VBG a_DT compile-replace_JJ process_NN using_VBG the_DT replace_VB operator_NN -LRB-_-LRB- Karttunen_NN and_CC Beesley_NNP ,_, 2000_CD -RRB-_-RRB- -LRB-_-LRB- Karttunen_NNP ,_, 1995_CD -RRB-_-RRB- ._.
Another_DT related_JJ task_NN is_VBZ supersense_JJ tagging_NN -LRB-_-LRB- Ciaramita_NN and_CC Johnson_NNP ,_, 2003_CD ;_: Curran_NNP ,_, 2005_CD ;_: Ciaramita_NNP and_CC Altun_NNP ,_, 2006_CD -RRB-_-RRB- ._.
Although_IN we_PRP could_MD adapt_VB our_PRP$ method_NN for_IN use_NN with_IN an_DT automatically_RB induced_VBN inventory_NN ,_, our_PRP$ method_NN which_WDT uses_VBZ WordNet_NNP might_MD also_RB be_VB combined_VBN with_IN one_CD that_WDT can_MD automatically_RB find_VB new_JJ senses_NNS from_IN text_NN and_CC then_RB relate_VBP these_DT to_TO WordNet_NNP synsets_NNS ,_, as_IN Ciaramita_NNP and_CC Johnson_NNP -LRB-_-LRB- 2003_CD -RRB-_-RRB- and_CC Curran_NNP -LRB-_-LRB- 2005_CD -RRB-_-RRB- do_VBP with_IN unknown_JJ nouns_NNS ._.
An_DT additional_JJ potential_NN is_VBZ to_TO integrate_VB automatically_RB acquired_VBN relationships_NNS with_IN the_DT information_NN found_VBN in_IN WordNet_NNP ,_, which_WDT seems_VBZ to_TO suffer_VB from_IN several_JJ serious_JJ limitations_NNS -LRB-_-LRB- Curran_NNP 2005_CD -RRB-_-RRB- ,_, and_CC typically_RB overlaps_VBZ to_TO a_DT rather_RB limited_JJ extent_NN with_IN the_DT output_NN of_IN automatic_JJ acquisition_NN methods_NNS ._.
There_EX are_VBP ,_, however_RB ,_, approaches_VBZ to_TO the_DT complementary_JJ problem_NN of_IN determining_VBG the_DT closest_JJS known_JJ sense_NN for_IN unknown_JJ words_NNS -LRB-_-LRB- Widdows_NNS ,_, 2003_CD ;_: Curran_NNP ,_, 2005_CD ;_: Burchardt_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ,_, which_WDT can_MD be_VB viewed_VBN as_IN the_DT logical_JJ next_JJ step_NN after_IN unknown_JJ sense_NN detection_NN ._.
Possibilities_NNS include_VBP associating_VBG items_NNS with_IN similar_JJ existing_VBG senses_NNS -LRB-_-LRB- Widdows_NNS ,_, 2003_CD ;_: Curran_NNP ,_, 2005_CD ;_: Burchardt_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- or_CC clustering_VBG them_PRP into_IN approximate_JJ senses_NNS ._.
While_IN contextual_JJ information_NN is_VBZ the_DT primary_JJ source_NN of_IN information_NN used_VBN in_IN WSD_NN research_NN and_CC has_VBZ been_VBN used_VBN for_IN acquiring_VBG semantic_JJ lexicons_NNS and_CC classifying_VBG unknown_JJ words_NNS in_IN other_JJ languages_NNS -LRB-_-LRB- e.g._FW ,_, Roark_NNP and_CC Charniak_NNP 1998_CD ;_: Ci_NN aramita_NN 2003_CD ;_: Curran_NNP 2005_CD -RRB-_-RRB- More_RBR re_JJ cently_NN ,_, the_DT task_NN of_IN automatic_JJ supersense_NN tagging_NN has_VBZ emerged_VBN for_IN English_NNP -LRB-_-LRB- Ciaramita_NNP and_CC Johnson_NNP ,_, 2003_CD ;_: Curran_NNP ,_, 2005_CD ;_: Ciaramita_NNP and_CC Altun_NNP ,_, 2006_CD ;_: PaaÃŸ_NN and_CC Reichartz_NNP ,_, 2009_CD -RRB-_-RRB- ,_, as_RB well_RB as_IN for_IN Italian_JJ -LRB-_-LRB- Picca_NNP et_FW al._FW ,_, 2008_CD ;_: Picca_NNP et_FW al._FW ,_, 2009_CD ;_: Attardi_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- and_CC Chinese_JJ -LRB-_-LRB- Qiu_NNP et_FW al._FW ,_, 2011_CD -RRB-_-RRB- ,_, languages_NNS with_IN WordNetsmapped_JJ to_TO English_NNP WordNet_NNP .3_NN In_IN principle_NN ,_, we_PRP be_VB lieve_NN supersenses_NNS ought_MD to_TO apply_VB to_TO nouns_NNS and_CC verbsin_VB any_DT language_NN ,_, and_CC need_MD not_RB depend_VB on_IN the_DT avail_NN ability_NN of_IN a_DT semantic_JJ lexicon_NN .4_CD In_IN this_DT work_NN we_PRP focuson_VBP the_DT noun_NN SSTs_NNS ,_, summarized_VBN in_IN figure_NN 2_CD and_CC ap_NN plied_VBD to_TO an_DT Arabic_JJ sentence_NN in_IN figure_NN 1_CD ._.
Thus_RB ,_, some_DT research_NN has_VBZ been_VBN focused_VBN on_IN deriving_VBG different_JJ sense_NN groupings_NNS to_TO overcome_VB the_DT fineâ_NN $_$ ``_`` grained_VBN distinctions_NNS of_IN WN_NN -LRB-_-LRB- Hearst_NNP and_CC SchuÂ_NNP ¨_CD tze_NN ,_, 1993_CD -RRB-_-RRB- -LRB-_-LRB- Peters_NNP et_FW al._FW ,_, 1998_CD -RRB-_-RRB- -LRB-_-LRB- Mihalcea_NNP and_CC Moldo_NNP -_: van_NN ,_, 2001_CD -RRB-_-RRB- -LRB-_-LRB- Agirre_NNP et_FW al._FW ,_, 2003_CD -RRB-_-RRB- and_CC on_IN using_VBG predefined_JJ sets_NNS of_IN sense-groupings_NNS for_IN learning_VBG class-based_JJ classifiers_NNS for_IN WSD_NN -LRB-_-LRB- Segond_NN et_FW al._FW ,_, 1997_CD -RRB-_-RRB- -LRB-_-LRB- Ciaramita_NNP and_CC Johnson_NNP ,_, 2003_CD -RRB-_-RRB- -LRB-_-LRB- Villarejo_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- -LRB-_-LRB- Curran_NNP ,_, 2005_CD -RRB-_-RRB- -LRB-_-LRB- Ciaramita_NNP and_CC Altun_NNP ,_, 2006_CD -RRB-_-RRB- ._.
In_IN contrast_NN ,_, some_DT research_NN have_VBP been_VBN focused_VBN on_IN using_VBG predefined_JJ sets_NNS of_IN sense-groupings_NNS for_IN learning_VBG class-based_JJ classifiers_NNS for_IN WSD_NN -LRB-_-LRB- Segond_NN et_FW al._FW ,_, 1997_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Ciaramita_NNP and_CC Johnson_NNP ,_, 2003_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Villarejo_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Curran_NNP ,_, 2005_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Kohomban_NNP and_CC Lee_NNP ,_, 2005_CD -RRB-_-RRB- and_CC -LRB-_-LRB- Ciaramita_NNP and_CC Altun_NNP ,_, 2006_CD -RRB-_-RRB- ._.
Distributed_VBN representations_NNS are_VBP useful_JJ in_IN capturing_VBG such_JJ meaning_NN for_IN individual_JJ words_NNS -LRB-_-LRB- Sato_NNP et_FW al._FW ,_, 2008_CD ;_: Maas_NNP and_CC Ng_NNP ,_, 2010_CD ;_: Curran_NNP ,_, 2005_CD -RRB-_-RRB- ._.
Supersense_NNP tagging_NN -LRB-_-LRB- Ciaramita_NN and_CC Johnson_NNP ,_, 2003_CD ;_: Curran_NNP ,_, 2005_CD -RRB-_-RRB- evaluates_VBZ a_DT modelâ_JJ $_$ ™_CD s_NNS ability_NN to_TO cluster_VB words_NNS by_IN their_PRP$ semantics_NNS ._.
A_DT concept_NN analogous_JJ to_TO our_PRP$ notion_NN of_IN meta_NN sense_NN -LRB-_-LRB- i.e._FW ,_, senses_NNS beyond_IN single_JJ words_NNS -RRB-_-RRB- has_VBZ been_VBN used_VBN in_IN previous_JJ work_NN on_IN class-based_JJ WSD_NN -LRB-_-LRB- Yarowsky_NNP ,_, 1992_CD ;_: Curran_NNP ,_, 2005_CD ;_: Izquierdo_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ,_, and_CC indeed_RB ,_, the_DT CAM_NNP might_MD be_VB used_VBN for_IN class-based_JJ WSD_NN as_RB well_RB ._.
Previous_JJ work_NN on_IN prediction_NN at_IN the_DT supersense_JJ level_NN -LRB-_-LRB- Ciaramita_NN and_CC Johnson_NNP ,_, 2003_CD ;_: Curran_NNP ,_, 2005_CD -RRB-_-RRB- has_VBZ focused_VBN on_IN lexical_JJ acquisition_NN -LRB-_-LRB- nouns_NNS exclusively_RB -RRB-_-RRB- ,_, thus_RB aiming_VBG at_IN word_NN type_NN classification_NN rather_RB than_IN tagging_VBG ._.
Another_DT related_JJ task_NN is_VBZ supersense_JJ tagging_NN -LRB-_-LRB- Ciaramita_NN and_CC Johnson_NNP ,_, 2003_CD ;_: Curran_NNP ,_, 2005_CD ;_: Ciaramita_NNP and_CC Altun_NNP ,_, 2006_CD -RRB-_-RRB- ._.
In_IN contrast_NN ,_, some_DT research_NN have_VBP been_VBN focused_VBN on_IN using_VBG predefined_JJ sets_NNS of_IN sense-groupings_NNS for_IN learning_VBG class-based_JJ classifiers_NNS for_IN WSD_NN -LRB-_-LRB- Segond_NN et_FW al._FW ,_, 1997_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Ciaramita_NNP and_CC Johnson_NNP ,_, 2003_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Villarejo_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Curran_NNP ,_, 2005_CD -RRB-_-RRB- and_CC -LRB-_-LRB- Ciaramita_NNP and_CC Altun_NNP ,_, 2006_CD -RRB-_-RRB- ._.
Although_IN we_PRP could_MD adapt_VB our_PRP$ method_NN for_IN use_NN with_IN an_DT automatically_RB induced_VBN inventory_NN ,_, our_PRP$ method_NN which_WDT uses_VBZ WordNet_NNP might_MD also_RB be_VB combined_VBN with_IN one_CD that_WDT can_MD automatically_RB find_VB new_JJ senses_NNS from_IN text_NN and_CC then_RB relate_VBP these_DT to_TO WordNet_NNP synsets_NNS ,_, as_IN Ciaramita_NNP and_CC Johnson_NNP -LRB-_-LRB- 2003_CD -RRB-_-RRB- and_CC Curran_NNP -LRB-_-LRB- 2005_CD -RRB-_-RRB- do_VBP with_IN unknown_JJ nouns_NNS ._.
An_DT additional_JJ potential_NN is_VBZ to_TO integrate_VB automatically_RB acquired_VBN relationships_NNS with_IN the_DT information_NN found_VBN in_IN WordNet_NNP ,_, which_WDT seems_VBZ to_TO suffer_VB from_IN several_JJ serious_JJ limitations_NNS -LRB-_-LRB- Curran_NNP 2005_CD -RRB-_-RRB- ,_, and_CC typically_RB overlaps_VBZ to_TO a_DT rather_RB limited_JJ extent_NN with_IN the_DT output_NN of_IN automatic_JJ acquisition_NN methods_NNS ._.
There_EX are_VBP ,_, however_RB ,_, approaches_VBZ to_TO the_DT complementary_JJ problem_NN of_IN determining_VBG the_DT closest_JJS known_JJ sense_NN for_IN unknown_JJ words_NNS -LRB-_-LRB- Widdows_NNS ,_, 2003_CD ;_: Curran_NNP ,_, 2005_CD ;_: Burchardt_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ,_, which_WDT can_MD be_VB viewed_VBN as_IN the_DT logical_JJ next_JJ step_NN after_IN unknown_JJ sense_NN detection_NN ._.
Possibilities_NNS include_VBP associating_VBG items_NNS with_IN similar_JJ existing_VBG senses_NNS -LRB-_-LRB- Widdows_NNS ,_, 2003_CD ;_: Curran_NNP ,_, 2005_CD ;_: Burchardt_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- or_CC clustering_VBG them_PRP into_IN approximate_JJ senses_NNS ._.
While_IN contextual_JJ information_NN is_VBZ the_DT primary_JJ source_NN of_IN information_NN used_VBN in_IN WSD_NN research_NN and_CC has_VBZ been_VBN used_VBN for_IN acquiring_VBG semantic_JJ lexicons_NNS and_CC classifying_VBG unknown_JJ words_NNS in_IN other_JJ languages_NNS -LRB-_-LRB- e.g._FW ,_, Roark_NNP and_CC Charniak_NNP 1998_CD ;_: Ci_NN aramita_NN 2003_CD ;_: Curran_NNP 2005_CD -RRB-_-RRB- More_RBR re_JJ cently_NN ,_, the_DT task_NN of_IN automatic_JJ supersense_NN tagging_NN has_VBZ emerged_VBN for_IN English_NNP -LRB-_-LRB- Ciaramita_NNP and_CC Johnson_NNP ,_, 2003_CD ;_: Curran_NNP ,_, 2005_CD ;_: Ciaramita_NNP and_CC Altun_NNP ,_, 2006_CD ;_: PaaÃŸ_NN and_CC Reichartz_NNP ,_, 2009_CD -RRB-_-RRB- ,_, as_RB well_RB as_IN for_IN Italian_JJ -LRB-_-LRB- Picca_NNP et_FW al._FW ,_, 2008_CD ;_: Picca_NNP et_FW al._FW ,_, 2009_CD ;_: Attardi_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- and_CC Chinese_JJ -LRB-_-LRB- Qiu_NNP et_FW al._FW ,_, 2011_CD -RRB-_-RRB- ,_, languages_NNS with_IN WordNetsmapped_JJ to_TO English_NNP WordNet_NNP .3_NN In_IN principle_NN ,_, we_PRP be_VB lieve_NN supersenses_NNS ought_MD to_TO apply_VB to_TO nouns_NNS and_CC verbsin_VB any_DT language_NN ,_, and_CC need_MD not_RB depend_VB on_IN the_DT avail_NN ability_NN of_IN a_DT semantic_JJ lexicon_NN .4_CD In_IN this_DT work_NN we_PRP focuson_VBP the_DT noun_NN SSTs_NNS ,_, summarized_VBN in_IN figure_NN 2_CD and_CC ap_NN plied_VBD to_TO an_DT Arabic_JJ sentence_NN in_IN figure_NN 1_CD ._.
Thus_RB ,_, some_DT research_NN has_VBZ been_VBN focused_VBN on_IN deriving_VBG different_JJ sense_NN groupings_NNS to_TO overcome_VB the_DT fineâ_NN $_$ ``_`` grained_VBN distinctions_NNS of_IN WN_NN -LRB-_-LRB- Hearst_NNP and_CC SchuÂ_NNP ¨_CD tze_NN ,_, 1993_CD -RRB-_-RRB- -LRB-_-LRB- Peters_NNP et_FW al._FW ,_, 1998_CD -RRB-_-RRB- -LRB-_-LRB- Mihalcea_NNP and_CC Moldo_NNP -_: van_NN ,_, 2001_CD -RRB-_-RRB- -LRB-_-LRB- Agirre_NNP et_FW al._FW ,_, 2003_CD -RRB-_-RRB- and_CC on_IN using_VBG predefined_JJ sets_NNS of_IN sense-groupings_NNS for_IN learning_VBG class-based_JJ classifiers_NNS for_IN WSD_NN -LRB-_-LRB- Segond_NN et_FW al._FW ,_, 1997_CD -RRB-_-RRB- -LRB-_-LRB- Ciaramita_NNP and_CC Johnson_NNP ,_, 2003_CD -RRB-_-RRB- -LRB-_-LRB- Villarejo_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- -LRB-_-LRB- Curran_NNP ,_, 2005_CD -RRB-_-RRB- -LRB-_-LRB- Ciaramita_NNP and_CC Altun_NNP ,_, 2006_CD -RRB-_-RRB- ._.
In_IN contrast_NN ,_, some_DT research_NN have_VBP been_VBN focused_VBN on_IN using_VBG predefined_JJ sets_NNS of_IN sense-groupings_NNS for_IN learning_VBG class-based_JJ classifiers_NNS for_IN WSD_NN -LRB-_-LRB- Segond_NN et_FW al._FW ,_, 1997_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Ciaramita_NNP and_CC Johnson_NNP ,_, 2003_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Villarejo_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Curran_NNP ,_, 2005_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Kohomban_NNP and_CC Lee_NNP ,_, 2005_CD -RRB-_-RRB- and_CC -LRB-_-LRB- Ciaramita_NNP and_CC Altun_NNP ,_, 2006_CD -RRB-_-RRB- ._.
Distributed_VBN representations_NNS are_VBP useful_JJ in_IN capturing_VBG such_JJ meaning_NN for_IN individual_JJ words_NNS -LRB-_-LRB- Sato_NNP et_FW al._FW ,_, 2008_CD ;_: Maas_NNP and_CC Ng_NNP ,_, 2010_CD ;_: Curran_NNP ,_, 2005_CD -RRB-_-RRB- ._.
Supersense_NNP tagging_NN -LRB-_-LRB- Ciaramita_NN and_CC Johnson_NNP ,_, 2003_CD ;_: Curran_NNP ,_, 2005_CD -RRB-_-RRB- evaluates_VBZ a_DT modelâ_JJ $_$ ™_CD s_NNS ability_NN to_TO cluster_VB words_NNS by_IN their_PRP$ semantics_NNS ._.
A_DT concept_NN analogous_JJ to_TO our_PRP$ notion_NN of_IN meta_NN sense_NN -LRB-_-LRB- i.e._FW ,_, senses_NNS beyond_IN single_JJ words_NNS -RRB-_-RRB- has_VBZ been_VBN used_VBN in_IN previous_JJ work_NN on_IN class-based_JJ WSD_NN -LRB-_-LRB- Yarowsky_NNP ,_, 1992_CD ;_: Curran_NNP ,_, 2005_CD ;_: Izquierdo_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ,_, and_CC indeed_RB ,_, the_DT CAM_NNP might_MD be_VB used_VBN for_IN class-based_JJ WSD_NN as_RB well_RB ._.
Previous_JJ work_NN on_IN prediction_NN at_IN the_DT supersense_JJ level_NN -LRB-_-LRB- Ciaramita_NN and_CC Johnson_NNP ,_, 2003_CD ;_: Curran_NNP ,_, 2005_CD -RRB-_-RRB- has_VBZ focused_VBN on_IN lexical_JJ acquisition_NN -LRB-_-LRB- nouns_NNS exclusively_RB -RRB-_-RRB- ,_, thus_RB aiming_VBG at_IN word_NN type_NN classification_NN rather_RB than_IN tagging_VBG ._.
Most_JJS of_IN the_DT features_NNS used_VBN in_IN our_PRP$ system_NN are_VBP based_VBN on_IN the_DT work_NN in_IN -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ._.
Due_JJ to_TO space_NN limitations_NNS ,_, we_PRP only_RB describe_VBP the_DT collocation_NN features_NNS and_CC refer_VB the_DT reader_NN to_TO -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- for_IN the_DT rest_NN of_IN the_DT features_NNS ._.
Among_IN them_PRP ,_, feature-based_JJ methods_NNS -LRB-_-LRB- Kambhatla_NNP 2004_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- achieve_VB certain_JJ success_NN by_IN employing_VBG a_DT large_JJ amount_NN of_IN diverse_JJ linguistic_JJ features_NNS ,_, varying_VBG from_IN lexical_JJ knowledge_NN ,_, entity_NN -_: related_JJ information_NN to_TO syntactic_JJ parse_NN trees_NNS ,_, dependency_NN trees_NNS and_CC semantic_JJ information_NN 7_CD Here_RB ,_, we_PRP use_VBP the_DT same_JJ set_NN of_IN flat_JJ features_NNS -LRB-_-LRB- i.e._FW word_NN ,_, ._.
entity_NN type_NN ,_, mention_NN level_NN ,_, overlap_VBP ,_, base_JJ phrase_NN chunk_NN -_: ing_NN ,_, dependency_NN tree_NN ,_, parse_VB tree_NN and_CC semantic_JJ information_NN -RRB-_-RRB- as_IN Zhou_NNP et_FW al_FW -LRB-_-LRB- 20_CD 05_CD -RRB-_-RRB- ._.
For_IN each_DT pair_NN of_IN entity_NN mentions_VBZ ,_, we_PRP extract_VBP and_CC compute_VBP various_JJ lexical_JJ and_CC syntactic_JJ features_NNS ,_, as_IN employed_VBN in_IN a_DT state-of-the-art_JJ relation_NN extraction_NN system_NN -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ._.
Recent_JJ work_NN has_VBZ begun_VBN to_TO address_VB relation_NN and_CC event_NN extraction_NN through_IN trainable_JJ means_NNS ,_, chiefly_RB SVM_NN classification_NN -LRB-_-LRB- Zelenko_NNP et_FW al_FW ,_, 2003_CD ,_, Zhou_NNP et_FW al_FW ,_, 2005_CD -RRB-_-RRB- ._.
For_IN the_DT choice_NN of_IN features_NNS ,_, we_PRP use_VBP the_DT full_JJ set_NN of_IN features_NNS from_IN Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- since_IN it_PRP is_VBZ reported_VBN to_TO have_VB a_DT state-of-the-art_JJ performance_NN -LRB-_-LRB- Sun_NNP et_FW al._FW ,_, 2011_CD -RRB-_-RRB- ._.
We_PRP use_VBP a_DT state-of-the-art_JJ feature_NN space_NN -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- to_TO represent_VB examples_NNS -LRB-_-LRB- including_VBG all_DT correct_JJ examples_NNS ,_, erroneous_JJ ones_NNS and_CC untagged_JJ examples_NNS -RRB-_-RRB- and_CC use_VB MaxEnt_NNP as_IN the_DT weight_NN learning_VBG model_NN since_IN it_PRP shows_VBZ competitive_JJ performance_NN in_IN relation_NN extraction_NN -LRB-_-LRB- Jiang_NNP and_CC Zhai_NNP ,_, 2007_CD -RRB-_-RRB- and_CC outputs_NN probabilities_NNS associated_VBN with_IN each_DT prediction_NN ._.
We_PRP use_VBP SVM_NNP as_IN our_PRP$ learning_VBG algorithm_NN with_IN the_DT full_JJ feature_NN set_VBN from_IN Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- ._.
Indeed_RB ,_, such_JJ feature-based_JJ methods_NNS have_VBP been_VBN widely_RB applied_VBN in_IN parsing_NN -LRB-_-LRB- Collins_NNP 1999_CD ;_: Charniak_NNP 2001_CD -RRB-_-RRB- ,_, semantic_JJ role_NN labeling_NN -LRB-_-LRB- Pradhan_NNP et_FW al_FW 2005_CD -RRB-_-RRB- ,_, semantic_JJ relation_NN extraction_NN -LRB-_-LRB- Zhou_NNP et_FW al_FW 2005_CD -RRB-_-RRB- and_CC co-reference_NN resolution_NN -LRB-_-LRB- Lapin_NNP and_CC Leass_NNP 1994_CD ;_: Aone_NNP and_CC Bennett_NNP 1995_CD ;_: Mitkov_NNP 1998_CD ;_: Yang_NNP et_FW al_FW 2004_CD ;_: Luo_NNP and_CC Zitouni_NNP 2005_CD ;_: Bergsma_NNP and_CC Lin_NNP 2006_CD -RRB-_-RRB- ._.
Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- explore_VBP various_JJ features_NNS in_IN relation_NN extraction_NN using_VBG SVM_NNP ._.
Besides_IN ,_, Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- introduce_VB additional_JJ chunking_VBG features_NNS to_TO enhance_VB the_DT parse_NN tree_NN features_NNS ._.
we_PRP call_VBP the_DT features_NNS used_VBN in_IN Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- and_CC Kambhatla_NN -LRB-_-LRB- 2004_CD -RRB-_-RRB- flat_JJ feature_NN set_NN ._.
-LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ,_, our_PRP$ experiments_NNS are_VBP carried_VBN out_RP on_IN explicit_JJ relations_NNS due_JJ to_TO the_DT poor_JJ inter-annotator_JJ agreement_NN in_IN annotation_NN of_IN implicit_JJ relations_NNS and_CC their_PRP$ limited_JJ numbers_NNS ._.
The_DT first_JJ utilizes_VBZ a_DT set_NN of_IN carefully_RB selected_VBN features_NNS obtained_VBN from_IN different_JJ levels_NNS of_IN text_NN analysis_NN ,_, from_IN part-of-speech_NN -LRB-_-LRB- POS_NN -RRB-_-RRB- tagging_VBG to_TO full_JJ parsing_NN and_CC dependency_NN parsing_NN -LRB-_-LRB- Kambhatla_NNP ,_, 2004_CD ;_: Zhao_NNP and_CC Grishman_NNP ,_, 2005_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- 1_CD ._.
Zhao_NNP and_CC Grishman_NNP -LRB-_-LRB- 2005_CD -RRB-_-RRB- and_CC Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- explored_VBD a_DT large_JJ set_NN of_IN features_NNS that_WDT are_VBP potentially_RB useful_JJ for_IN relation_NN extraction_NN ._.
Bag-of-Words_NNP Dependency_NNP Relations_NNPS and_CC Dependency_NNP Paths_NNP These_DT experiments_NNS are_VBP done_VBN using_VBG Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- ,_, TPWF_NN kernel_NN ,_, SL_NN kernel_NN ,_, different_JJ versions_NNS of_IN proposed_VBN KH_NN F_NN kernel_NN and_CC KH_NN ybrid_NN kernel_NN ._.
We_PRP also_RB performed_VBD -LRB-_-LRB- 5-fold_RB cross_VB validation_NN -RRB-_-RRB- experiments_NNS by_IN combining_VBG the_DT Stage_NN 1_CD classifier_NN with_IN each_DT of_IN the_DT Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- While_IN various_JJ machine_NN learning_VBG approaches_NNS ,_, such_JJ as_IN generative_JJ modeling_NN -LRB-_-LRB- Miller_NNP et_FW al_FW 2000_CD -RRB-_-RRB- ,_, maximum_NN entropy_NN -LRB-_-LRB- Kambhatla_NN 2004_CD -RRB-_-RRB- and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- Zhao_NNP and_CC Grisman_NNP 2005_CD ;_: Zhou_NNP et_FW al_FW 2005_CD -RRB-_-RRB- ,_, have_VBP been_VBN applied_VBN in_IN the_DT relation_NN extraction_NN task_NN ,_, no_DT explicit_JJ learning_NN strategy_NN is_VBZ proposed_VBN to_TO deal_VB with_IN the_DT inherent_JJ data_NNS sparseness_NN problem_NN caused_VBN by_IN the_DT much_JJ uneven_JJ distribution_NN among_IN different_JJ relations_NNS ._.
Same_JJ as_IN Zhou_NNP et_FW al_FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- ,_, we_PRP only_RB model_NN explicit_JJ relations_NNS and_CC explicitly_RB model_NN the_DT argument_NN order_NN of_IN the_DT two_CD mentions_VBZ involved_VBN ._.
In_IN the_DT future_NN ,_, we_PRP would_MD like_VB to_TO use_VB more_RBR effective_JJ feature_NN sets_NNS Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- Feature-based_JJ methods_NNS -LRB-_-LRB- Kambhatla_NNP ,_, 2004_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD ;_: Zhao_NNP and_CC Grishman_NNP ,_, 20052_CD -RRB-_-RRB- for_IN this_DT task_NN employ_VB a_DT large_JJ amount_NN of_IN diverse_JJ linguistic_JJ features_NNS ,_, such_JJ as_IN lexical_JJ ,_, syntactic_JJ and_CC semantic_JJ features_NNS ._.
More_RBR recent_JJ approaches_NNS have_VBP used_VBN deeper_JJR syntactic_JJ information_NN derived_VBN from_IN parses_NNS of_IN the_DT input_NN sentences_NNS ,_, including_VBG work_NN exploiting_VBG syntactic_JJ dependencies_NNS by_IN Lin_NNP and_CC Pantel_NNP -LRB-_-LRB- 2001_CD -RRB-_-RRB- and_CC Snow_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- ,_, and_CC work_NN in_IN the_DT ACE_NN paradigm_NN such_JJ as_IN Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- and_CC Zhou_NNP et_FW al._FW -LRB-_-LRB- 2007_CD -RRB-_-RRB- ._.
Recent_JJ work_NN on_IN relation_NN extraction_NN has_VBZ been_VBN dominated_VBN by_IN feature-based_JJ and_CC kernel-based_JJ supervised_JJ learning_NN methods.Zhou_NN et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- and_CC Zhao_NNP and_CC Grishman_NNP -LRB-_-LRB- 2005_CD -RRB-_-RRB- studied_VBN various_JJ features_NNS and_CC feature_NN combinations_NNS for_IN relation_NN extraction_NN ._.
Recent_JJ work_NN on_IN relation_NN extraction_NN has_VBZ shown_VBN that_IN supervised_JJ machine_NN learning_VBG coupled_VBN with_IN intelligent_JJ feature_NN engineering_NN or_CC kernel_NN design_NN provides_VBZ state-of-the-art_JJ solutions_NNS to_TO the_DT problem_NN -LRB-_-LRB- Culotta_NN and_CC Sorensen_NNP ,_, 2004_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD ;_: Bunescu_NNP and_CC Mooney_NNP ,_, 2005_CD ;_: Qian_NNP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- ._.
Then_RB the_DT feature_NN based_VBN method_NN explicitly_RB extracts_VBZ a_DT variety_NN of_IN lexical_JJ ,_, syntactic_JJ and_CC semantic_JJ features_NNS for_IN statistical_JJ learning_NN ,_, either_CC generative_NN or_CC discriminative_JJ -LRB-_-LRB- Miller_NNP et_FW al._FW ,_, 2000_CD ;_: Kambhatla_NNP ,_, 2004_CD ;_: Boschee_NNP et_FW al._FW ,_, 2005_CD ;_: Grishman_NNP et_FW al._FW ,_, 2005_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD ;_: Jiang_NNP and_CC Zhai_NNP ,_, 2007_CD -RRB-_-RRB- ._.
We_PRP first_RB adopted_VBD the_DT full_JJ feature_NN set_VBN from_IN Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- ,_, a_DT state-of-the-art_JJ feature_NN based_VBN relation_NN extraction_NN system_NN ._.
Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- tested_VBN their_PRP$ system_NN on_IN the_DT ACE_NN 2003_CD data_NNS ;_: ._.
However_RB ,_, most_JJS approaches_NNS to_TO RE_VB have_VBP assumed_VBN that_IN the_DT relationsâ_NN $_$ ™_CD arguments_NNS are_VBP given_VBN as_IN input_NN -LRB-_-LRB- Chan_NNP and_CC Roth_NNP ,_, 2010_CD ;_: Jiang_NNP and_CC Zhai_NNP ,_, 2007_CD ;_: Jiang_NNP ,_, 2009_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ,_, and_CC therefore_RB offer_VBP only_RB a_DT partial_JJ solution_NN to_TO the_DT problem_NN ._.
Most_JJS prior_JJ RE_NN evaluation_NN on_IN ACE_NN data_NNS assumed_VBD that_IN mentions_VBZ are_VBP already_RB pre-annotated_JJ and_CC given_VBN as_IN input_NN -LRB-_-LRB- Chan_NNP and_CC Roth_NNP ,_, 2010_CD ;_: Jiang_NNP and_CC Zhai_NNP ,_, 2007_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ._.
We_PRP used_VBD Zhou_NNP et_FW al._FW â_FW $_$ ™_CD s_NNS lexical_JJ features_NNS -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- as_IN the_DT basis_NN for_IN the_DT features_NNS of_IN our_PRP$ system_NN similar_JJ to_TO what_WP other_JJ researchers_NNS have_VBP done_VBN -LRB-_-LRB- Chan_NNP and_CC Roth_NNP ,_, 2010_CD -RRB-_-RRB- ._.
This_DT is_VBZ slightly_RB behind_IN that_DT of_IN Zhang_NNP -LRB-_-LRB- 2006_CD -RRB-_-RRB- ;_: the_DT reason_NN might_MD be_VB threefold_JJ Techniques_NNS based_VBN on_IN machine_NN learning_NN -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD ;_: Hao_NNP et_FW al._FW ,_, 2005_CD ;_: Bunescu_NNP and_CC Mooney_NNP ,_, 2006_CD -RRB-_-RRB- are_VBP expected_VBN to_TO alleviate_VB this_DT problem_NN in_IN manually_RB crafted_VBN IE_NN ._.
We_PRP use_VBP features_NNS developed_VBN in_IN part_NN from_IN those_DT described_VBN in_IN Zhou_NNP et_FW al_FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- and_CC Wang_NNP et_FW al_FW -LRB-_-LRB- 2006_CD -RRB-_-RRB- ._.
A_DT variety_NN of_IN features_NNS have_VBP been_VBN explored_VBN for_IN ERD_NNP in_IN previous_JJ research_NN -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD ;_: Zhou_NNP et_FW al._FW ,_, 2008_CD ;_: Jiang_NNP and_CC Zhai_NNP ,_, 2007_CD ;_: Miller_NNP et_FW al._FW ,_, 2000_CD -RRB-_-RRB- ._.
For_IN those_DT interested_JJ in_IN feature-based_JJ methods_NNS ,_, please_VB refer_VB to_TO Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- for_IN more_JJR details_NNS ._.
Most_JJS of_IN the_DT features_NNS used_VBN in_IN our_PRP$ system_NN are_VBP based_VBN on_IN the_DT work_NN in_IN -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ._.
Due_JJ to_TO space_NN limitations_NNS ,_, we_PRP only_RB describe_VBP the_DT collocation_NN features_NNS and_CC refer_VB the_DT reader_NN to_TO -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- for_IN the_DT rest_NN of_IN the_DT features_NNS ._.
While_IN many_JJ supervised_JJ machine_NN learning_VBG approaches_NNS have_VBP been_VBN successfully_RB applied_VBN to_TO the_DT RDC_NN task_NN -LRB-_-LRB- Kambhatla_NNP ,_, 2004_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD ;_: Zelenko_NNP et_FW al._FW ,_, 2003_CD ;_: Culotta_NNP and_CC Sorensen_NNP ,_, 2004_CD ;_: Bunescu_NNP and_CC Mooney_NNP ,_, 2005_CD ;_: Zhang_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- ,_, few_JJ have_VBP focused_VBN on_IN weakly-supervised_JJ relation_NN extraction_NN ._.
Among_IN them_PRP ,_, feature-based_JJ methods_NNS -LRB-_-LRB- Kambhatla_NNP 2004_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- achieve_VB certain_JJ success_NN by_IN employing_VBG a_DT large_JJ amount_NN of_IN diverse_JJ linguistic_JJ features_NNS ,_, varying_VBG from_IN lexical_JJ knowledge_NN ,_, entity_NN -_: related_JJ information_NN to_TO syntactic_JJ parse_NN trees_NNS ,_, dependency_NN trees_NNS and_CC semantic_JJ information_NN 7_CD Here_RB ,_, we_PRP use_VBP the_DT same_JJ set_NN of_IN flat_JJ features_NNS -LRB-_-LRB- i.e._FW word_NN ,_, ._.
entity_NN type_NN ,_, mention_NN level_NN ,_, overlap_VBP ,_, base_JJ phrase_NN chunk_NN -_: ing_NN ,_, dependency_NN tree_NN ,_, parse_VB tree_NN and_CC semantic_JJ information_NN -RRB-_-RRB- as_IN Zhou_NNP et_FW al_FW -LRB-_-LRB- 20_CD 05_CD -RRB-_-RRB- ._.
This_DT paper_NN focuses_VBZ on_IN the_DT ACE_NN RDC_NN subtask_NN ,_, where_WRB many_JJ machine_NN learning_VBG methods_NNS have_VBP been_VBN proposed_VBN ,_, including_VBG supervised_JJ methods_NNS -LRB-_-LRB- Miller_NNP et_FW al._FW ,_, 2000_CD ;_: Zelenko_NNP et_FW al._FW ,_, 2002_CD ;_: Culotta_NNP and_CC Soresen_NNP ,_, 2004_CD ;_: Kambhatla_NNP ,_, 2004_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD ;_: Zhang_NNP et_FW al._FW ,_, 2006_CD ;_: Qian_NNP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- ,_, semi-supervised_JJ methods_NNS -LRB-_-LRB- Brin_NNP ,_, 1998_CD ;_: Agichtein_NNP and_CC Gravano_NNP ,_, 2000_CD ;_: Zhang_NNP ,_, 2004_CD ;_: Chen_NNP et_FW al._FW ,_, 2006_CD ;_: Zhou_NNP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- ,_, and_CC unsupervised_JJ methods_NNS -LRB-_-LRB- Hasegawa_NNP et_FW al._FW ,_, 2004_CD ;_: Zhang_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ._.
For_IN each_DT pair_NN of_IN entity_NN mentions_VBZ ,_, we_PRP extract_VBP and_CC compute_VBP various_JJ lexical_JJ and_CC syntactic_JJ features_NNS ,_, as_IN employed_VBN in_IN a_DT state-of-the-art_JJ relation_NN extraction_NN system_NN -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ._.
Recent_JJ work_NN has_VBZ begun_VBN to_TO address_VB relation_NN and_CC event_NN extraction_NN through_IN trainable_JJ means_NNS ,_, chiefly_RB SVM_NN classification_NN -LRB-_-LRB- Zelenko_NNP et_FW al_FW ,_, 2003_CD ,_, Zhou_NNP et_FW al_FW ,_, 2005_CD -RRB-_-RRB- ._.
For_IN the_DT choice_NN of_IN features_NNS ,_, we_PRP use_VBP the_DT full_JJ set_NN of_IN features_NNS from_IN Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- since_IN it_PRP is_VBZ reported_VBN to_TO have_VB a_DT state-of-the-art_JJ performance_NN -LRB-_-LRB- Sun_NNP et_FW al._FW ,_, 2011_CD -RRB-_-RRB- ._.
We_PRP use_VBP a_DT state-of-the-art_JJ feature_NN space_NN -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- to_TO represent_VB examples_NNS -LRB-_-LRB- including_VBG all_DT correct_JJ examples_NNS ,_, erroneous_JJ ones_NNS and_CC untagged_JJ examples_NNS -RRB-_-RRB- and_CC use_VB MaxEnt_NNP as_IN the_DT weight_NN learning_VBG model_NN since_IN it_PRP shows_VBZ competitive_JJ performance_NN in_IN relation_NN extraction_NN -LRB-_-LRB- Jiang_NNP and_CC Zhai_NNP ,_, 2007_CD -RRB-_-RRB- and_CC outputs_NN probabilities_NNS associated_VBN with_IN each_DT prediction_NN ._.
We_PRP use_VBP SVM_NNP as_IN our_PRP$ learning_VBG algorithm_NN with_IN the_DT full_JJ feature_NN set_VBN from_IN Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- ._.
Indeed_RB ,_, such_JJ feature-based_JJ methods_NNS have_VBP been_VBN widely_RB applied_VBN in_IN parsing_NN -LRB-_-LRB- Collins_NNP 1999_CD ;_: Charniak_NNP 2001_CD -RRB-_-RRB- ,_, semantic_JJ role_NN labeling_NN -LRB-_-LRB- Pradhan_NNP et_FW al_FW 2005_CD -RRB-_-RRB- ,_, semantic_JJ relation_NN extraction_NN -LRB-_-LRB- Zhou_NNP et_FW al_FW 2005_CD -RRB-_-RRB- and_CC co-reference_NN resolution_NN -LRB-_-LRB- Lapin_NNP and_CC Leass_NNP 1994_CD ;_: Aone_NNP and_CC Bennett_NNP 1995_CD ;_: Mitkov_NNP 1998_CD ;_: Yang_NNP et_FW al_FW 2004_CD ;_: Luo_NNP and_CC Zitouni_NNP 2005_CD ;_: Bergsma_NNP and_CC Lin_NNP 2006_CD -RRB-_-RRB- ._.
Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- explore_VBP various_JJ features_NNS in_IN relation_NN extraction_NN using_VBG SVM_NNP ._.
Besides_IN ,_, Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- introduce_VB additional_JJ chunking_VBG features_NNS to_TO enhance_VB the_DT parse_NN tree_NN features_NNS ._.
we_PRP call_VBP the_DT features_NNS used_VBN in_IN Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- and_CC Kambhatla_NN -LRB-_-LRB- 2004_CD -RRB-_-RRB- flat_JJ feature_NN set_NN ._.
-LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ,_, our_PRP$ experiments_NNS are_VBP carried_VBN out_RP on_IN explicit_JJ relations_NNS due_JJ to_TO the_DT poor_JJ inter-annotator_JJ agreement_NN in_IN annotation_NN of_IN implicit_JJ relations_NNS and_CC their_PRP$ limited_JJ numbers_NNS ._.
The_DT first_JJ utilizes_VBZ a_DT set_NN of_IN carefully_RB selected_VBN features_NNS obtained_VBN from_IN different_JJ levels_NNS of_IN text_NN analysis_NN ,_, from_IN part-of-speech_NN -LRB-_-LRB- POS_NN -RRB-_-RRB- tagging_VBG to_TO full_JJ parsing_NN and_CC dependency_NN parsing_NN -LRB-_-LRB- Kambhatla_NNP ,_, 2004_CD ;_: Zhao_NNP and_CC Grishman_NNP ,_, 2005_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- 1_CD ._.
Zhao_NNP and_CC Grishman_NNP -LRB-_-LRB- 2005_CD -RRB-_-RRB- and_CC Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- explored_VBD a_DT large_JJ set_NN of_IN features_NNS that_WDT are_VBP potentially_RB useful_JJ for_IN relation_NN extraction_NN ._.
Bag-of-Words_NNP Dependency_NNP Relations_NNPS and_CC Dependency_NNP Paths_NNP These_DT experiments_NNS are_VBP done_VBN using_VBG Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- ,_, TPWF_NN kernel_NN ,_, SL_NN kernel_NN ,_, different_JJ versions_NNS of_IN proposed_VBN KH_NN F_NN kernel_NN and_CC KH_NN ybrid_NN kernel_NN ._.
We_PRP also_RB performed_VBD -LRB-_-LRB- 5-fold_RB cross_VB validation_NN -RRB-_-RRB- experiments_NNS by_IN combining_VBG the_DT Stage_NN 1_CD classifier_NN with_IN each_DT of_IN the_DT Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- While_IN various_JJ machine_NN learning_VBG approaches_NNS ,_, such_JJ as_IN generative_JJ modeling_NN -LRB-_-LRB- Miller_NNP et_FW al_FW 2000_CD -RRB-_-RRB- ,_, maximum_NN entropy_NN -LRB-_-LRB- Kambhatla_NN 2004_CD -RRB-_-RRB- and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- Zhao_NNP and_CC Grisman_NNP 2005_CD ;_: Zhou_NNP et_FW al_FW 2005_CD -RRB-_-RRB- ,_, have_VBP been_VBN applied_VBN in_IN the_DT relation_NN extraction_NN task_NN ,_, no_DT explicit_JJ learning_NN strategy_NN is_VBZ proposed_VBN to_TO deal_VB with_IN the_DT inherent_JJ data_NNS sparseness_NN problem_NN caused_VBN by_IN the_DT much_JJ uneven_JJ distribution_NN among_IN different_JJ relations_NNS ._.
With_IN the_DT increasing_VBG popularity_NN of_IN ACE_NN ,_, this_DT task_NN is_VBZ starting_VBG to_TO attract_VB more_JJR and_CC more_RBR researchers_NNS within_IN the_DT natural_JJ language_NN processing_NN and_CC machine_NN learning_NN communities.Typical_JJ works_NNS include_VBP Miller_NNP et_FW al_FW -LRB-_-LRB- 2000_CD -RRB-_-RRB- ,_, Zelenko_NNP et_FW al_FW -LRB-_-LRB- 2003_CD -RRB-_-RRB- ,_, Culotta_NNP and_CC Sorensen_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- ,_, Bunescu_NN and_CC Mooney_NN -LRB-_-LRB- 2005a_NN -RRB-_-RRB- ,_, Bunescu_NN and_CC Mooney_NN -LRB-_-LRB- 2005b_NN -RRB-_-RRB- ,_, Zhang_NNP et_FW al_FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- ,_, Roth_NNP and_CC Yih_NNP -LRB-_-LRB- 2002_CD -RRB-_-RRB- ,_, Kambhatla_NN -LRB-_-LRB- 2004_CD -RRB-_-RRB- ,_, Zhao_NNP and_CC Grisman_NNP -LRB-_-LRB- 2005_CD -RRB-_-RRB- and_CC Zhou_NNP et_FW al_FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- ._.
Same_JJ as_IN Zhou_NNP et_FW al_FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- ,_, we_PRP only_RB model_NN explicit_JJ relations_NNS and_CC explicitly_RB model_NN the_DT argument_NN order_NN of_IN the_DT two_CD mentions_VBZ involved_VBN ._.
Many_JJ machine_NN learning_VBG methods_NNS have_VBP been_VBN proposed_VBN to_TO address_VB this_DT problem_NN ,_, e.g._FW ,_, supervised_JJ learning_NN algorithms_NNS -LRB-_-LRB- Miller_NNP et_FW al._FW ,_, 2000_CD ;_: Zelenko_NNP et_FW al._FW ,_, 2002_CD ;_: Culotta_NNP and_CC Soresen_NNP ,_, 2004_CD ;_: Kambhatla_NNP ,_, 2004_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ,_, semi-supervised_JJ learning_NN algorithms_NNS -LRB-_-LRB- Brin_NNP ,_, 1998_CD ;_: Agichtein_NNP and_CC Gravano_NNP ,_, 2000_CD ;_: Zhang_NNP ,_, 2004_CD -RRB-_-RRB- ,_, and_CC unsupervised_JJ learning_NN algorithms_NNS -LRB-_-LRB- Hasegawa_NNP et_FW al._FW ,_, 2004_CD -RRB-_-RRB- ._.
Bootstrapping_NNP Currently_NNP most_JJS of_IN works_NNS on_IN the_DT RDC_NN task_NN of_IN ACE_NN focused_VBD on_IN supervised_JJ learning_NN methods_NNS Culotta_NNP and_CC Soresen_NNP -LRB-_-LRB- 2004_CD ;_: Kambhatla_NNP -LRB-_-LRB- 2004_CD ;_: Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- ._.
In_IN the_DT future_NN ,_, we_PRP would_MD like_VB to_TO use_VB more_RBR effective_JJ feature_NN sets_NNS Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- Many_JJ techniques_NNS on_IN relation_NN extraction_NN ,_, such_JJ as_IN rule-based_JJ -LRB-_-LRB- MUC_NN ,_, 19871998_CD ;_: Miller_NNP et_FW al._FW ,_, 2000_CD -RRB-_-RRB- ,_, feature-based_JJ -LRB-_-LRB- Kambhatla_JJ 2004_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- and_CC kernel-based_JJ -LRB-_-LRB- Zelenko_NNP et_FW al._FW ,_, 2003_CD ;_: Culotta_NNP and_CC Sorensen_NNP ,_, 2004_CD ;_: Bunescu_NNP and_CC Mooney_NNP ,_, 2005_CD -RRB-_-RRB- ,_, have_VBP been_VBN proposed_VBN in_IN the_DT literature_NN ._.
Feature-based_JJ methods_NNS -LRB-_-LRB- Kambhatla_NNP ,_, 2004_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD ;_: Zhao_NNP and_CC Grishman_NNP ,_, 20052_CD -RRB-_-RRB- for_IN this_DT task_NN employ_VB a_DT large_JJ amount_NN of_IN diverse_JJ linguistic_JJ features_NNS ,_, such_JJ as_IN lexical_JJ ,_, syntactic_JJ and_CC semantic_JJ features_NNS ._.
Many_JJ methods_NNS have_VBP been_VBN proposed_VBN to_TO deal_VB with_IN this_DT task_NN ,_, including_VBG supervised_JJ learning_NN algorithms_NNS -LRB-_-LRB- Miller_NNP et_FW al._FW ,_, 2000_CD ;_: Zelenko_NNP et_FW al._FW ,_, 2002_CD ;_: Culotta_NNP and_CC Soresen_NNP ,_, 2004_CD ;_: Kambhatla_NNP ,_, 2004_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ,_, semi-supervised_JJ learning_NN algorithms_NNS -LRB-_-LRB- Brin_NNP ,_, 1998_CD ;_: Agichtein_NNP and_CC Gravano_NNP ,_, 2000_CD ;_: Zhang_NNP ,_, 2004_CD -RRB-_-RRB- ,_, and_CC unsupervised_JJ learning_NN algorithm_NN -LRB-_-LRB- Hasegawa_NNP et_FW al._FW ,_, 2004_CD -RRB-_-RRB- ._.
More_RBR recent_JJ approaches_NNS have_VBP used_VBN deeper_JJR syntactic_JJ information_NN derived_VBN from_IN parses_NNS of_IN the_DT input_NN sentences_NNS ,_, including_VBG work_NN exploiting_VBG syntactic_JJ dependencies_NNS by_IN Lin_NNP and_CC Pantel_NNP -LRB-_-LRB- 2001_CD -RRB-_-RRB- and_CC Snow_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- ,_, and_CC work_NN in_IN the_DT ACE_NN paradigm_NN such_JJ as_IN Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- and_CC Zhou_NNP et_FW al._FW -LRB-_-LRB- 2007_CD -RRB-_-RRB- ._.
Recent_JJ work_NN on_IN relation_NN extraction_NN has_VBZ been_VBN dominated_VBN by_IN feature-based_JJ and_CC kernel-based_JJ supervised_JJ learning_NN methods.Zhou_NN et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- and_CC Zhao_NNP and_CC Grishman_NNP -LRB-_-LRB- 2005_CD -RRB-_-RRB- studied_VBN various_JJ features_NNS and_CC feature_NN combinations_NNS for_IN relation_NN extraction_NN ._.
Recent_JJ work_NN on_IN relation_NN extraction_NN has_VBZ shown_VBN that_IN supervised_JJ machine_NN learning_VBG coupled_VBN with_IN intelligent_JJ feature_NN engineering_NN or_CC kernel_NN design_NN provides_VBZ state-of-the-art_JJ solutions_NNS to_TO the_DT problem_NN -LRB-_-LRB- Culotta_NN and_CC Sorensen_NNP ,_, 2004_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD ;_: Bunescu_NNP and_CC Mooney_NNP ,_, 2005_CD ;_: Qian_NNP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- ._.
Then_RB the_DT feature_NN based_VBN method_NN explicitly_RB extracts_VBZ a_DT variety_NN of_IN lexical_JJ ,_, syntactic_JJ and_CC semantic_JJ features_NNS for_IN statistical_JJ learning_NN ,_, either_CC generative_NN or_CC discriminative_JJ -LRB-_-LRB- Miller_NNP et_FW al._FW ,_, 2000_CD ;_: Kambhatla_NNP ,_, 2004_CD ;_: Boschee_NNP et_FW al._FW ,_, 2005_CD ;_: Grishman_NNP et_FW al._FW ,_, 2005_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD ;_: Jiang_NNP and_CC Zhai_NNP ,_, 2007_CD -RRB-_-RRB- ._.
We_PRP first_RB adopted_VBD the_DT full_JJ feature_NN set_VBN from_IN Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- ,_, a_DT state-of-the-art_JJ feature_NN based_VBN relation_NN extraction_NN system_NN ._.
Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- tested_VBN their_PRP$ system_NN on_IN the_DT ACE_NN 2003_CD data_NNS ;_: ._.
However_RB ,_, most_JJS approaches_NNS to_TO RE_VB have_VBP assumed_VBN that_IN the_DT relationsâ_NN $_$ ™_CD arguments_NNS are_VBP given_VBN as_IN input_NN -LRB-_-LRB- Chan_NNP and_CC Roth_NNP ,_, 2010_CD ;_: Jiang_NNP and_CC Zhai_NNP ,_, 2007_CD ;_: Jiang_NNP ,_, 2009_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ,_, and_CC therefore_RB offer_VBP only_RB a_DT partial_JJ solution_NN to_TO the_DT problem_NN ._.
Most_JJS prior_JJ RE_NN evaluation_NN on_IN ACE_NN data_NNS assumed_VBD that_IN mentions_VBZ are_VBP already_RB pre-annotated_JJ and_CC given_VBN as_IN input_NN -LRB-_-LRB- Chan_NNP and_CC Roth_NNP ,_, 2010_CD ;_: Jiang_NNP and_CC Zhai_NNP ,_, 2007_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ._.
We_PRP used_VBD Zhou_NNP et_FW al._FW â_FW $_$ ™_CD s_NNS lexical_JJ features_NNS -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- as_IN the_DT basis_NN for_IN the_DT features_NNS of_IN our_PRP$ system_NN similar_JJ to_TO what_WP other_JJ researchers_NNS have_VBP done_VBN -LRB-_-LRB- Chan_NNP and_CC Roth_NNP ,_, 2010_CD -RRB-_-RRB- ._.
This_DT is_VBZ slightly_RB behind_IN that_DT of_IN Zhang_NNP -LRB-_-LRB- 2006_CD -RRB-_-RRB- ;_: the_DT reason_NN might_MD be_VB threefold_JJ Techniques_NNS based_VBN on_IN machine_NN learning_NN -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD ;_: Hao_NNP et_FW al._FW ,_, 2005_CD ;_: Bunescu_NNP and_CC Mooney_NNP ,_, 2006_CD -RRB-_-RRB- are_VBP expected_VBN to_TO alleviate_VB this_DT problem_NN in_IN manually_RB crafted_VBN IE_NN ._.
Prior_JJ work_NN on_IN automatic_JJ relation_NN extraction_NN come_VBN in_IN three_CD kinds_NNS We_PRP use_VBP features_NNS developed_VBN in_IN part_NN from_IN those_DT described_VBN in_IN Zhou_NNP et_FW al_FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- and_CC Wang_NNP et_FW al_FW -LRB-_-LRB- 2006_CD -RRB-_-RRB- ._.
A_DT variety_NN of_IN features_NNS have_VBP been_VBN explored_VBN for_IN ERD_NNP in_IN previous_JJ research_NN -LRB-_-LRB- Zhou_NNP et_FW al._FW ,_, 2005_CD ;_: Zhou_NNP et_FW al._FW ,_, 2008_CD ;_: Jiang_NNP and_CC Zhai_NNP ,_, 2007_CD ;_: Miller_NNP et_FW al._FW ,_, 2000_CD -RRB-_-RRB- ._.
Researchers_NNS have_VBP used_VBN supervised_JJ and_CC semi-supervised_JJ approaches_NNS -LRB-_-LRB- Hasegawa_NNP et_FW al._FW ,_, 2004_CD ;_: Mintz_NNP et_FW al._FW ,_, 2009_CD ;_: Jiang_NNP ,_, 2009_CD -RRB-_-RRB- ,_, and_CC explored_VBN rich_JJ features_NNS -LRB-_-LRB- Kambhatla_NNP ,_, 2004_CD -RRB-_-RRB- ,_, kernel_NN design_NN -LRB-_-LRB- Culotta_NN and_CC Sorensen_NNP ,_, 2004_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD ;_: Bunescu_NNP and_CC Mooney_NNP ,_, 2005_CD ;_: Qian_NNP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- and_CC inference_NN algorithms_NNS -LRB-_-LRB- Chan_NNP and_CC Roth_NNP ,_, 2011_CD -RRB-_-RRB- ,_, to_TO detect_VB predefined_JJ relations_NNS between_IN NEs_NNS ._.
There_EX are_VBP only_RB a_DT few_JJ studies_NNS on_IN document-level_JJ SMT.Representative_JJ work_NN includes_VBZ Zhao_NNP et_FW al._FW -LRB-_-LRB- 2006_CD -RRB-_-RRB- ,_, Tam_NNP et_FW al._FW -LRB-_-LRB- 2007_CD -RRB-_-RRB- ,_, Carpuat_NN -LRB-_-LRB- 2009_CD -RRB-_-RRB- ._.
Zhao_NNP et_FW al._FW -LRB-_-LRB- 2006_CD -RRB-_-RRB- assumed_VBD that_IN the_DT parallel_JJ sentence_NN pairs_NNS within_IN a_DT document_NN pair_NN constitute_VBP a_DT mixture_NN of_IN hidden_JJ topics_NNS and_CC each_DT word_NN pair_NN follows_VBZ a_DT topic-specific_JJ bilingual_JJ translation_NN model.It_NN shows_VBZ that_IN the_DT performance_NN of_IN word_NN alignment_NN can_MD be_VB improved_VBN with_IN the_DT help_NN of_IN document-level_JJ information_NN ,_, which_WDT indirectly_RB improves_VBZ the_DT quality_NN of_IN SMT_NNP ._.
Related_JJ work_NN includes_VBZ the_DT Bilingual_NNP Topic_NNP Admixture_NNP Model_NNP -LRB-_-LRB- BiTAM_NNP -RRB-_-RRB- for_IN word_NN alignment_NN proposed_VBN by_IN -LRB-_-LRB- Zhao_NNP and_CC Xing_NNP ,_, 2006_CD -RRB-_-RRB- ._.
Basically_RB ,_, the_DT BiTAM_NNP model_NN consists_VBZ of_IN topic-dependent_JJ transla_NN tion_NN lexicons_NNS modeling_NN P_NN r_NN -LRB-_-LRB- c_NN e_SYM ,_, k_NN -RRB-_-RRB- where_WRB c_NN ,_, e_SYM and_CC k_NN denotes_VBZ the_DT source_NN Chinese_JJ word_NN ,_, target_NN English_NNP word_NN and_CC the_DT topic_NN index_NN respectively_RB ._.
The_DT alignment_NN results_VBZ for_IN both_DT directions_NNS were_VBD refined_VBN with_IN `_`` GROW_NNP '_'' heuristics_NNS to_TO yield_VB high_JJ precision_NN and_CC high_JJ recall_NN in_IN accordance_NN with_IN previous_JJ work_NN -LRB-_-LRB- Och_NN and_CC Ney_NN ,_, 2003_CD ;_: Zhao_NNP and_CC Xing_NNP ,_, 2006_CD -RRB-_-RRB- ._.
Zhao_NNP and_CC Xing_NNP -LRB-_-LRB- 2006_CD -RRB-_-RRB- note_NN that_IN the_DT parameter_NN estimation_NN -LRB-_-LRB- for_IN which_WDT they_PRP use_VBP variational_JJ EM_NN -RRB-_-RRB- suffers_VBZ from_IN data_NNS sparsity_NN and_CC use_VB symmetric_JJ Dirichlet_JJ priors_NNS ,_, but_CC they_PRP find_VBP the_DT MAP_NN solution_NN ._.
Our_PRP$ approach_NN is_VBZ inspired_VBN by_IN the_DT recent_JJ studies_NNS -LRB-_-LRB- Zhao_NNP and_CC Xing_NNP ,_, 2006_CD ;_: Zhao_NNP and_CC Xing_NNP ,_, 2007_CD ;_: Tam_NNP et_FW al._FW ,_, 2007_CD ;_: Gong_NNP and_CC Zhou_NNP ,_, 2010_CD ;_: Ruiz_NNP and_CC Federico_NNP ,_, 2011_CD -RRB-_-RRB- which_WDT have_VBP shown_VBN that_IN a_DT particular_JJ translation_NN always_RB appears_VBZ in_IN some_DT specific_JJ topical_JJ contexts_NNS ,_, and_CC the_DT topical_JJ context_NN information_NN has_VBZ a_DT great_JJ effect_NN on_IN translation_NN selection_NN ._.
â_RB $_$ cents_NNS In_IN addition_NN to_TO the_DT utilization_NN of_IN in-domain_JJ monolingual_JJ corpora_NN ,_, our_PRP$ method_NN is_VBZ different_JJ from_IN the_DT previous_JJ works_NNS -LRB-_-LRB- Zhao_NNP and_CC Xing_NNP ,_, 2006_CD ;_: Zhao_NNP and_CC Xing_NNP ,_, 2007_CD ;_: Tam_NNP et_FW al._FW ,_, 2007_CD ;_: Gong_NNP and_CC Zhou_NNP ,_, 2010_CD -RRB-_-RRB- in_IN the_DT following_VBG aspects_NNS In_IN -LRB-_-LRB- Zhao_NNP and_CC Xing_NNP ,_, 2006_CD -RRB-_-RRB- ,_, three_CD fairly_RB sophisticated_JJ bayesian_JJ topical_JJ translation_NN models_NNS ,_, taking_VBG IBM_NNP Model_NNP 1_CD as_IN a_DT baseline_NN model_NN ,_, were_VBD presented_VBN under_IN the_DT bilingual_JJ topic_NN admixture_NN model_NN formalism.These_NN models_NNS capture_VBP latent_JJ topics_NNS at_IN the_DT document_NN level_NN in_IN order_NN to_TO reduce_VB semantic_JJ ambiguity_NN and_CC improve_VB translation_NN coherence.The_NN models_NNS proposed_VBD provide_VB in_IN some_DT cases_NNS better_JJR word_NN alignment_NN and_CC translation_NN quality_NN than_IN HMM_NN and_CC IBM_NNP models_NNS on_IN an_DT EnglishChinese_NNP task_NN ._.
A_DT possible_JJ solution_NN is_VBZ the_DT implementation_NN of_IN interpolation_NN techniques_NNS to_TO smooth_VB sharp_JJ distributions_NNS estimated_VBN on_IN few_JJ events_NNS -LRB-_-LRB- Och_NN and_CC Ney_NN ,_, 2003_CD ;_: Zhao_NNP and_CC Xing_NNP ,_, 2006_CD -RRB-_-RRB- ._.
In_IN this_DT two-pass_JJ method_NN ,_, translation_NN performance_NN hinges_VBZ on_IN the_DT N-best_JJ hypotheses_NNS that_WDT are_VBP generated_VBN in_IN the_DT first_JJ pass_NN -LRB-_-LRB- since_IN rescoring_NN occurs_VBZ on_IN these_DT -RRB-_-RRB- ,_, so_RB adding_VBG the_DT translation_NN candidates_NNS generated_VBN by_IN other_JJ MT_NN systems_NNS to_TO these_DT hypotheses_NNS could_MD potentially_RB improve_VB the_DT performance.This_NN technique_NN is_VBZ called_VBN system_NN combination_NN -LRB-_-LRB- Bangalore_NNP et_FW al._FW ,_, 2001_CD ;_: Matusov_NNP et_FW al._FW ,_, 2006_CD ;_: Sim_NNP et_FW al._FW ,_, 2007_CD ;_: Rosti_NNP et_FW al._FW ,_, 2007a_NN ;_: Rosti_NNP et_FW al._FW ,_, 2007b_NN -RRB-_-RRB- ._.
Confusion_NN network_NN and_CC re-decoding_NN have_VBP been_VBN well_RB studied_VBN in_IN the_DT combination_NN of_IN different_JJ MT_NN systems_NNS -LRB-_-LRB- Bangalore_NNP et_FW al._FW ,_, 2001_CD ;_: Matusov_NNP et_FW al._FW ,_, 2006_CD ;_: Sim_NNP et_FW al._FW ,_, 2007_CD ;_: Rosti_NNP et_FW al._FW ,_, 2007a_NN ;_: Rosti_NNP et_FW al._FW ,_, 2007b_NN -RRB-_-RRB- ._.
Bangalore_NNP et_FW al._FW -LRB-_-LRB- 2001_CD -RRB-_-RRB- ,_, Sim_NNP et_FW al._FW -LRB-_-LRB- 2007_CD -RRB-_-RRB- ,_, Rosti_NNP et_FW al._FW -LRB-_-LRB- 2007a_NN -RRB-_-RRB- ,_, and_CC Rosti_NNP et_FW al._FW -LRB-_-LRB- 2007b_NN -RRB-_-RRB- chose_VBD the_DT hypothesis_NN that_IN best_JJS agrees_VBZ with_IN other_JJ hypotheses_NNS on_IN average_NN as_IN the_DT skeleton_NN ._.
Bangalore_NNP et_FW al._FW -LRB-_-LRB- 2001_CD -RRB-_-RRB- used_VBD a_DT WER_NN based_VBN alignment_NN and_CC Sim_NNP et_FW al._FW -LRB-_-LRB- 2007_CD -RRB-_-RRB- ,_, Rosti_NNP et_FW al._FW -LRB-_-LRB- 2007a_NN -RRB-_-RRB- ,_, and_CC Rosti_NNP et_FW al._FW -LRB-_-LRB- 2007b_NN -RRB-_-RRB- used_VBN minimum_JJ Translation_NN Error_NNP Rate_NNP -LRB-_-LRB- TER_NNP -RRB-_-RRB- based_VBN alignment_NN to_TO build_VB the_DT confusion_NN network_NN ._.
In_IN recent_JJ several_JJ years_NNS ,_, the_DT system_NN combination_NN methods_NNS based_VBN on_IN confusion_NN networks_NNS developed_VBD rapidly_RB -LRB-_-LRB- Bangalore_NNP et_FW al._FW ,_, 2001_CD ;_: Matusov_NNP et_FW al._FW ,_, 2006_CD ;_: Sim_NNP et_FW al._FW ,_, 2007_CD ;_: Rosti_NNP et_FW al._FW ,_, 2007a_NN ;_: Rosti_NNP et_FW al._FW ,_, 2007b_NN ;_: Rosti_NNP et_FW al._FW ,_, 2008_CD ;_: He_PRP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- ,_, which_WDT show_VBP state-of-the-art_JJ performance_NN in_IN benchmarks_NNS ._.
While_IN in_IN lattice_NN decoding_NN ,_, a_DT translation_NN path_NN may_MD skip_VB some_DT nodes_NNS as_IN some_DT hypothesis_NN arcs_NNS may_MD cross_VB more_JJR than_IN one_CD backbone_NN arc_NN ._.
Similar_JJ to_TO the_DT features_NNS in_IN Rosti_NNP et_FW al._FW -LRB-_-LRB- 2007a_NN -RRB-_-RRB- ,_, the_DT features_NNS adopted_VBN by_IN lattice-based_JJ model_NN are_VBP arc_NN posterior_JJ probability_NN ,_, language_NN model_NN probability_NN ,_, the_DT number_NN of_IN null_JJ arcs_NNS ,_, the_DT number_NN of_IN hypothesis_NN arcs_NNS possessing_VBG more_JJR than_IN one_CD non-null_JJ word_NN and_CC the_DT number_NN of_IN all_DT non-null_JJ words_NNS ._.
Each_DT arc_NN has_VBZ different_JJ confidences_NNS concerned_VBN with_IN different_JJ systems_NNS ,_, and_CC the_DT confidence_NN of_IN system_NN s_NNS is_VBZ denoted_VBN by_IN ps_NNS -LRB-_-LRB- arc_NN -RRB-_-RRB- ._.
ps_NN -LRB-_-LRB- arc_NN -RRB-_-RRB- is_VBZ increased_VBN by_IN 1_CD /_: -LRB-_-LRB- k_NN +_CC 1_LS -RRB-_-RRB- if_IN the_DT hypothesis_NN ranking_JJ k_NN in_IN the_DT system_NN s_VBZ contains_VBZ the_DT arc_NN -LRB-_-LRB- Rosti_NNP et_FW al._FW ,_, 2007a_NN ;_: He_PRP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- ._.
Qc_NNP 2009_CD Association_NNP for_IN Computational_NNP Linguistics_NNP System_NNP Combination_NNP We_PRP build_VBP our_PRP$ confusion_NN networks_NNS using_VBG the_DT method_NN of_IN Rosti_NNP et_FW al._FW -LRB-_-LRB- 2007_CD -RRB-_-RRB- ,_, but_CC ,_, instead_RB of_IN forming_VBG alignments_NNS using_VBG the_DT tercom_NN script_NN -LRB-_-LRB- Snover_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- ,_, we_PRP create_VBP alignments_NNS that_WDT minimize_VBP invWER_NN -LRB-_-LRB- Leusch_NNP et_FW al._FW ,_, 2003_CD -RRB-_-RRB- ,_, a_DT form_NN of_IN edit_NN distance_NN that_WDT permits_VBZ properly_RB nested_JJ block_NN movements_NNS of_IN substrings_NNS ._.
The_DT procedure_NN described_VBN by_IN Rosti_NNP et_FW al._FW -LRB-_-LRB- 2007_CD -RRB-_-RRB- has_VBZ been_VBN shown_VBN to_TO yield_VB significant_JJ improvements_NNS in_IN translation_NN quality_NN ,_, and_CC uses_VBZ an_DT estimate_NN of_IN Translation_NN Error_NN Rate_NN -LRB-_-LRB- TER_NN -RRB-_-RRB- to_TO guide_VB the_DT alignment_NN ._.
In_IN fact_NN ,_, it_PRP only_RB requires_VBZ a_DT procedure_NN for_IN creating_VBG pairwise_JJ alignments_NNS of_IN translations_NNS that_WDT allow_VBP appropriate_JJ re-orderings_NNS ._.
For_IN this_DT ,_, Rosti_NNP et_FW al._FW S_NN sid_NN =_JJ ``_`` 30_CD ''_'' ssid_NN =_JJ ``_`` 30_CD ''_'' >_JJR -LRB-_-LRB- 2007_CD -RRB-_-RRB- use_VBP the_DT tercom_NN script_NN -LRB-_-LRB- Snover_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- ,_, which_WDT uses_VBZ a_DT number_NN of_IN heuristics_NNS -LRB-_-LRB- as_RB well_RB as_IN dynamic_JJ programming_NN -RRB-_-RRB- for_IN finding_VBG a_DT sequence_NN of_IN edits_NNS -LRB-_-LRB- insertions_NNS ,_, deletions_NNS ,_, substitutions_NNS and_CC block_VB shifts_NNS -RRB-_-RRB- that_WDT convert_VBP an_DT input_NN string_NN to_TO another_DT ._.
ITG-based_JJ alignments_NNS and_CC tercom-based_JJ alignments_NNS were_VBD also_RB compared_VBN in_IN oracle_NN experiments_NNS involving_VBG confusion_NN networks_NNS created_VBN through_IN the_DT algorithm_NN of_IN Rosti_NNP et_FW al._FW -LRB-_-LRB- 2007_CD -RRB-_-RRB- ._.
Note_VB that_IN the_DT algorithm_NN of_IN Rosti_NNP et_FW al._FW -LRB-_-LRB- 2007_CD -RRB-_-RRB- used_VBN N_NN -_: best_JJS lists_NNS in_IN the_DT combination_NN ._.
This_DT large_JJ grammatical_JJ difference_NN may_MD produce_VB a_DT longer_RBR sentence_NN with_IN spuriously_RB inserted_VBN words_NNS ,_, as_IN in_IN I_PRP saw_VBD the_DT blue_JJ trees_NNS was_VBD found_VBN in_IN Figure_NNP 1_CD -LRB-_-LRB- c_NN -RRB-_-RRB- ._.
Rosti_NNP et_FW al._FW -LRB-_-LRB- 2007b_NN -RRB-_-RRB- partially_RB resolved_VBD the_DT problem_NN by_IN constructing_VBG a_DT large_JJ network_NN in_IN which_WDT each_DT hypothesis_NN was_VBD treated_VBN as_IN a_DT skeleton_NN and_CC the_DT multiple_JJ networks_NNS were_VBD merged_VBN into_IN a_DT single_JJ network_NN ._.
Our_PRP$ baseline_NN confusion_NN network_NN system_NN has_VBZ an_DT additional_JJ penalty_NN feature_NN ,_, hp_NN -LRB-_-LRB- m_NN -RRB-_-RRB- ,_, which_WDT is_VBZ the_DT total_JJ edits_NNS required_VBN to_TO construct_VB a_DT confusion_NN network_NN using_VBG the_DT mth_NN system_NN hypothesis_NN as_IN a_DT skeleton_NN ,_, normalized_VBN by_IN the_DT number_NN of_IN nodes_NNS in_IN the_DT network_NN -LRB-_-LRB- Rosti_NNP et_FW al._FW ,_, 2007b_NN -RRB-_-RRB- ._.
@_SYM 2009_CD Association_NNP for_IN Computational_NNP Linguistics_NNP System_NNP Combination_NNP If_IN measures_NNS with_IN this_DT property_NN are_VBP used_VBN to_TO tune_VB a_DT typical_JJ statistical_JJ MT_NN system_NN ,_, it_PRP can_MD sometimes_RB be_VB observed_VBN that_IN the_DT MT_NN system_NN learns_VBZ to_TO play_VB against_IN this_DT ,_, and_CC might_MD even_RB learn_VB to_TO produce_VB translations_NNS which_WDT show_VBP the_DT good_JJ features_NNS without_IN actually_RB being_VBG good_JJ translations_NNS ._.
For_IN example_NN ,_, Rosti_NNP et_FW al._FW -LRB-_-LRB- 2007_CD -RRB-_-RRB- report_NN such_JJ an_DT effect_NN ._.
In_IN this_DT paper_NN ,_, a_DT system_NN combination_NN based_VBN on_IN confusion_NN network_NN -LRB-_-LRB- CN_NN -RRB-_-RRB- is_VBZ described.This_NNP approach_NN is_VBZ not_RB new_JJ ,_, and_CC numerous_JJ publications_NNS are_VBP available_JJ on_IN that_DT subject_JJ ,_, see_VB for_IN example_NN ,_, -LRB-_-LRB- Rosti_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ;_: -LRB-_-LRB- Shen_NNP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- ;_: -LRB-_-LRB- Karakos_NNP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- and_CC -LRB-_-LRB- Leusch_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ._.
This_DT diers_VBZ from_IN the_DT result_NN of_IN -LRB-_-LRB- Rosti_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- where_WRB the_DT nearest_JJS hypothesis_NN is_VBZ computed_VBN at_IN each_DT step_NN ,_, which_WDT is_VBZ supposed_VBN to_TO be_VB better_JJR ._.
The_DT handicap_NN of_IN using_VBG a_DT single_JJ reference_NN can_MD be_VB addressed_VBN by_IN constructing_VBG a_DT lattice_NN of_IN reference_NN translationsthis_NN technique_NN has_VBZ been_VBN used_VBN to_TO combine_VB the_DT output_NN of_IN multiple_JJ translation_NN systems_NNS -LRB-_-LRB- Rosti_NNP et_FW al._FW 2007_CD -RRB-_-RRB- ._.
In_IN addition_NN ,_, it_PRP may_MD also_RB be_VB used_VBN as_IN a_DT general-purpose_JJ string_NN alignment_NN toolTER_NN has_VBZ been_VBN used_VBN for_IN aligning_VBG multiple_JJ system_NN outputs_NNS to_TO each_DT other_JJ for_IN MT_NN system_NN combination_NN -LRB-_-LRB- Rosti_NNP et_FW al._FW 2007_CD -RRB-_-RRB- ,_, a_DT task_NN for_IN which_WDT TERp_NN may_MD be_VB even_RB better_RBR suited_VBN ._.
The_DT recent_JJ approaches_NNS used_VBN pairwise_JJ alignment_NN algorithms_NNS based_VBN on_IN symmetric_JJ alignments_NNS from_IN a_DT HMM_NN alignment_NN model_NN -LRB-_-LRB- Matusov_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- or_CC edit_VB distance_NN alignments_NNS allowing_VBG shifts_NNS -LRB-_-LRB- Rosti_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ._.
As_IN in_IN -LRB-_-LRB- Rosti_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ,_, confusion_NN networks_NNS built_VBN around_IN all_DT skeletons_NNS are_VBP joined_VBN into_IN a_DT lattice_NN which_WDT is_VBZ expanded_VBN and_CC re_SYM -_: scored_VBN with_IN language_NN models_NNS ._.
Other_JJ scores_NNS for_IN the_DT word_NN arc_NN are_VBP set_VBN as_IN in_IN -LRB-_-LRB- Rosti_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ._.
The_DT first_JJ ,_, syscomb_JJ pw_NN ,_, corresponds_VBZ BLEU_NNP System_NNP deen_NN fren_NN worst_JJS 11.84_CD 16.31_CD best_JJS 28.30_CD 33.13_CD syscomb_NN 29.05_CD 33.63_CD Table_NNP 3_CD The_DT handicap_NN of_IN using_VBG a_DT single_JJ reference_NN can_MD be_VB addressed_VBN by_IN the_DT construction_NN of_IN a_DT lattice_NN of_IN reference_NN translations.Such_NN a_DT technique_NN has_VBZ been_VBN used_VBN with_IN TER_NN to_TO combine_VB the_DT output_NN of_IN multiple_JJ translation_NN systems_NNS -LRB-_-LRB- Rosti_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ._.
Levin_NNP 's_POS classification_NN has_VBZ been_VBN extended_VBN by_IN other_JJ NLP_NN researchers_NNS -LRB-_-LRB- Dorr_NN and_CC Jones_NNP ,_, 1996_CD ;_: Dang_NNP et_FW al._FW ,_, 1998_CD -RRB-_-RRB- ._.
Dang_NNP et_FW al._FW -LRB-_-LRB- 1998_CD -RRB-_-RRB- modify_VB it_PRP by_IN adding_VBG new_JJ classes_NNS which_WDT remove_VBP the_DT overlap_VBP between_IN classes_NNS from_IN the_DT original_JJ scheme_NN ._.
\_NN tVe_NN think_VBP that_IN many_JJ cases_NNS of_IN amÂ_NN biguous_JJ classification_NN of_IN verb_VB types_NNS can_MD be_VB adÂ_JJ dressed_VBN with_IN the_DT notion_NN of_IN intersedive_JJ sets_NNS inÂ_NN troduced_VBN by_IN -LRB-_-LRB- Dang_NNP ct_VBD a_DT !_. ._.
,_, 1998_CD -RRB-_-RRB- ._.
Many_JJ verbs_NNS are_VBP listed_VBN in_IN multiple_JJ classes_NNS ,_, some_DT of_IN which_WDT have_VBP conflicting_VBG sets_NNS of_IN syntactic_JJ frames.Dang_NN ct_NN al._FW -LRB-_-LRB- 1998_CD -RRB-_-RRB- showed_VBD that_IN multiple_JJ listings_NNS could_MD in_IN some_DT cases_NNS be_VB interpreted_VBN as_IN regular_JJ sense_NN extensions_NNS ,_, and_CC defined_VBN intcrsectivc_NN Levin_NNP classes_NNS ,_, which_WDT are_VBP a_DT more_JJR fine-grained_JJ ,_, syntactically_RB and_CC semantically_RB coherÂ_JJ ent_NN refinement_NN of_IN basic_JJ Levin_NNP classes_NNS ._.
We_PRP think_VBP that_IN many_JJ cases_NNS of_IN ambiguÂ_NN ous_JJ classification_NN of_IN the_DT lexical_JJ entry_NN for_IN a_DT verb_VBP can_MD be_VB addressed_VBN with_IN the_DT notion_NN of_IN intersective_JJ sets_NNS introduced_VBN by_IN Dang_NNP et_FW al._FW -LRB-_-LRB- 1998_CD -RRB-_-RRB- ._.
This_DT constraint_NN of_IN having_VBG the_DT same_JJ semantic_JJ roles_NNS is_VBZ further_JJ ensured_VBD inside_IN the_DT VN_NNP lexicon_NN which_WDT is_VBZ constructed_VBN based_VBN on_IN a_DT more_RBR refined_JJ version_NN of_IN the_DT Levinâ_NNP $_$ ™_CD s_NNS classification_NN ,_, called_VBN Intersective_NNP Levin_NNP classes_NNS -LRB-_-LRB- ILCs_NNS -RRB-_-RRB- -LRB-_-LRB- Dang_NNP et_FW al._FW ,_, 1998_CD -RRB-_-RRB- ._.
This_DT reorganization_NN which_WDT was_VBD facilitated_VBN by_IN the_DT use_NN of_IN inter_NN -_: sective_JJ Levin_NNP classes_NNS -LRB-_-LRB- Dang_NNP et_FW al_FW 1998_CD -RRB-_-RRB- refined_VBN the_DT classes_NNS to_TO account_VB for_IN semantic_JJ and_CC syntactic_JJ differences_NNS within_IN a_DT class_NN We_PRP also_RB plan_VBP to_TO experiment_NN with_IN different_JJ classification_NN schemes_NNS for_IN verb_VBP semantics_NNS such_JJ as_IN WordNet_NNP -LRB-_-LRB- Miller_NNP et_FW al._FW ,_, 1990_CD -RRB-_-RRB- and_CC intersective_JJ Levin_NNP classes_NNS -LRB-_-LRB- Dang_NNP et_FW al._FW ,_, 1998_CD -RRB-_-RRB- ._.
And_CC ._.
nally_RB ,_, TAGPAIR_NN uses_VBZ classi.cation_NN pair_NN weights_NNS based_VBN on_IN the_DT probability_NN of_IN a_DT classi.cation_NN for_IN some_DT predicted_VBN classi.cation_NN pair_NN -LRB-_-LRB- van_NN Halteren_NNP et_FW al._FW ,_, 1998_CD -RRB-_-RRB- ._.
Like_IN Van_NNP Halteren_NNP et_FW al._FW -LRB-_-LRB- 1998_CD -RRB-_-RRB- ,_, we_PRP evaluated_VBD two_CD features_NNS combinations_NNS ._.
We_PRP consider_VBP three_CD voting_VBG strategies_NNS suggested_VBN by_IN van_NN Halteren_NNP et_FW al._FW -LRB-_-LRB- 1998_CD -RRB-_-RRB- Combination_NN techniques_NNS have_VBP been_VBN successfully_RB applied_VBN to_TO part_NN of_IN speech_NN tagging_NN -LRB-_-LRB- van_NN Halteren_NNP et_FW al._FW ,_, 1998_CD ;_: Brill_NNP and_CC Wu_NNP ,_, 1998_CD ;_: van_NN Halteren_NNP et_FW al._FW ,_, 2001_CD -RRB-_-RRB- ._.
In_IN both_DT cases_NNS the_DT investigators_NNS were_VBD able_JJ to_TO achieve_VB significant_JJ improvements_NNS over_IN the_DT previous_JJ best_JJS tagging_NN results_NNS ._.
Parallel_JJ to_TO -LRB-_-LRB- van_NN Halteren_NNP et_FW al._FW ,_, 1998_CD -RRB-_-RRB- ,_, we_PRP ran_VBD experiments_NNS with_IN two_CD stacked_VBN classifiers_NNS ,_, Memory-Based_JJ ,_, and_CC Decision-Tree-Based_JJ ._.
In_IN all_DT experiments_NNS ,_, the_DT TotPrecision_NNP voting_NN scheme_NN of_IN -LRB-_-LRB- van_NN Halteren_NNP et_FW al._FW ,_, 1998_CD -RRB-_-RRB- has_VBZ been_VBN used_VBN ._.
The_DT most_RBS advanced_JJ voting_NN method_NN ex_FW amines_FW output_NN values_NNS of_IN pairs_NNS of_IN classifiers_NNS and_CC assigns_VBZ weights_NNS to_TO tags_NNS based_VBN on_IN how_WRB often_RB they_PRP appear_VBP with_IN this_DT pair_NN in_IN the_DT tuning_NN data_NNS -LRB-_-LRB- Tag_NN Pair_NN ,_, Van_NNP Halteren_NNP et_FW al._FW ,_, -LRB-_-LRB- 1998_CD -RRB-_-RRB- -RRB-_-RRB- ._.
We_PRP will_MD evaluate_VB nine_CD different_JJ methods_NNS for_IN combining_VBG the_DT output_NN of_IN our_PRP$ five_CD chunkers_NNS -LRB-_-LRB- Van_NNP Halteren_NNP et_FW al._FW ,_, 1998_CD -RRB-_-RRB- ._.
Five_CD are_VBP so-called_JJ voting_NN methods.They_NN assign_VBP weights_NNS to_TO the_DT output_NN of_IN the_DT individual_JJ systems_NNS and_CC use_VB these_DT weights_NNS to_TO determine_VB the_DT most_RBS probable_JJ output_NN tag_NN ._.
For_IN this_DT purpose_NN we_PRP have_VBP used_VBN the_DT part-of-speech_JJ tag_NN of_IN the_DT cur_NN rent_NN word_NN as_IN compressed_VBN representation_NN of_IN the_DT first_JJ stage_NN input_NN -LRB-_-LRB- Van_NNP Halteren_NNP et_FW al._FW ,_, 1998_CD -RRB-_-RRB- ._.
For_IN part-of-speech_JJ tagging_NN ,_, a_DT significant_JJ increase_NN in_IN accuracy_NN through_IN combining_VBG the_DT output_NN of_IN different_JJ taggers_NNS was_VBD first_JJ demonstrated_VBN in_IN van_NN Halteren_NNP ,_, Zavrel_NNP ,_, and_CC Daelemans_NNP -LRB-_-LRB- 1998_CD -RRB-_-RRB- and_CC Brill_NNP and_CC Wu_NNP -LRB-_-LRB- 1998_CD -RRB-_-RRB- ._.
In_IN both_DT approaches_NNS ,_, different_JJ tagger_NN gen_NN erators_NNS were_VBD applied_VBN to_TO the_DT same_JJ training_NN data_NNS and_CC their_PRP$ predictions_NNS combined_VBN using_VBG different_JJ combination_NN methods_NNS ,_, including_VBG stacking.As_NN we_PRP now_RB apply_VBP the_DT methods_NNS of_IN van_NN Halteren_NNP ,_, Zavrel_NNP ,_, and_CC Daelemans_NNP -LRB-_-LRB- 1998_CD -RRB-_-RRB- to_TO WSJ_NNP as_RB well_RB ,_, it_PRP is_VBZ easier_JJR to_TO make_VB a_DT comparison_NN ._.
One_CD of_IN the_DT best_JJS methods_NNS for_IN tagger_NN combination_NN in_IN -LRB-_-LRB- van_NN Halteren_NNP ,_, Zavrel_NNP ,_, and_CC Daele_NNP mans_VBZ 1998_CD -RRB-_-RRB- is_VBZ the_DT TagPair_NNP method.It_NN looks_VBZ at_IN all_DT situations_NNS where_WRB one_CD tagger_NN suggests_VBZ tag1_NN and_CC the_DT other_JJ tag2_NN and_CC estimates_VBZ the_DT probability_NN that_IN in_IN this_DT situation_NN the_DT tag_NN should_MD actually_RB be_VB tagx.Although_JJ it_PRP is_VBZ presented_VBN as_IN a_DT variant_NN of_IN voting_NN in_IN that_DT paper_NN ,_, it_PRP is_VBZ in_IN fact_NN also_RB a_DT stacked_VBN classifier_NN ,_, because_IN it_PRP does_VBZ not_RB necessarily_RB select_JJ one_CD of_IN the_DT tags_NNS suggested_VBN by_IN the_DT component_NN taggers_NNS ._.
The_DT first_JJ is_VBZ the_DT LOB_NN corpus_NN -LRB-_-LRB- Johansson_NNP 1986_CD -RRB-_-RRB- ,_, which_WDT we_PRP used_VBD in_IN the_DT earlier_JJR experiments_NNS as_RB well_RB -LRB-_-LRB- van_NN Halteren_NNP ,_, Zavrel_NNP ,_, and_CC Daelemans_NNP 1998_CD -RRB-_-RRB- and_CC which_WDT has_VBZ proved_VBN to_TO be_VB a_DT good_JJ testing_NN ground_NN ._.
The_DT anaphora_NN resolver_NN is_VBZ an_DT adaptation_NN for_IN Bulgarian_JJ of_IN Mitkovs_NNP knowledge-poor_JJ pronoun_NN resolution_NN approach_NN -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- ._.
This_DT module_NN resolves_VBZ third-person_JJ personal_JJ pronouns_NNS and_CC is_VBZ an_DT adaptation_NN of_IN Mitkovâ_NNP $_$ ™_CD s_NNS robust_JJ ,_, knowledge-poor_JJ multilingual_JJ approach_NN -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- whose_WP$ latest_JJS implementation_NN by_IN R._NNP Evans_NNP is_VBZ referred_VBN to_TO as_IN MARS_NN 2_CD -LRB-_-LRB- Orasan_NNP et_FW al._FW ,_, 2000_CD -RRB-_-RRB- ._.
LINGUA_NNP performs_VBZ the_DT pre-processing_JJ ,_, needed_VBN as_IN an_DT input_NN to_TO the_DT anaphora_NN resolution_NN algorithm_NN Most_JJS of_IN the_DT indicators_NNS have_VBP been_VBN adopted_VBN in_IN LINGUA_NN without_IN modification_NN from_IN the_DT original_JJ English_NNP version_NN -LRB-_-LRB- see_VB -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- for_IN more_JJR details_NNS -RRB-_-RRB- ._.
Binding_NN constraints_NNS have_VBP been_VBN in_IN the_DT focus_NN of_IN linguistic_JJ research_NN for_IN more_JJR than_IN thirty_CD years.They_NN provide_VBP restrictions_NNS on_IN coindexation_NN of_IN pronouns_NNS with_IN clause_NN siblings_NNS ,_, and_CC therefore_RB can_MD only_RB be_VB applied_VBN with_IN systems_NNS that_WDT determine_VBP clause_NN boundaries_NNS ,_, i.e._FW parsers_FW -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- ._.
However_RB ,_, the_DT pressing_VBG need_NN for_IN the_DT development_NN of_IN robust_JJ and_CC inexpensive_JJ solutions_NNS encouraged_VBD the_DT drive_NN toward_IN knowledge-poor_JJ strategies_NNS -LRB-_-LRB- Dagan_NNP and_CC Itai_NNP 1990_CD ;_: Lappin_NNP and_CC Leass_NNP 1994_CD ;_: Mitkov_NNP 1998_CD ;_: The_DT search_NN scope_NN for_IN candidate_NN antecedents_NNS is_VBZ set_VBN to_TO the_DT current_JJ sentence_NN together_RB with_IN the_DT three_CD preceding_VBG sentences_NNS as_IN suggested_VBN in_IN -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- Like_IN many_JJ heuristic-based_JJ pronoun_NN resolvers_NNS -LRB-_-LRB- e.g._FW ,_, Mitkov_NNP -LRB-_-LRB- 1998_CD -RRB-_-RRB- -RRB-_-RRB- ,_, they_PRP first_RB apply_VB a_DT set_NN of_IN constraints_NNS to_TO filter_NN grammatically_RB incompatible_JJ candidate_NN antecedents_NNS and_CC then_RB rank_VB the_DT remaining_VBG ones_NNS using_VBG salience_NN factors_NNS ._.
We_PRP implemented_VBD meta-modules_NNS to_TO inÂ_NN terface_NN to_TO the_DT genetic_JJ algorithm_NN driver_NN and_CC to_TO combine_VB different_JJ salience_NN factors_NNS into_IN an_DT overÂ_NN all_DT score_NN -LRB-_-LRB- similar_JJ to_TO -LRB-_-LRB- Carbonell_NNP and_CC Brown_NNP ,_, 1988_CD ;_: Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- -RRB-_-RRB- ._.
The_DT current_JJ version_NN of_IN the_DT system_NN includes_VBZ an_DT implementation_NN of_IN the_DT MARS_NNP pronoun_NN resolution_NN algorithm_NN -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- 3.2.1_CD Pronoun_NNP Resolution_NNP Mitkov_NNP -LRB-_-LRB- 1998_CD -RRB-_-RRB- developed_VBD a_DT robust_JJ approach_NN to_TO pronoun_NN resolution_NN which_WDT only_RB requires_VBZ input_NN text_NN to_TO be_VB part-of-speech_JJ tagged_VBN and_CC noun_NN phrases_NNS to_TO be_VB identified.Mitkovâ_JJ $_$ ™_CD s_NNS algorithm_NN operates_VBZ on_IN the_DT basis_NN of_IN antecedent-tracking_JJ preferences_NNS -LRB-_-LRB- referred_VBN to_TO hereafter_RB as_IN â_NN $_$ antecedent_JJ indicatorsâ_NN $_$ -RRB-_-RRB- ._.
The_DT approach_NN works_VBZ as_IN follows_VBZ Early_JJ work_NN on_IN pronoun_NN anaphora_NN resolution_NN usually_RB uses_VBZ rule-based_JJ methods_NNS -LRB-_-LRB- e.g._FW Hobbs_FW 1976_CD ;_: Ge_NNP et_FW al._FW ,_, 1998_CD ;_: Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- ,_, which_WDT try_VBP to_TO mine_VB the_DT cues_NNS of_IN the_DT relation_NN between_IN the_DT pronouns_NNS and_CC its_PRP$ antecedents_NNS ._.
A_DT lot_NN of_IN work_NN has_VBZ been_VBN done_VBN in_IN English_NNP for_IN the_DT purpose_NN of_IN anaphora_NN resolution_NN and_CC various_JJ algorithms_NNS have_VBP been_VBN devised_VBN for_IN this_DT purpose_NN -LRB-_-LRB- Aone_NN and_CC Bennette_NN ,_, 1996_CD ;_: Brenan_NNP ,_, Friedman_NNP and_CC Pollard_NNP ,_, 1987_CD ;_: Ge_NNP ,_, Hale_NNP and_CC Charniak_NNP ,_, 1998_CD ;_: Grosz_NNP ,_, Aravind_NNP and_CC Weinstein_NNP ,_, 1995_CD ;_: McCarthy_NNP and_CC Lehnert_NNP ,_, 1995_CD ;_: Lappins_NNP and_CC Leass_NNP ,_, 1994_CD ;_: Mitkov_NNP ,_, 1998_CD ;_: Soon_RB ,_, Ng_NN and_CC Lim_NNP ,_, 1999_CD -RRB-_-RRB- ._.
How_WRB these_DT factors_NNS are_VBP helpful_JJ in_IN anaphora_NN resolution_NN in_IN English_JJ language_NN was_VBD worked_VBN out_RP by_IN Mitkov_NNP -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- ,_, but_CC their_PRP$ role_NN in_IN Urdu_NNP discourse_NN for_IN the_DT resolution_NN of_IN personal_JJ pronouns_NNS is_VBZ more_RBR cherished_VBN ._.
Many_JJ hand-tested_JJ corpus_NN evaluations_NNS have_VBP been_VBN done_VBN in_IN the_DT past_NN -LRB-_-LRB- e.g._FW ,_, Walker_NNP 1989_CD ;_: Strube_NNP 1998_CD ;_: Mitkov_NNP 1998_CD ;_: Strube_NNP and_CC Hahn_NNP 1999_CD -RRB-_-RRB- ,_, but_CC these_DT have_VBP the_DT drawback_NN of_IN being_VBG carried_VBN out_RP on_IN small_JJ corpora_NN ._.
Consequently_RB ,_, current_JJ anaphora_NN resolution_NN methods_NNS rely_VBP mainly_RB on_IN constraint_NN and_CC preference_NN heuristics_NNS ,_, which_WDT employ_VBP morpho-syntactic_JJ information_NN or_CC shallow_JJ semantic_JJ analysis_NN -LRB-_-LRB- see_VB ,_, for_IN example_NN ,_, Mitkov_NNP -LSB-_-LRB- 1998_CD -RSB-_-RRB- -RRB-_-RRB- ._.
Exa_NN mple_NN s_VBZ The_DT acquisition_NN of_IN exten_NN sive_JJ linguistic_JJ and_CC discourse_NN knowledge_NN necessaryfor_NN resolving_VBG coreference_NN is_VBZ time_NN consuming_JJ ,_, diffi_JJ cult_NN and_CC error-prone_NN ._.
Neverthless_NNP ,_, recent_JJ resultsshow_NN that_WDT knowledge-poor_NN ,_, empirical_JJ methods_NNS per_IN form_NN with_IN amazing_JJ accuracy_NN on_IN certain_JJ forms_NNS ofcoreference_NN -LRB-_-LRB- cf._VB -LRB-_-LRB- Mitkov_NNP 1998_CD -RRB-_-RRB- -LRB-_-LRB- Kennedy_NNP and_CC Boguraev_NNP 1996_CD -RRB-_-RRB- -LRB-_-LRB- Kameyama_NNP 1997_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Unlike_IN other_JJ knowledge-poor_JJ methods_NNS for_IN coreference_NN resolution_NN -LRB-_-LRB- Baldwin_NNP 1997_CD -RRB-_-RRB- -LRB-_-LRB- Mitkov_NNP 1998_CD -RRB-_-RRB- ,_, COCK_NNP TAIL_NNP filters_VBZ its_PRP$ most_RBS performant_JJ rules_NNS through_IN massivetraining_VBG data_NNS ,_, generated_VBN by_IN its_PRP$ AUTOTAGCOFtEF_NN com_NN ponent_NN ._.
Mitkov_NNP showed_VBD that_IN a_DT salience-based_JJ approach_NN can_MD be_VB applied_VBN across_IN genres_NNS and_CC without_IN complex_JJ syntactic_NN ,_, semantic_JJ ,_, and_CC discourse_NN analysis_NN -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- ._.
Consequently_RB ,_, current_JJ anaphora_NN resolution_NN methods_NNS rely_VBP mainly_RB on_IN restrictions_NNS and_CC preference_NN heuristics_NNS ,_, which_WDT employ_VBP information_NN originating_VBG from_IN morpho-syntactic_JJ or_CC shallow_JJ semantic_JJ analysis_NN ,_, -LRB-_-LRB- see_VB Mitkov_NNP -LRB-_-LRB- 1998_CD -RRB-_-RRB- for_IN example_NN -RRB-_-RRB- ._.
Mitkov_NNP -LRB-_-LRB- 1998_CD -RRB-_-RRB- obtains_VBZ a_DT success_NN rate_NN of_IN 89.7_CD %_NN for_IN pronominal_JJ references_NNS ,_, working_VBG with_IN English_NNP technical_JJ manuals_NNS ._.
Ruslan_NNP Mitkov_NNP -LRB-_-LRB- 1998_CD -RRB-_-RRB- Robust_JJ pronoun_NN resolution_NN th_DT evaluation_NN ,_, several_JJ baselines_NNS on_IN pronominal_JJ anaphora_NN resolution_NN have_VBP been_VBN implemented_VBN ,_, and_CC with_IN limited_JJ knowledge_NN ._.
We_PRP selected_VBD for_IN comparative_JJ evaluation_NN three_CD approaches_NNS extensively_RB cited_VBD in_IN the_DT literature_NN Mitkovâ_NNP $_$ ™_CD s_NNS approach_VBP Mitkovâ_NNP $_$ ™_CD s_NNS approach_NN -LRB-_-LRB- Mitkov_NNP ,_, 1998b_NN -RRB-_-RRB- is_VBZ a_DT robust_JJ anaphora_NN resolution_NN method_NN for_IN technical_JJ texts_NNS which_WDT is_VBZ based_VBN on_IN a_DT set_NN of_IN boosting_VBG and_CC impeding_VBG indicators_NNS applied_VBN to_TO each_DT candidate_NN for_IN antecedent_JJ ._.
Our_PRP$ paper_NN discusses_VBZ a_DT particular_JJ configuration_NN of_IN this_DT new_JJ evaluation_NN environment_NN incorporating_VBG three_CD approaches_NNS sharing_VBG a_DT common_JJ â_NN $_$ knowledge-poor_JJ philosophyâ_NN $_$ Mitkovâ_JJ $_$ ™_CD s_NNS knowledge-poor_JJ pronoun_NN resolution_NN method_NN -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- ,_, for_IN example_NN ,_, uses_VBZ the_DT scores_NNS from_IN a_DT set_NN of_IN antecedent_JJ indicators_NNS to_TO rank_VB the_DT candidates_NNS ._.
The_DT coreferential_JJ chain_NN length_NN of_IN a_DT candidate_NN ,_, or_CC its_PRP$ variants_NNS such_JJ as_IN occurrence_NN frequency_NN and_CC TFIDF_NN ,_, has_VBZ been_VBN used_VBN as_IN a_DT salience_NN factor_NN in_IN some_DT learning-based_JJ reference_NN resolution_NN systems_NNS -LRB-_-LRB- Iida_NNP et_FW al._FW ,_, 2003_CD ;_: Mitkov_NNP ,_, 1998_CD ;_: Paul_NNP et_FW al._FW ,_, 1999_CD ;_: Strube_NNP and_CC Muller_NNP ,_, 2003_CD -RRB-_-RRB- ._.
Early_RB work_NN of_IN anaphora_NN resolution_NN focuses_VBZ on_IN find_VB ing_JJ antecedents_NNS of_IN pronouns_NNS -LRB-_-LRB- Hobbs_NNS ,_, 1976_CD ;_: Ge_NNP et_FW al._FW ,_, 1998_CD ;_: Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- ParalStuctmarks_NNPS whether_IN a_DT candidate_NN and_CC an_DT anaphor_NN have_VBP sim_NN StatSemN_NN -LRB-_-LRB- C_NN ,_, ana_NN -RRB-_-RRB- =_JJ c_NN max_NN StatSem_NNP -LRB-_-LRB- ci_NNP ,_, ana_NN -RRB-_-RRB- -LRB-_-LRB- ana_NN -RRB-_-RRB- ilar_JJ surrounding_VBG words_NNS ,_, which_WDT is_VBZ also_RB a_DT salience_NN factor_NN for_IN the_DT candidate_NN evaluation_NN -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- ._.
These_DT features_NNS are_VBP calculated_VBN by_IN mining_VBG the_DT parse_NN trees_NNS ,_, and_CC then_RB could_MD be_VB used_VBN for_IN resolution_NN by_IN using_VBG manually_RB designed_VBN rules_NNS -LRB-_-LRB- Lappin_NN and_CC Leass_NN ,_, 1994_CD ;_: Kennedy_NNP and_CC Boguraev_NNP ,_, 1996_CD ;_: Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- ,_, or_CC using_VBG machine-learning_JJ methods_NNS -LRB-_-LRB- Aone_NN and_CC Bennett_NNP ,_, 1995_CD ;_: Yang_NNP et_FW al._FW ,_, 2004_CD ;_: Luo_NNP and_CC Zitouni_NNP ,_, 2005_CD -RRB-_-RRB- ._.
In_IN knowledge-lean_JJ approaches_NNS ,_, coreference_NN resolvers_NNS employ_VBP only_RB morpho-syntactic_JJ cues_NNS as_IN knowledge_NN sources_NNS in_IN the_DT resolution_NN process_NN -LRB-_-LRB- e.g._FW ,_, Mitkov_NNP -LRB-_-LRB- 1998_CD -RRB-_-RRB- ,_, Tetreault_NNP -LRB-_-LRB- 2001_CD -RRB-_-RRB- -RRB-_-RRB- ._.
While_IN not_RB developed_VBN within_IN a_DT graph-based_JJ framework_NN ,_, factor-based_JJ approaches_NNS for_IN pronoun_NN resolution_NN -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- can_MD be_VB regarded_VBN as_IN greedy_JJ clustering_NN in_IN a_DT multigraph_JJ ,_, where_WRB edges_NNS representing_VBG factors_NNS for_IN pronoun_NN resolution_NN have_VBP negative_JJ or_CC positive_JJ weight_NN ._.
Coreference_NN resolution_NN is_VBZ a_DT field_NN in_IN which_WDT major_JJ progress_NN has_VBZ been_VBN made_VBN in_IN the_DT last_JJ decade.After_NN a_DT concentration_NN on_IN rule-based_JJ systems_NNS -LRB-_-LRB- cf.e.g_NN ._.
-LRB-_-LRB- Mitkov_NNP ,_, 1998_CD ;_: Poesio_NNP et_FW al._FW ,_, 2002_CD ;_: Markert_NNP and_CC Nissim_NNP ,_, 2005_CD -RRB-_-RRB- -RRB-_-RRB- ,_, machine_NN learning_NN methods_NNS were_VBD embraced_VBN -LRB-_-LRB- cf._VBP They_PRP use_VB limited_JJ knowledge_NN -LRB-_-LRB- lexical_JJ ,_, morphological_JJ and_CC syntacticinformation_NN sources_NNS -RRB-_-RRB- for_IN the_DT detection_NN of_IN the_DT cor_NN rect_NN antecedent.These_NN proposals_NNS have_VBP report_NN high_JJ success_NN rates_NNS for_IN English_NNP -LRB-_-LRB- 89.7_CD %_NN -RRB-_-RRB- -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- G_NN U_NN I_PRP TA_NNP R_NNP -LRB-_-LRB- Poesio_NNP and_CC AlexandrovKabadjov_NNP ,_, 2004_CD -RRB-_-RRB- is_VBZ a_DT general-purpose_JJ anaphoric_JJ resolver_NN that_WDT includes_VBZ an_DT implementation_NN of_IN the_DT Vieira_NNP /_: Poesio_NNP algorithm_NN for_IN definite_JJ descriptions_NNS and_CC of_IN Mitkovâ_NNP $_$ ™_CD s_NNS algorithm_NN for_IN pronoun_NN resolution_NN -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- ._.
In_IN most_JJS systems_NNS -LRB-_-LRB- -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Lappin_NNP and_CC Leass_NNP ,_, 1994_CD -RRB-_-RRB- -RRB-_-RRB- the_DT weights_NNS that_WDT are_VBP assigned_VBN for_IN different_JJ anaphor-antecedent_JJ relationships_NNS are_VBP programmer_NN dependent_JJ ._.
The_DT approach_NN is_VBZ presented_VBN as_IN a_DT knowledge_NN poor_JJ anaphora_NN resolution_NN algorithm_NN -LRB-_-LRB- Mitkov_NNP R._NNP -LSB-_-LRB- 1995_CD ;_: 1998_CD -RSB-_-RRB- -RRB-_-RRB- ,_, which_WDT makes_VBZ use_NN of_IN POS_NN and_CC NP_NN chunking_NN ,_, it_PRP tries_VBZ to_TO individuate_VB pleonastic_JJ â_NN $_$ œitâ_CD $_$ occurrences_NNS ,_, and_CC assigns_VBZ animacy_NN ._.
Some_DT of_IN the_DT limitations_NNS of_IN the_DT traditional_JJ rule_NN based_VBN approaches_NNS -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- could_MD be_VB overcome_VBN by_IN machine_NN learning_NN techniques_NNS ,_, which_WDT allow_VBP automating_VBG the_DT acquisition_NN of_IN knowledge_NN from_IN annotated_JJ corpora_NN ._.
Other_JJ pronominal_JJ resolution_NN approaches_NNS promote_VBP knowledge-poor_JJ methods_NNS -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- ,_, eitper_NN by_IN using_VBG an_DT ordered_VBN set_NN of_IN general_JJ heuristics_NNS or_CC by_IN combining_VBG scores_NNS assigned_VBN to_TO candidate_NN antecedents_NNS ._.
The_DT CogNIAC_NN algorithm_NN -LCB-_-LRB- Baldwin_NNP ,_, 1997_CD -RRB-_-RRB- uses_VBZ six_CD heuristic_NN rules_NNS to_TO resalv.e_VB coreference_NN ,_, whereas_IN the_DT algorithm_NN presented_VBN in_IN -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- is_VBZ based_VBN on_IN a_DT limited_JJ set_NN of_IN preferences_NNS -LRB-_-LRB- e.g._FW definitiveness_NN ,_, l_NN cal_JJ reiteration_NN or_CC immediate_JJ reference_NN -RRB-_-RRB- ._.
However_RB ,_, the_DT difficulty_NN of_IN our_PRP$ task_NN can_MD be_VB verified_VBN according_VBG to_TO the_DT baseline_NN experiment_NN results_VBZ reported_VBN in_IN -LRB-_-LRB- Mitkov_NNP ,_, 1998_CD -RRB-_-RRB- ._.
Resolving_NNP pro_JJ nouns_NNS in_IN English_NNP technical_JJ manuals_NNS to_TO the_DT most_RBS re_JJ cent_NN candidate_NN achieved_VBD a_DT success_NN rate_NN of_IN 62.5_CD %_NN ,_, whereas_IN in_IN our_PRP$ experiments_NNS only_RB 43.9_CD %_NN of_IN the_DT most_RBS recent_JJ candidates_NNS are_VBP resolved_VBN correctly_RB as_IN the_DT an_DT tecedent_NN -LRB-_-LRB- cf._VB Stevenson_NNP and_CC Joanis_NNP ,_, 2003_CD for_IN English_NNP semantic_JJ verb_VB classes_NNS We_PRP adopt_VBP as_IN our_PRP$ baseline_NN method_NN a_DT well-known_JJ hierarchical_JJ method_NN --_: agglomerative_JJ clustering_NN -LRB-_-LRB- AGG_NN -RRB-_-RRB- --_: which_WDT has_VBZ been_VBN previously_RB used_VBN to_TO acquire_VB flat_JJ Levin-style_JJ classifications_NNS -LRB-_-LRB- Stevenson_NNP and_CC Joanis_NNP ,_, 2003_CD -RRB-_-RRB- We_PRP used_VBD three_CD gold_NN standards_NNS -LRB-_-LRB- and_CC corresponding_JJ test_NN sets_NNS -RRB-_-RRB- extracted_VBN from_IN these_DT resources_NNS in_IN our_PRP$ experiments_NNS Following_VBG Stevenson_NNP and_CC Joanis_NNP -LRB-_-LRB- 2003_CD -RRB-_-RRB- ,_, we_PRP selected_VBD 20_CD verbs_NNS from_IN each_DT class_NN which_WDT occur_VBP at_IN least_JJS 100_CD times_NNS in_IN our_PRP$ corpus_NN ._.
Previous_JJ works_NNS on_IN Levin_NNP style_NN verb_VB classification_NN have_VBP investigated_VBN optimal_JJ features_NNS for_IN this_DT task_NN -LRB-_-LRB- Stevenson_NNP and_CC Joanis_NNP ,_, 2003_CD ;_: Li_NNP and_CC Brew_NNP ,_, 2008_CD ;_: Sun_NNP and_CC Korhonen_NNP ,_, 2009_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Table_NNP 1_CD Table_NNP 1_CD shows_VBZ our_PRP$ results_NNS and_CC the_DT results_NNS of_IN Stevenson_NNP and_CC Joanis_NNP -LRB-_-LRB- 2003_CD -RRB-_-RRB- on_IN T1_NN when_WRB employing_VBG AGG_NNP using_VBG Ward_NNP as_IN the_DT linkage_NN criterion_NN ._.
In_IN this_DT experiment_NN ,_, we_PRP used_VBD the_DT same_JJ feature_NN set_VBN as_IN Stevenson_NNP and_CC Joanis_NNP -LRB-_-LRB- 2003_CD -RRB-_-RRB- -LRB-_-LRB- set_NN B_NN ,_, see_VBP section_NN 3.1_CD -RRB-_-RRB- and_CC were_VBD therefore_RB able_JJ to_TO reproduce_VB their_PRP$ AGG_NNP result_NN with_IN a_DT difference_NN smaller_JJR than_IN 2_CD %_NN ._.
For_IN example_NN ,_, the_DT accuracy/purity_NN measure_NN -LRB-_-LRB- Stevenson_NNP and_CC Joanis_NNP 2003_CD ;_: Korhonen_NNP ,_, Krymolowski_NNP ,_, and_CC Marx_NNP 2003_CD -RRB-_-RRB- evaluates_VBZ whether_IN a_DT verb_VBP is_VBZ assigned_VBN to_TO a_DT correct_JJ cluster_NN with_IN respect_NN to_TO the_DT gold_JJ standard_JJ class_NN of_IN the_DT majority_NN of_IN cluster_NN members_NNS ._.
In_IN recent_JJ work_NN ,_, Stevenson_NNP and_CC Joanis_NNP -LRB-_-LRB- 2003_CD -RRB-_-RRB- compared_VBN their_PRP$ supervised_JJ method_NN for_IN verb_VB classification_NN with_IN semisupervised_VBN and_CC unsupervised_JJ techniques.In_NN these_DT experiments_NNS ,_, they_PRP enlarged_JJ the_DT number_NN of_IN gold_JJ standard_JJ English_JJ verb_VB classes_NNS to_TO 14_CD classes_NNS related_JJ to_TO Levin_NNP classes_NNS ,_, with_IN a_DT total_NN of_IN 841_CD verbs.Low_NN -_: frequency_NN and_CC ambiguous_JJ verbs_NNS were_VBD excluded_VBN from_IN the_DT classes.They_NN found_VBD that_IN a_DT semisupervised_JJ approach_NN where_WRB the_DT classifier_NN was_VBD trained_VBN with_IN five_CD seed_NN verbs_NNS from_IN each_DT verb_VB class_NN outperformed_VBD both_CC a_DT manual_JJ selection_NN of_IN features_NNS and_CC the_DT unsupervised_JJ 186_CD approach_NN of_IN Dash_NN ,_, Liu_NNP ,_, and_CC Yao_NNP -LRB-_-LRB- 1997_CD -RRB-_-RRB- ,_, which_WDT used_VBD an_DT entropy_NN measure_NN to_TO organize_VB data_NNS into_IN a_DT multidimensional_JJ space_NN ._.
Our_PRP$ second_JJ measure_NN is_VBZ derived_VBN from_IN purity_NN ,_, a_DT global_JJ measure_NN which_WDT evaluates_VBZ the_DT mean_NN precision_NN of_IN the_DT clusters_NNS ,_, weighted_JJ according_VBG to_TO the_DT cluster_NN size_NN -LRB-_-LRB- Stevenson_NNP and_CC Joanis_NNP ,_, 2003_CD -RRB-_-RRB- ._.
For_IN this_DT reason_NN ,_, various_JJ methods_NNS for_IN automatically_RB classifying_VBG verbs_NNS using_VBG machine_NN learning_NN techniques_NNS have_VBP been_VBN attempted_VBN -LRB-_-LRB- -LRB-_-LRB- Merlo_NNP and_CC Stevenson_NNP ,_, 2001_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Stevenson_NNP and_CC Joanis_NNP ,_, 2003_CD -RRB-_-RRB- ,_, -LRB-_-LRB- Schulte_NNP im_NNP Walde_NNP ,_, 2003_CD -RRB-_-RRB- -RRB-_-RRB- ._.
As_IN an_DT alternative_NN to_TO the_DT resource-intensive_JJ manual_JJ classifications_NNS ,_, automatic_JJ methods_NNS such_JJ as_IN classification_NN and_CC clustering_NN are_VBP applied_VBN to_TO induce_VB verb_VB classes_NNS from_IN corpus_NN data_NNS ,_, e.g._FW -LRB-_-LRB- Merlo_NNP and_CC Stevenson_NNP ,_, 2001_CD ;_: Joanis_NNP and_CC Stevenson_NNP ,_, 2003_CD ;_: Korhonen_NNP et_FW al._FW ,_, 2003_CD ;_: Stevenson_NNP and_CC Joanis_NNP ,_, 2003_CD ;_: Schulte_NNP im_NNP Walde_NNP ,_, 2003_CD ;_: Fer_SYM -_: rer_NN ,_, 2004_CD -RRB-_-RRB- ._.
In_IN larger-scale_JJ classifications_NNS such_JJ as_IN -LRB-_-LRB- Korhonen_NNP et_FW al._FW ,_, 2003_CD ;_: Stevenson_NNP and_CC Joanis_NNP ,_, 2003_CD ;_: Schulte_NNP im_NNP Walde_NNP ,_, 2003_CD -RRB-_-RRB- ,_, which_WDT model_VBP verb_VB classes_NNS with_IN similarity_NN at_IN the_DT syntax-semantics_NNS interface_NN ,_, it_PRP is_VBZ not_RB clear_JJ which_WDT features_NNS are_VBP the_DT most_RBS salient_JJ ._.
For_IN the_DT evaluation_NN of_IN the_DT clustering_NN results_VBZ ,_, we_PRP calculated_VBD the_DT accuracy_NN of_IN the_DT clusters_NNS ,_, a_DT cluster_NN similarity_NN measure_NN that_WDT has_VBZ been_VBN applied_VBN before_RB ,_, cf._VBP -LRB-_-LRB- Stevenson_NNP and_CC Joanis_NNP ,_, 2003_CD ;_: Korhonen_NNP et_FW al._FW ,_, 2003_CD -RRB-_-RRB- Two_CD examples_NNS of_IN such_JJ corpora_NN are_VBP the_DT RST_NNP Tree_NNP Corpus_NNP by_IN -LRB-_-LRB- Marcu_NNP et_FW al._FW ,_, 1999_CD -RRB-_-RRB- for_IN English_NNP and_CC the_DT Potsdam_NNP Commentary_NNP Corpus_NNP -LRB-_-LRB- Stede_NNP ,_, 2004_CD -RRB-_-RRB- for_IN German_JJ ._.
However_RB ,_, when_WRB we_PRP trained_VBD two_CD -LRB-_-LRB- experienced_JJ -RRB-_-RRB- students_NNS to_TO annotate_VB the_DT 171_CD newspaper_NN commentaries_NNS of_IN the_DT Potsdam_NNP Commentary_NNP Corpus_NNP -LRB-_-LRB- Stede_NNP ,_, 2004_CD -RRB-_-RRB- and_CC upon_IN completion_NN of_IN the_DT task_NN asked_VBD them_PRP about_IN their_PRP$ experiences_NNS ,_, a_DT very_RB different_JJ picture_NN emerged_VBD ._.
Annotators_NNS have_VBP to_TO also_RB make_VB syntactic_JJ judgements_NNS ,_, which_WDT is_VBZ not_RB the_DT case_NN in_IN our_PRP$ approach_NN -LRB-_-LRB- where_WRB syntax_NN would_MD be_VB done_VBN on_IN a_DT different_JJ annotation_NN layer_NN ,_, see_VB -LRB-_-LRB- Stede_NNP ,_, 2004_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Discourse_NN structures_NNS can_MD not_RB always_RB be_VB described_VBN completely_RB ,_, either_CC because_IN they_PRP are_VBP ambiguous_JJ -LRB-_-LRB- Stede_JJ ,_, 2004_CD -RRB-_-RRB- ,_, or_CC because_IN a_DT discourse_NN parser_NN fails_VBZ to_TO analyse_VB them_PRP completely_RB ._.
For_IN the_DT purpose_NN of_IN language_NN engineering_NN and_CC linguistic_JJ investigation_NN ,_, we_PRP are_VBP constructing_VBG a_DT Chinese_JJ corpus_NN comparable_JJ to_TO the_DT English_NNP WSJRST_NN treebank_NN and_CC the_DT German_JJ Potsdam_NNP Commentary_NNP Corpus_NNP -LRB-_-LRB- Carlson_NNP et_FW al._FW 2003_CD ;_: Stede_NNP 2004_CD -RRB-_-RRB- ._.
Discourse_NN processing_NN has_VBZ emerged_VBN as_IN a_DT highly_RB relevant_JJ source_NN of_IN information_NN for_IN applications_NNS such_JJ as_IN information_NN extraction_NN and_CC automatic_JJ summarisation_NN -LRB-_-LRB- Taboada_NNP and_CC Mann_NNP -LRB-_-LRB- 2006_CD -RRB-_-RRB- outline_NN this_DT and_CC further_JJ applications_NNS -RRB-_-RRB- ._.
But_CC discourse_NN structures_NNS can_MD not_RB always_RB be_VB described_VBN completely_RB ,_, either_CC due_JJ to_TO genuine_JJ ambiguity_NN -LRB-_-LRB- Stede_NN ,_, 2004_CD -RRB-_-RRB- or_CC to_TO the_DT limitations_NNS of_IN a_DT discourse_NN parser_NN ._.
Following_VBG annotation_NN schemes_NNS like_IN the_DT one_CD of_IN Stede_NN -LRB-_-LRB- 2004_CD -RRB-_-RRB- ,_, we_PRP model_VBP discourse_NN structures_NNS by_IN binary_JJ trees_NNS ._.
Discourse_NN studies_NNS The_DT Potsdam_NNP Commentary_NNP Corpus_NNP ,_, PCC_NNP -LRB-_-LRB- Stede_NNP ,_, 2004_CD -RRB-_-RRB- ,_, consists_VBZ of_IN 173_CD newspaper_NN commentaries_NNS ,_, annotated_JJ for_IN morphosyn_NN -_: tax_NN ,_, coreference_NN ,_, discourse_NN structure_NN according_VBG to_TO Rhetorical_NNP Structure_NN Theory_NNP ,_, and_CC information_NN structure_NN ._.
The_DT original_JJ annotation_NN guidelines_NNS were_VBD drafted_VBN in_IN 2004_CD by_IN the_DT authors_NNS for_IN the_DT annotation_NN of_IN the_DT Potsdam_NNP Commentary_NNP Corpus_NNP of_IN German_JJ newspaper_NN commentaries_NNS -LRB-_-LRB- PCC_NN -RRB-_-RRB- -LRB-_-LRB- Stede_NNP ,_, 2004_CD -RRB-_-RRB- The_DT PCC176_NN -LRB-_-LRB- Stede_NN ,_, 2004_CD -RRB-_-RRB- is_VBZ a_DT sub-corpus_NN that_WDT is_VBZ available_JJ upon_IN request_NN for_IN research_NN purposes.It_NN consists_VBZ of_IN 176_CD relatively_RB short_JJ commentaries_NNS -LRB-_-LRB- 12_CD 15_CD sentences_NNS -RRB-_-RRB- ,_, with_IN 33.000_CD tokens_NNS in_IN total_NN ._.
-LRB-_-LRB- Manfred_NNP Stede_NNP ,_, Potsdam_NNP -RRB-_-RRB- Construction_NN of_IN the_DT Potsdam_NNP Commentary_NNP Corpus_NNP -LRB-_-LRB- PCC_NNP -RRB-_-RRB- began_VBD in_IN 2003_CD and_CC is_VBZ still_RB ongoing_JJ ._.
Another_DT well-known_JJ corpus_NN is_VBZ the_DT Potsdam_NNP Commentary_NNP Corpus_NNP ,_, for_IN German_JJ -LRB-_-LRB- Stede_JJ ,_, 2004_CD ;_: Reitter_NNP and_CC Stede_NNP ,_, 2003_CD -RRB-_-RRB- ._.
This_DT corpus_NN includes_VBZ 173_CD texts_NNS on_IN politics_NNS from_IN the_DT online_JJ newspaper_NN MÃ_NN $_$ rkische_JJ Allgemeine_NN Zeitung.It_NN contains_VBZ 32,962_CD words_NNS and_CC 2,195_CD sentences.It_NN is_VBZ annotated_JJ with_IN several_JJ data_NN For_IN discourse_NN relations_NNS annotated_JJ in_IN the_DT RST_NN framework_NN ,_, there_EX is_VBZ the_DT RST_NN Discourse_NN TreeBank_NN of_IN English_NNP text_NN -LRB-_-LRB- Carlson_NNP et_FW al._FW ,_, 2003_CD -RRB-_-RRB- ,_, available_JJ through_IN the_DT Linguistic_NNP Data_NNP Consortium_NNP -LRB-_-LRB- LDC_NNP -RRB-_-RRB- ,_, as_RB well_RB as_IN similarly_RB annotated_JJ corpora_NN in_IN Spanish_JJ -LRB-_-LRB- da_NN Cunha_NNP et_FW al._FW ,_, 2011_CD -RRB-_-RRB- ,_, Portugese_NN -LRB-_-LRB- Pardo_NNP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- and_CC German_JJ -LRB-_-LRB- Stede_JJ ,_, 2004_CD -RRB-_-RRB- ._.
We_PRP first_RB extracted_VBN opinionated_VBN and_CC objective_JJ texts_NNS from_IN DeReKo_NN corpus_NN -LRB-_-LRB- Stede_NN ,_, 2004_CD ;_: Kupietz_NNP Figure_NNP 4_CD For_IN discourse_NN relations_NNS and_CC DCs_NNS especially_RB ,_, more_JJR and_CC more_RBR annotated_JJ resources_NNS have_VBP become_VBN available_JJ in_IN several_JJ languages_NNS ,_, such_JJ as_IN English_NNP -LRB-_-LRB- Prasad_NNP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- ,_, French_JJ -LRB-_-LRB- PeÂ_NN '_'' ryWoodley_NN et_FW al._FW ,_, 2009_CD ;_: Danlos_NNP et_FW al._FW ,_, 2012_CD -RRB-_-RRB- ,_, German_JJ -LRB-_-LRB- Stede_JJ ,_, 2004_CD -RRB-_-RRB- We_PRP instantiate_VBP such_JJ relations_NNS instead_RB of_IN the_DT classical_JJ is-a_NN patterns_NNS since_IN these_DT have_VBP been_VBN shown_VBN to_TO bring_VB in_RP too_RB many_JJ false_JJ positives_NNS ,_, see_VBP -LRB-_-LRB- Pantel_NNP and_CC Pennacchiotti_NNP ,_, 2006_CD -RRB-_-RRB- for_IN a_DT discussion_NN of_IN such_JJ generic_JJ patterns_NNS ._.
Minimal_JJ supervision_NN is_VBZ used_VBN in_IN the_DT form_NN of_IN small_JJ sets_NNS of_IN manually_RB provided_VBN seed_NN patterns_NNS or_CC seed_NN instances_NNS ._.
This_DT approach_NN is_VBZ very_RB common_JJ in_IN both_CC the_DT NLP_NN and_CC Semantic_JJ Web_NN communities_NNS -LRB-_-LRB- Cimiano_NN and_CC Staab_NNP ,_, 2004_CD ;_: Cafarella_NNP et_FW al._FW ,_, 2005_CD ;_: Pantel_NNP and_CC Pennacchiotti_NNP ,_, 2006_CD ;_: Pasca_NNP et_FW al._FW ,_, 2006_CD -RRB-_-RRB- ._.
Typically_RB algorithms_NNS are_VBP compared_VBN using_VBG one_CD set_NN of_IN handpicked_VBN seeds_NNS for_IN each_DT category_NN -LRB-_-LRB- Pennacchiotti_NN and_CC Pantel_NN ,_, 2006_CD ;_: McIntosh_NNP and_CC Curran_NNP ,_, 2008_CD -RRB-_-RRB- ._.
A_DT third_JJ approach_NN has_VBZ been_VBN to_TO use_VB a_DT very_RB small_JJ number_NN of_IN seed_NN instances_NNS or_CC patterns_NNS to_TO do_VB bootstrap_JJ learning_NN -LRB-_-LRB- Brin_NN ,_, 1998_CD ;_: Riloff_NNP and_CC Jones_NNP ,_, 1999_CD ;_: Agichtein_NNP and_CC Gravano_NNP ,_, 2000_CD ;_: Ravichandran_NNP and_CC Hovy_NNP ,_, 2002_CD ;_: Etzioni_NNP et_FW al._FW ,_, 2005_CD ;_: Pennacchiotti_NNP and_CC Pantel_NNP ,_, 2006_CD ;_: Bunescu_NNP and_CC Mooney_NNP ,_, 2007_CD ;_: Rozenfeld_NNP and_CC Feldman_NNP ,_, 2008_CD -RRB-_-RRB- ._.
To_TO generalize_VB the_DT task_NN ,_, we_PRP first_RB determine_VB noun_NN phrases_NNS in_IN the_DT data_NNS following_VBG the_DT definition_NN in_IN -LRB-_-LRB- Pennacchiotti_NNP and_CC Pantel_NNP 2006_CD -RRB-_-RRB- ._.
In_IN a_DT completely_RB separate_JJ stream_NN of_IN work_NN ,_, Pantel_NNP and_CC Pennacchiotti_NNP investigated_VBD the_DT extraction_NN of_IN axioms_NNS from_IN the_DT text_NN using_VBG the_DT statistical_JJ text_NN harvesting_VBG paradigm_NN ._.
In_IN -LRB-_-LRB- Pennacchiotti_NNP and_CC Pantel_NNP ,_, 2006_CD ;_: Pantel_NNP and_CC Pennacchiotti_NNP ,_, 2006_CD -RRB-_-RRB- they_PRP report_VBP the_DT results_NNS ._.
Pennacchiotti_NNP and_CC Pantel_NNP -LSB-_-LRB- 32_CD -RSB-_-RRB- describes_VBZ a_DT system_NN called_VBN Espresso_NNP ._.
Pantel_NNP and_CC Pennacchiotti_NNP -LSB-_-LRB- 31_CD -RSB-_-RRB- extends_VBZ Espresso_NN by_IN treating_VBG patterns_NNS with_IN high_JJ recall_NN differently_RB from_IN patterns_NNS with_IN high_JJ precision_NN ._.
As_IN pointed_VBN out_RP by_IN Pennacchiotti_NNP and_CC Pantel_NNP -LSB-_-LRB- 6_CD -RSB-_-RRB- ,_, most_JJS ontology_JJ extraction_NN systems_NNS so_RB far_RB have_VBP focused_VBN on_IN generalised_JJ is-a_NN or_CC part-of_JJ relationships_NNS ._.
Hearsts_NNS method_NN has_VBZ since_IN then_RB been_VBN followed_VBN by_IN the_DT most_RBS successful_JJ systems_NNS ,_, such_JJ as_IN the_DT Espresso_NN system_NN proposed_VBN by_IN Pennacchiotti_NNP and_CC Pantel_NNP -LSB-_-LRB- 6_CD -RSB-_-RRB- ,_, based_VBN on_IN bootstrapping_NN ._.
Pennachiotti_NNP and_CC Pantel_NNP developed_VBD a_DT system_NN that_WDT extracts_VBZ the_DT relations_NNS such_JJ as_IN is-a_NN ,_, part-of_NN ,_, and_CC succession_NN from_IN the_DT Trec9_NN corpus_NN and_CC is-a_NN ,_, part-of_NN ,_, production_NN ,_, and_CC reaction_NN from_IN a_DT chemistry_NN corpus_NN -LRB-_-LRB- Pennacchiotti_NNP &_CC Pantel_NNP 2006_CD -RRB-_-RRB- ._.
We_PRP use_VBP Boxer_NNP semantic_JJ analyzer_NN -LRB-_-LRB- Bos_NNS ,_, 2008_CD -RRB-_-RRB- to_TO extract_VB semantic_JJ predicates_NNS such_JJ as_IN EVENT_NN or_CC DATE_NN ._.
This_DT means_VBZ that_IN it_PRP is_VBZ relatively_RB straightforward_JJ to_TO deterministically_RB map_VB parser_NN output_NN to_TO a_DT logical_JJ form_NN ,_, as_IN in_IN the_DT Boxer_NNP system_NN -LRB-_-LRB- Bos_NNS ,_, 2008_CD -RRB-_-RRB- ._.
In_IN this_DT paper_NN we_PRP present_VBP and_CC evaluate_VBP a_DT system_NN that_WDT transforms_VBZ texts_NNS into_IN logical_JJ formulas_NNS â_VBP $_$ ``_`` using_VBG the_DT C&C_NN tools_NNS and_CC Boxer_NNP -LRB-_-LRB- Bos_NNP ,_, 2008_CD -RRB-_-RRB- â_RB $_$ ``_`` in_IN the_DT context_NN of_IN the_DT shared_JJ task_NN on_IN recognising_VBG negation_NN in_IN English_NNP texts_NNS -LRB-_-LRB- Morante_NNP and_CC Blanco_NNP ,_, 2012_CD -RRB-_-RRB- ._.
Wide-coverage_JJ logic-based_JJ semantics_NNS Boxer_NNP -LRB-_-LRB- Bos_NNP ,_, 2008_CD -RRB-_-RRB- is_VBZ a_DT software_NN package_NN for_IN wide-coverage_JJ semantic_JJ analysis_NN that_IN produces_VBZ logical_JJ forms_NNS using_VBG Discourse_NNP Representation_NNP Structures_NNS -LRB-_-LRB- Kamp_NNP and_CC Reyle_NNP ,_, 1993_CD -RRB-_-RRB- ._.
For_IN the_DT discursive_JJ analysis_NN of_IN texts_NNS ,_, DR_NN metrics_NNS rely_VBP on_IN the_DT C&C_NNP Tools_NNP -LRB-_-LRB- Curran_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ,_, specifically_RB on_IN the_DT Boxer_NNP component_NN -LRB-_-LRB- Bos_NNS ,_, 2008_CD -RRB-_-RRB- ._.
Computing_NNP logical_JJ forms_NNS -LRB-_-LRB- as_RB ,_, e.g._FW ,_, in_IN Bos_NNS -LRB-_-LRB- 2008_CD -RRB-_-RRB- -RRB-_-RRB- and_CC then_RB deriving_VBG logically_RB formulated_VBN rules_NNS from_IN these_DT rather_RB than_IN deriving_VBG sentential_JJ forms_NNS directly_RB from_IN text_NN should_MD also_RB allow_VB us_PRP to_TO be_VB more_RBR precise_JJ about_IN dropping_VBG modifiers_NNS ,_, reshaping_VBG into_IN generic_JJ present_JJ tense_JJ from_IN other_JJ tenses_NNS ,_, and_CC other_JJ issues_NNS that_WDT affect_VBP the_DT quality_NN of_IN the_DT statements_NNS ._.
This_DT line_NN of_IN research_NN converts_NNS logical_JJ representations_NNS obtained_VBN from_IN syntactic_NN parses_VBZ using_VBG Bosâ_NNP $_$ ™_CD Boxer_NNP -LRB-_-LRB- Bos_NNP ,_, 2008_CD -RRB-_-RRB- GigaPairs_NNP has_VBZ been_VBN derived_VBN from_IN Gigaword_NNP using_VBG the_DT pairwise_JJ similarity_NN method_NN on_IN headlines_NNS presented_VBN by_IN Wubben_NNP et_FW al._FW -LRB-_-LRB- 2009_CD -RRB-_-RRB- Similarly_RB to_TO previous_JJ work_NN -LRB-_-LRB- Dolan_NNP et_FW al._FW ,_, 2004_CD ;_: Wubben_NNP et_FW al._FW ,_, 2009_CD ;_: Bejan_NNP &_CC Harabagiu_NNP ,_, 2010_CD ,_, inter_NN alia_NN -RRB-_-RRB- ,_, the_DT Google_NNP News_NNP service3_NN was_VBD used_VBN to_TO identify_VB news_NN ._.
Wubben_NNP et_FW al._FW have_VBP compared_VBN Clustering_NN against_IN pairwise_JJ matching_NN for_IN extracting_VBG paraphrases_NNS from_IN news_NN corpora_NN -LSB-_-LRB- 9_CD -RSB-_-RRB- ._.
The_DT obtained_VBN results_NNS have_VBP been_VBN compared_VBN with_IN that_DT of_IN the_DT Paraphrase_NNP Acquisition_NNP system_NN developed_VBN by_IN Wubben_NNP et_FW al._FW -LSB-_-LRB- 9_CD -RSB-_-RRB- ._.
Besides_IN Wubben_NNP et_FW al._FW s_NNS systems_NNS ,_, a_DT Fuzzy_JJ C-Means_NN -LRB-_-LRB- FCM_NN -RRB-_-RRB- clustering_NN approach_NN has_VBZ also_RB been_VBN adopted_VBN ._.
Wubben_NNP et_FW al._FW have_VBP attempted_VBN k-means_NNS clustering_NN ,_, while_IN the_DT proposed_JJ system_NN uses_VBZ fuzzy_JJ clustering_NN ._.
However_RB ,_, the_DT proposed_JJ system_NN performs_VBZ better_JJR than_IN Wubben_NNP et_FW al._FW s_NNS approaches_VBZ as_RB well_RB as_IN FCM_NNP Clustering_NNP for_IN Paraphrase_NNP Extraction_NNP ._.
The_DT proposed_JJ system_NN ,_, the_DT existing_VBG systems_NNS -LRB-_-LRB- Wubben_NNP et_FW al._FW -RRB-_-RRB- and_CC FCM_NNP Clustering_VBG approach_NN were_VBD tested_VBN on_IN this_DT dataset_NN ._.
Approach_NN Accuracy_NNP %_NN Precision_NN %_NN Recall_VB %_NN F-Measure_NN %_NN Fernando_NNP et_FW al._FW -LRB-_-LRB- 2008_CD -RRB-_-RRB- -LSB-_-LRB- 40_CD -RSB-_-RRB- 74.1_CD 75.2_CD 91.3_CD 82.4_CD Mihalcea_NNP et_FW al._FW -LRB-_-LRB- 2006_CD -RRB-_-RRB- -LSB-_-LRB- 41_CD -RSB-_-RRB- 70.3_CD 69.6_CD 97.7_CD 81.3_CD Proposed_VBN system_NN variant_JJ WSD_NN ,_, threshold_NN =_JJ 0.2_CD ,_, top_JJ 50_CD %_NN 66.4_CD 81.0_CD 65.2_CD 72.3_CD Cosine_NNP similarity_NN ,_, threshold_NN =_JJ 0.7_CD -LRB-_-LRB- Wubben_NNP et_FW al._FW -LSB-_-LRB- 9_CD -RSB-_-RRB- -RRB-_-RRB- 62.5_CD 80.5_CD 56.6_CD 66.5_CD k-Means_NNS clustering_NN -LRB-_-LRB- Wubben_NNP et_FW al._FW -LSB-_-LRB- 9_CD -RSB-_-RRB- -RRB-_-RRB- 60.6_CD 70.6_CD 71.0_CD 70.8_CD FCM_NN clustering_NN 36.2_CD 68.1_CD 9.5_CD 16.7_CD Table_NNP 6_CD Performance_NNP of_IN proposed_JJ system_NN on_IN MSRVDC_NNP Dataset_NNP 1_CD ._.
This_DT method_NN ,_, described_VBN in_IN earlier_JJR work_NN Wubben_NNP et_FW al._FW -LRB-_-LRB- 2009_CD -RRB-_-RRB- ,_, was_VBD reported_VBN to_TO yield_VB a_DT precision_NN of_IN 0.76_CD and_CC a_DT recall_NN of_IN 0.41_CD on_IN clustering_NN actual_JJ Dutch_JJ paraphrases_NNS in_IN a_DT headline_NN corpus_NN ._.
So-called_JJ comparable_JJ monolingual_JJ corpora_NN ,_, for_IN instance_NN independently_RB written_VBN news_NN reports_NNS describing_VBG the_DT same_JJ event_NN ,_, in_IN which_WDT some_DT pairs_NNS of_IN sentences_NNS exhibit_VBP partial_JJ semantic_JJ overlap_VBP have_VBP also_RB been_VBN investigated_VBN -LRB-_-LRB- Shinyama_NNP et_FW al._FW ,_, 2002_CD ;_: Barzilay_NNP and_CC Lee_NNP ,_, 2003_CD ;_: Shen_NNP et_FW al._FW ,_, 2006_CD ;_: Wubben_NNP et_FW al._FW ,_, 2009_CD -RRB-_-RRB- The_DT first_JJ manually_RB collected_VBN paraphrase_NN corpus_NN is_VBZ the_DT Microsoft_NNP Research_NNP Paraphrase_NNP -LRB-_-LRB- MSRP_NNP -RRB-_-RRB- Corpus_NNP -LRB-_-LRB- Dolan_NNP et_FW al._FW ,_, 2004_CD -RRB-_-RRB- ,_, consisting_VBG of_IN 5,801_CD sentence_NN pairs_NNS ,_, sampled_VBN from_IN a_DT larger_JJR corpus_NN of_IN news_NN articles_NNS ._.
To_TO investigate_VB the_DT effect_NN of_IN the_DT amount_NN of_IN training_NN data_NNS on_IN results_NNS ,_, we_PRP also_RB train_VBP a_DT phrase-based_JJ model_NN on_IN more_JJR data_NNS by_IN adding_VBG more_RBR aligned_VBN headlines_NNS originating_VBG from_IN data_NNS crawled_VBD in_IN 2010_CD and_CC aligned_VBN using_VBG -LRB-_-LRB- i_FW i_FW =_JJ LD_NN -LRB-_-LRB- 1_CD ._.
.8_NN -RRB-_-RRB- Ni_NN N_NN I_PRP STi_VBP -RRB-_-RRB- tf.idf_JJ scores_NNS over_IN headline_NN clusters_NNS and_CC Cosine_NNP sim_VBP ilarity_NN as_IN described_VBN in_IN -LRB-_-LRB- Wubben_JJ et_FW al._FW ,_, 2009_CD -RRB-_-RRB- ,_, resulting_VBG in_IN an_DT extra_JJ 612,158_CD aligned_VBN headlines_NNS ._.
The_DT task_NN of_IN identifying_VBG MWEs_NNS is_VBZ relevant_JJ not_RB only_RB to_TO lexical_JJ semantics_NNS applications_NNS ,_, but_CC also_RB machine_NN translation_NN -LRB-_-LRB- Koehn_NNP et_FW al._FW ,_, 2003_CD ;_: Ren_NNP et_FW al._FW ,_, 2009_CD ;_: Pal_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- ,_, information_NN retrieval_NN -LRB-_-LRB- Xu_NN et_FW al._FW ,_, 2010_CD ;_: Acosta_NNP et_FW al._FW ,_, 2011_CD -RRB-_-RRB- ,_, and_CC syntactic_NN parsing_NN -LRB-_-LRB- Sag_NN et_FW al._FW ,_, 2002_CD -RRB-_-RRB- ._.
Joining_VBG the_DT words_NNS of_IN MWEs_NNS before_IN indexation_NN is_VBZ a_DT simple_JJ idea_NN that_WDT was_VBD put_VBN in_IN practice_NN by_IN Acosta_NNP et_FW al._FW ._.
Our_PRP$ research_NN in_IN compositionality_NN is_VBZ motivated_VBN by_IN the_DT hypothesis_NN that_IN a_DT special_JJ treatment_NN of_IN se_FW mantically_FW non-compositional_JJ expressions_NNS can_MD im_VB prove_VB results_NNS in_IN various_JJ Natural_JJ Language_NN Process_VB ing_NN -LRB-_-LRB- NPL_NN -RRB-_-RRB- tasks_NNS ,_, as_IN shown_VBN for_IN example_NN by_IN Acosta_NNP et_FW al._FW ._.
As_IN an_DT example_NN ,_, Carpuat_NN and_CC Diab_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- proposed_VBD two_CD strategies_NNS for_IN integrating_VBG MWEs_NNS into_IN statisti_NNS cal_JJ machine_NN translation_NN ._.
Investigating_VBG the_DT degree_NN of_IN MWE_NNP compositionality_NN has_VBZ been_VBN shown_VBN to_TO have_VB applications_NNS in_IN information_NN retrieval_NN and_CC machine_NN translation_NN -LRB-_-LRB- Acosta_NNP et_FW al._FW ,_, 2011_CD ;_: Venkatapathy_NNP and_CC Joshi_NNP ,_, 2006_CD -RRB-_-RRB- ._.
Information_NNP retrieval_NN Our_PRP$ research_NN in_IN compositionality_NN is_VBZ motivated_VBN by_IN the_DT hypothesis_NN that_IN a_DT special_JJ treatment_NN of_IN semantically_RB non-compositional_JJ expressions_NNS can_MD improve_VB results_NNS in_IN various_JJ Natural_JJ Language_NN Processing_NN -LRB-_-LRB- NPL_NN -RRB-_-RRB- tasks_NNS ,_, as_IN shown_VBN for_IN example_NN by_IN Acosta_NNP et_FW al._FW ._.
-LRB-_-LRB- 2002_CD -RRB-_-RRB- ,_, Baldwin_NNP and_CC Kim_NNP -LRB-_-LRB- 2009_CD -RRB-_-RRB- -RRB-_-RRB- has_VBZ been_VBN shown_VBN to_TO be_VB useful_JJ in_IN various_JJ NLP_NN applications_NNS -LRB-_-LRB- Ramisch_NNP ,_, 2012_CD -RRB-_-RRB- ,_, recent_JJ work_NN has_VBZ shown_VBN that_IN automatic_JJ prediction_NN of_IN the_DT degree_NN of_IN compositionality_NN of_IN MWEs_NNS also_RB has_VBZ utility_NN ,_, in_IN applications_NNS including_VBG information_NN retrieval_NN -LRB-_-LRB- IR_NNP Golding_NNP -LRB-_-LRB- 1995_CD -RRB-_-RRB- showed_VBD how_WRB methods_NNS used_VBN for_IN WSD_NN -LRB-_-LRB- decision_NN lists_NNS and_CC Bayesian_JJ classifiers_NNS -RRB-_-RRB- could_MD be_VB adapted_VBN to_TO detect_VB errors_NNS resulting_VBG from_IN common_JJ spelling_NN confusions_NNS among_IN sets_NNS such_JJ as_IN there_RB ,_, their_PRP$ ,_, and_CC they_PRP 're_VBP ._.
A_DT number_NN of_IN feature-based_JJ methods_NNS have_VBP been_VBN tried_VBN ,_, including_VBG Bayesian_JJ classifiers_NNS -LRB-_-LRB- Gale_NNP ,_, Church_NNP ,_, and_CC Yarowsky_NNP ,_, 1992_CD ;_: Golding_NNP ,_, 1995_CD -RRB-_-RRB- ,_, decision_NN lists_NNS -LRB-_-LRB- Yarowsky_NNP ,_, 1994_CD -RRB-_-RRB- ,_, and_CC knowledge-based_JJ approaches_NNS -LRB-_-LRB- McRoy_NN ,_, 1992_CD -RRB-_-RRB- ._.
We_PRP have_VBP also_RB selected_VBN a_DT decision_NN list_NN classifier_NN -LRB-_-LRB- DL_NN -RRB-_-RRB- which_WDT is_VBZ similar_JJ to_TO the_DT classifier_NN used_VBN by_IN -LRB-_-LRB- Yarowsky_NNP ,_, 1994_CD -RRB-_-RRB- for_IN words_NNS having_VBG two_CD senses_NNS ,_, and_CC extended_VBN for_IN more_JJR senses_NNS by_IN -LRB-_-LRB- Golding_NNP ,_, 1995_CD -RRB-_-RRB- ._.
Golding_NNP -LRB-_-LRB- 1995_CD -RRB-_-RRB- builds_VBZ a_DT classifier_NN based_VBN on_IN a_DT rich_JJ set_NN of_IN context_NN features_NNS ._.
A_DT variety_NN of_IN machine-learning_JJ methods_NNS have_VBP been_VBN proposed_VBN in_IN spelling_NN correction_NN and_CC preposition_NN and_CC article_NN error_NN correction_NN fields_NNS ,_, such_JJ as_IN Bayesian_JJ classifiers_NNS -LRB-_-LRB- Golding_NNP ,_, 1995_CD ;_: Golding_NNP and_CC Roth_NNP ,_, 1996_CD -RRB-_-RRB- ,_, Winnow-based_JJ learning_NN -LRB-_-LRB- Golding_NN and_CC Roth_NNP ,_, 1999_CD -RRB-_-RRB- ,_, decision_NN lists_NNS -LRB-_-LRB- Golding_NNP ,_, 1995_CD -RRB-_-RRB- Take_VB the_DT case_NN of_IN context-sensitive_JJ spelling_NN error_NN detection_NN 3_CD ,_, which_WDT is_VBZ equivalent_JJ to_TO the_DT homophone_NN problem.For_NN that_WDT problem_NN ,_, some_DT statistical_JJ methods_NNS have_VBP been_VBN applied_VBN and_CC succeeded_VBN -LRB-_-LRB- Golding_NNP ,_, 1995_CD ;_: GoldÂ_NNP ing_NN and_CC Schabes_NNS ,_, 1996_CD -RRB-_-RRB- ._.
The_DT more_JJR recent_JJ set_NN of_IN techniques_NNS includes_VBZ multiplicative_JJ weight-update_JJ algorithms_NNS -LSB-_-LRB- 4_CD -RSB-_-RRB- ,_, latent_JJ semantic_JJ analysis_NN -LSB-_-LRB- 7_CD -RSB-_-RRB- ,_, transformation-based_JJ learning_NN -LSB-_-LRB- 8_CD -RSB-_-RRB- ,_, differential_JJ grammars_NNS -LSB-_-LRB- 10_CD -RSB-_-RRB- ,_, decision_NN lists_NNS -LSB-_-LRB- 12_CD -RSB-_-RRB- ,_, and_CC a_DT variety_NN of_IN Bayesian_JJ classifiers_NNS -LSB-_-LRB- 2,3,5_CD -RSB-_-RRB- ._.
In_IN all_DT of_IN these_DT papers_NNS ,_, the_DT problem_NN is_VBZ formulated_VBN as_IN follows_VBZ For_IN each_DT si_FW ,_, the_DT probability_NN is_VBZ computed_VBN with_IN Bayes_NNS '_POS rule_NN Golding_NN -LSB-_-LRB- 3_CD -RSB-_-RRB- proposed_VBD a_DT Bayesian_JJ hybrid_NN method_NN to_TO take_VB into_IN account_NN all_DT available_JJ evidence_NN ,_, instead_RB of_IN only_RB the_DT strongest_JJS one.The_NN method_NN was_VBD applied_VBN to_TO the_DT task_NN of_IN context-sentitive_JJ spelling_NN correction_NN and_CC was_VBD reported_VBN to_TO be_VB superior_JJ to_TO decision_NN lists_NNS ._.
Hybrid_NN approach_NN -LSB-_-LRB- 3_CD ,_, 12_CD -RSB-_-RRB- combines_VBZ the_DT strengths_NNS of_IN other_JJ techniques_NNS such_JJ as_IN Bayesian_JJ classifier_NN ,_, n-gram_NN ,_, and_CC decision_NN list_NN ._.
In_IN the_DT experiment_NN ,_, we_PRP classify_VBP the_DT data_NNS into_IN three_CD group_NN depending_VBG on_IN types_NNS of_IN text_NN ambiguity_NN according_VBG to_TO section_NN 2_CD These_DT include_VBP a_DT variety_NN of_IN Bayesian_JJ classifi_NNS ers_NNPS -LRB-_-LRB- Golding_NNP ,_, 1995_CD ;_: Golding_NNP and_CC Schabes_NNP ,_, 1996_CD -RRB-_-RRB- ,_, decision_NN lists_NNS -LRB-_-LRB- Golding_NNP ,_, 1995_CD -RRB-_-RRB- transformation-based_JJ learning_NN -LRB-_-LRB- Mangu_NN and_CC Brill_NNP ,_, 1997_CD -RRB-_-RRB- ,_, Latent_JJ Semantic_NNP Analysis_NN -LRB-_-LRB- LSA_NN -RRB-_-RRB- -LRB-_-LRB- Jones_NNP and_CC Martin_NNP ,_, 1997_CD -RRB-_-RRB- ,_, multiplicative_JJ weight_NN update_VBP algorithms_NNS -LRB-_-LRB- Golding_NN and_CC Roth_NNP ,_, 1999_CD -RRB-_-RRB- ,_, and_CC augmented_VBD mixture_NN models_NNS -LRB-_-LRB- Cucerzan_NN and_CC Yarowsky_NNP ,_, 2002_CD -RRB-_-RRB- ._.
Despite_IN their_PRP$ differences_NNS ,_, most_JJS approaches_NNS use_VBP two_CD types_NNS of_IN features_NNS A_DT comparison_NN with_IN the_DT literature_NN shows_VBZ that_IN the_DT best_JJS Altavista_NNP model_NN outperforms_VBZ Golding_NNP -LRB-_-LRB- 1995_CD -RRB-_-RRB- ,_, Jones_NNP and_CC Martin_NNP -LRB-_-LRB- 1997_CD -RRB-_-RRB- highest_JJS accuracy_NN on_IN the_DT task_NN is_VBZ achieved_VBN by_IN the_DT class_NN of_IN multiplicative_JJ weight-update_JJ algorithms_NNS such_JJ as_IN Winnow_NNP -LRB-_-LRB- Golding_NNP and_CC Roth_NNP ,_, 1999_CD -RRB-_-RRB- ._.
The_DT majority_NN of_IN the_DT data-driven_JJ methods_NNS use_VBP a_DT classification_NN technique_NN to_TO determine_VB whether_IN a_DT word_NN is_VBZ used_VBN appropriately_RB in_IN its_PRP$ context_NN ,_, continuing_VBG the_DT tradition_NN established_VBN for_IN contextual_JJ spelling_NN correction_NN by_IN Golding_NNP -LRB-_-LRB- 1995_CD -RRB-_-RRB- and_CC Golding_NNP and_CC Roth_NNP -LRB-_-LRB- 1996_CD -RRB-_-RRB- ._.
The_DT more_JJR recent_JJ set_NN of_IN techniques_NNS includes_VBZ mult_JJ iplicative_JJ weight_NN -_: update_VB algorithms_NNS -LRB-_-LRB- Golding_NN and_CC Roth_NNP ,_, 1998_CD -RRB-_-RRB- ,_, latent_JJ semantic_JJ analysis_NN -LRB-_-LRB- Jones_NNP and_CC Martin_NNP ,_, 1997_CD -RRB-_-RRB- ,_, transformation_NN -_: based_VBN learning_NN -LRB-_-LRB- Mangu_NN and_CC Brill_NNP ,_, 1997_CD -RRB-_-RRB- ,_, differential_JJ grammars_NNS -LRB-_-LRB- Powers_NNP ,_, 1997_CD -RRB-_-RRB- ,_, decision_NN lists_NNS -LRB-_-LRB- Yarowsky_NNP ,_, 1994_CD -RRB-_-RRB- ,_, and_CC a_DT variety_NN of_IN Bayesian_JJ classifiers_NNS -LRB-_-LRB- Gale_NNP et_FW al._FW ,_, 1993_CD ,_, Golding_NNP ,_, 1995_CD ,_, Golding_NNP and_CC Schabes_NNP ,_, 1996_CD -RRB-_-RRB- ._.
In_IN all_DT of_IN these_DT approaches_NNS ,_, the_DT problem_NN is_VBZ formulated_VBN as_IN follows_VBZ Feature-based_JJ approaches_NNS ,_, such_JJ as_IN Bayesian_JJ clasÂ_NN sifiers_NNS -LRB-_-LRB- Gale_NNP ,_, Church_NNP ,_, and_CC Yarowsky_NNP ,_, 1993_CD -RRB-_-RRB- ,_, deciÂ_NN sion_NN lists_NNS -LRB-_-LRB- Yarowsky_NNP ,_, 1994_CD -RRB-_-RRB- ,_, and_CC Bayesian_JJ hybrids_NNS -LRB-_-LRB- Golding_NNP ,_, 1995_CD -RRB-_-RRB- ,_, have_VBP had_VBN varying_VBG degrees_NNS of_IN sucÂ_NN cess_NN for_IN the_DT problem_NN of_IN context-sensitive_JJ spelling_NN correction_NN ._.
A_DT number_NN of_IN feature-based_JJ methods_NNS have_VBP been_VBN proposed_VBN ,_, including_VBG Bayesian_JJ classifiers_NNS -LRB-_-LRB- Gale_NNP ,_, Church_NNP ,_, and_CC Yarowsky_NNP ,_, 1993_CD -RRB-_-RRB- ,_, decision_NN lists_NNS -LRB-_-LRB- Yarowsky_NNP ,_, 1994_CD -RRB-_-RRB- ,_, Bayesian_JJ hybrids_NNS -LRB-_-LRB- Golding_NNP ,_, 1995_CD -RRB-_-RRB- ,_, and_CC ,_, more_RBR recently_RB ,_, a_DT method_NN based_VBN on_IN the_DT Winnow_NNP multiplicative_JJ weight-updating_JJ algorithm_NN -LRB-_-LRB- Golding_NN and_CC Roth_NNP ,_, 1996_CD -RRB-_-RRB- ._.
We_PRP adopt_VBP the_DT Bayesian_JJ hybrid_NN methodThis_NN method_NN has_VBZ been_VBN described_VBN elsewhere_RB -LRB-_-LRB- Golding_NNP ,_, 1995_CD -RRB-_-RRB- Following_VBG previous_JJ works_NNS -LRB-_-LRB- Golding_NNP ,_, 1995_CD ;_: Meknavin_NNP et_FW al._FW ,_, 1997_CD -RRB-_-RRB- ,_, we_PRP have_VBP tried_VBN two_CD types_NNS of_IN features_NNS This_DT general_JJ scheme_NN has_VBZ been_VBN used_VBN to_TO deÂ_VB rive_JJ classifiers_NNS for_IN a_DT variety_NN of_IN natural_JJ lanÂ_NN guage_NN applications_NNS including_VBG speech_NN applicaÂ_NN tions_NNS -LRB-_-LRB- Rab89_NN -RRB-_-RRB- ,_, pos_NN tagging_NN -LRB-_-LRB- Kup92_NN ;_: Sch95_NN -RRB-_-RRB- ,_, word-sense_JJ ambiguation_NN -LRB-_-LRB- GCY93_NN -RRB-_-RRB- and_CC contextÂ_NN sensitive_JJ spelling_NN correction_NN -LRB-_-LRB- Gol95_NN -RRB-_-RRB- ._.
A_DT partial_JJ list_NN consists_VBZ of_IN Bayesian_JJ classifiers_NNS -LRB-_-LRB- Gale_NNP et_FW al._FW ,_, 1993_CD -RRB-_-RRB- ,_, decision_NN lists_NNS -LRB-_-LRB- Yarowsky_NNP ,_, 1994_CD -RRB-_-RRB- ,_, Bayesian_JJ hybrids_NNS -LRB-_-LRB- Golding_NNP ,_, 1995_CD -RRB-_-RRB- Previous_JJ work_NN has_VBZ addressed_VBN the_DT problem_NN of_IN CSSC_NNP from_IN a_DT machine_NN learning_VBG perspective_NN ,_, including_VBG Bayesian_JJ and_CC Decision_NN List_NN models_NNS -LRB-_-LRB- Golding_NNP ,_, 1995_CD -RRB-_-RRB- We_PRP use_VBP the_DT metric_JJ described_VBN in_IN -LRB-_-LRB- Yarowsky_NNP ,_, 1994_CD ;_: Golding_NNP ,_, 1995_CD -RRB-_-RRB- ._.
There_EX are_VBP also_RB other_JJ studies_NNS -LRB-_-LRB- Yarowsky_NNP ,_, 1994_CD ;_: Golding_NNP ,_, 1995_CD or_CC Golding_NNP and_CC Roth_NNP ,_, 1996_CD -RRB-_-RRB- that_WDT report_VBP the_DT application_NN of_IN decision_NN lists_NNS and_CC Bayesian_JJ classifiers_NNS for_IN spell_NN checking_NN ;_: however_RB ,_, these_DT models_NNS can_MD not_RB be_VB applied_VBN to_TO grammar_NN error_NN detection_NN ._.
Golding_VBG -LSB-_-LRB- 1995_CD -RSB-_-RRB- has_VBZ applied_VBN a_DT hybrid_NN Bayesian_JJ method_NN for_IN real-word_JJ error_NN correction_NN and_CC Golding_NNP and_CC Schabes_NNP -LSB-_-LRB- 1996_CD -RSB-_-RRB- have_VBP combined_VBN a_DT POS_NN trigram_NN and_CC Bayesian_JJ methods_NNS for_IN the_DT same_JJ purpose_NN ._.
As_IN a_DT result_NN ,_, quantitative_JJ evaluation_NN is_VBZ now_RB commonplace_JJ in_IN areas_NNS of_IN language_NN engineering_NN such_JJ as_IN parsing_NN ,_, and_CC quantitative_JJ evaluation_NN techniques_NNS are_VBP being_VBG proposed_VBN for_IN semantic_JJ interpretation_NN as_RB well_RB ,_, for_IN example_NN ,_, at_IN the_DT Sixth_NNP and_CC Seventh_NNP Message_NNP Understa_NNP nd_NN ing_NN Conferences_NNS -LRB-_-LRB- MUC6_NN and_CC MUC7_NN -RRB-_-RRB- -LRB-_-LRB- Sundheim_NNP 1995_CD ;_: Chinchor_NNP 1997_CD -RRB-_-RRB- ,_, which_WDT also_RB included_VBD evaluations_NNS of_IN systems_NNS on_IN the_DT so-called_JJ coreference_NN task_NN ,_, a_DT subtask_NN of_IN which_WDT is_VBZ the_DT resolution_NN of_IN definite_JJ descriptions_NNS ._.
Algorit_NNP hmThis_NNP algorithm_NN was_VBD first_JJ implemented_VBN for_IN the_DT MUC_NN 6_CD FASTUS_NN system_NN -LRB-_-LRB- Appelt_NN et_FW al._FW ,_, 1995_CD -RRB-_-RRB- ,_, and_CC prod.uced_VBD one_CD of_IN the_DT top_JJ scores_NNS -LRB-_-LRB- a_DT recall_NN of_IN 59_CD %_NN and_CC precision_NN of_IN 72_CD %_NN -RRB-_-RRB- in_IN the_DT MUC6_NN Coreference_NN Task_NNP ,_, which_WDT evaluated_VBD systems_NNS '_POS ability_NN to_TO recog_NN nize_NN coreference_NN among_IN noun_NN phrases_NNS -LRB-_-LRB- Sund_NNP heim_NN ,_, 1995_CD -RRB-_-RRB- ._.
The_DT MUC_NNP organisers_NNS provided_VBD strict_JJ guidelines_NNS about_IN what_WP constituted_VBD a_DT succession_NN event_NN and_CC how_WRB the_DT templates_NNS should_MD be_VB ._.
lled_VBD which_WDT the_DT annotators_NNS sometimes_RB found_VBD di.cult_NN to_TO interpret_VB -LRB-_-LRB- Sundheim_NNP ,_, 1995_CD -RRB-_-RRB- ._.
Interannotator_NNP agreement_NN was_VBD measured_VBN on_IN 30_CD texts_NNS which_WDT were_VBD examined_VBN by_IN two_CD annotators.It_NN was_VBD found_VBN to_TO be_VB 83_CD %_NN when_WRB one_CD annotator_NN 's_POS templates_NNS were_VBD assumed_VBN to_TO be_VB correct_JJ and_CC compared_VBN with_IN the_DT other_JJ ._.
In_IN an_DT article_NN on_IN the_DT Named_VBN Entity_NN recognition_NN competition_NN -LRB-_-LRB- part_NN of_IN MUC6_NN -RRB-_-RRB- Sundheim_NN -LRB-_-LRB- 1995_CD -RRB-_-RRB- remarks_NNS that_IN ``_`` common_JJ organization_NN names_NNS ,_, first_RB names_NNS of_IN people_NNS and_CC location_NN names_NNS can_MD be_VB handled_VBN by_IN recourse_NN to_TO list_NN lookup_NN ,_, although_IN there_EX are_VBP drawbacks_NNS ''_'' -LRB-_-LRB- Sundheim_NNP 1995_CD
