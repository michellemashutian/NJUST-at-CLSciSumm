It_PRP is_VBZ faster_RBR because_IN the_DT search_NN problem_NN for_IN noisy_JJ -_: channel_NN models_NNS is_VBZ NP-complete_JJ -LRB-_-LRB- Knight_NNP ,_, 1999_CD -RRB-_-RRB- ,_, and_CC even_RB the_DT fastest_JJS dynamic-programming_JJ heuristics_NNS used_VBN in_IN statistical_JJ MT_NN -LRB-_-LRB- Niessen_NNP et_FW al._FW ,_, 1998_CD ;_: Till_IN -_: mann_NN and_CC Ney_NN ,_, 2000_CD -RRB-_-RRB- ,_, are_VBP polynomial_JJ in_IN J_NN --_: for_IN in_IN p_NN -LRB-_-LRB- v1_NN ,_, w2_NN ,_, wm_NN −_NN 1_CD ,_, um_NN h_NN ,_, s_NNS -RRB-_-RRB- =_JJ stance_NN O_NN -LRB-_-LRB- mJ_NN 4V_NN 3_CD -RRB-_-RRB- in_IN -LRB-_-LRB- Tillmann_NNP and_CC Ney_NNP ,_, 2000_CD -RRB-_-RRB- ._.
Various_JJ clues_NNS have_VBP been_VBN considered_VBN when_WRB computing_VBG the_DT similarities_NNS The_DT other_JJ is_VBZ multilingual_JJ parallel_NN and_CC comparable_JJ corpora_NN -LRB-_-LRB- e.g._FW ,_, Wikipedia1_NN -RRB-_-RRB- ,_, wherein_WRB features_NNS such_JJ as_IN co_NN -_: occurrence_NN frequency_NN and_CC context_NN are_VBP popularly_RB employed_VBN -LRB-_-LRB- Cheng_NNP et_FW al._FW ,_, 2004_CD ;_: Shao_NNP and_CC Ng_NNP ,_, 2004_CD ;_: Cao_NNP et_FW al._FW ,_, 2007_CD ;_: Lin_NNP et_FW al._FW ,_, 2008_CD -RRB-_-RRB- ._.
Shao_NNP and_CC Ng_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- presented_VBD a_DT method_NN to_TO mine_VB new_JJ translations_NNS from_IN Chinese_JJ and_CC English_JJ news_NN documents_NNS of_IN the_DT same_JJ period_NN from_IN different_JJ news_NN agencies_NNS ,_, combining_VBG both_CC transliteration_NN and_CC context_NN information_NN ._.
Much_JJ of_IN the_DT work_NN involving_VBG comparable_JJ corpora_NN has_VBZ focused_VBN on_IN extracting_VBG word_NN translations_NNS -LRB-_-LRB- Fung_NNP and_CC Yee_NNP ,_, 1998_CD ;_: Rapp_NNP ,_, 1999_CD ;_: Diab_NNP and_CC Finch_NNP ,_, 2000_CD ;_: Koehn_NNP and_CC Knight_NNP ,_, 2000_CD ;_: Gaussier_NNP et_FW al._FW ,_, 2004_CD ;_: Shao_NNP and_CC Ng_NNP ,_, 2004_CD ;_: Shinyama_NNP and_CC Sekine_NNP ,_, 2004_CD -RRB-_-RRB- ._.
Recently_RB ,_, holistic_JJ approaches_NNS combining_VBG such_JJ similarities_NNS have_VBP been_VBN studied_VBN -LRB-_-LRB- Shao_NNP and_CC Ng_NNP ,_, 2004_CD ;_: You_PRP et_FW al._FW ,_, 2010_CD ;_: Kim_NNP et_FW al._FW ,_, 2011_CD -RRB-_-RRB- ._.
Some_DT recent_JJ research_NN used_VBN comparable_JJ corpora_NN to_TO re-score_JJ name_NN transliterations_NNS -LRB-_-LRB- Sproat_NNP et_FW al._FW ,_, 2006_CD ;_: Klementiev_NNP and_CC Roth_NNP ,_, 2006_CD -RRB-_-RRB- or_CC mine_PRP new_JJ word_NN translations_NNS -LRB-_-LRB- Fung_NNP and_CC Yee_NNP ,_, 1998_CD ;_: Rapp_NNP ,_, 1999_CD ;_: Shao_NNP and_CC Ng_NNP ,_, 2004_CD ;_: Tao_NNP and_CC Zhai_NNP ,_, 2005_CD ;_: Hassan_NNP et_FW al._FW ,_, 2007_CD ;_: Udupa_NNP et_FW al._FW ,_, 2009_CD ;_: Ji_NNP ,_, 2009_CD -RRB-_-RRB- ._.
We_PRP lemmatized_VBD German_JJ articles_NNS ,_, adjectives_NNS -LRB-_-LRB- only_RB positive_JJ form_NN -RRB-_-RRB- ,_, for_IN some_DT pronouns_NNS and_CC for_IN nouns_NNS in_IN order_NN to_TO remove_VB the_DT lexical_JJ redundancy_NN -LRB-_-LRB- e.g._FW ,_, Bildes_NNS as_IN Bild_NN -RRB-_-RRB- by_IN using_VBG the_DT fine_NN -_: grained_VBN part-of-speech_NN tags_NNS generated_VBN by_IN RFTagger_NN -LRB-_-LRB- Schmid_NN and_CC Laws_NNS ,_, 2008_CD -RRB-_-RRB- ._.
As_IN for_IN work_NN on_IN Arabic_JJ -LRB-_-LRB- MSA_NN -RRB-_-RRB- ,_, results_NNS have_VBP been_VBN reported_VBN on_IN the_DT PATB_NN -LRB-_-LRB- Kulick_NN ,_, Gabbard_NNP ,_, and_CC Marcus_NNP 2006_CD ;_: Diab_NNP 2007_CD ;_: Green_NNP and_CC Manning_NNP 2010_CD -RRB-_-RRB- We_PRP previously_RB showed_VBD optimal_JJ Berkeley_NNP parser_NN -LRB-_-LRB- Petrov_NNP et_FW al._FW 2006_CD -RRB-_-RRB- pa_SYM -_: rameterizations_NNS for_IN both_CC the_DT Arabic_JJ -LRB-_-LRB- Green_NN and_CC Manning_VBG 2010_CD -RRB-_-RRB- and_CC French_JJ -LRB-_-LRB- Green_NNP et_FW al._FW 2011_CD -RRB-_-RRB- data_NNS sets_NNS Recently_RB ,_, Green_NNP and_CC Manning_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- analyzed_VBD the_DT PATB_NN for_IN annotation_NN consistency_NN We_PRP allow_VBP the_DT parser_NN to_TO produce_VB empty_JJ elements_NNS by_IN means_NNS of_IN lattice-parsing_JJ -LRB-_-LRB- Chappelier_JJ et_FW al._FW ,_, 1999_CD -RRB-_-RRB- ,_, a_DT general_JJ processing_NN community_NN -LRB-_-LRB- Hall_NN ,_, 2005_CD ;_: Chappelier_NNP et_FW al._FW ,_, 1999_CD -RRB-_-RRB- ,_, and_CC was_VBD recently_RB applied_VBN to_TO the_DT task_NN of_IN joint_JJ clitic-segmentation_NN and_CC syntactic-parsing_NN in_IN Hebrew_NNP -LRB-_-LRB- Goldberg_NNP and_CC Tsarfaty_NNP ,_, 2008_CD ;_: Goldberg_NNP and_CC Elhadad_NNP ,_, 2011_CD -RRB-_-RRB- and_CC Arabic_JJ -LRB-_-LRB- Green_NN and_CC Manning_NN ,_, 2010_CD -RRB-_-RRB- ._.
The_DT data_NNS was_VBD pre-processed_JJ with_IN packages_NNS from_IN the_DT Stanford_NNP Arabic_NNP parser_NN -LRB-_-LRB- Green_NN and_CC Manning_NN ,_, 2010_CD -RRB-_-RRB- ._.
2_CD The_DT complete_JJ set_NN of_IN analyses_NNS for_IN this_DT word_NN is_VBZ provided_VBN in_IN Goldberg_NNP and_CC Tsarfaty_NNP -LRB-_-LRB- 2008_CD -RRB-_-RRB- ._.
Examples_NNS for_IN similar_JJ phenomena_NNS in_IN Arabic_NNP may_MD be_VB found_VBN in_IN Green_NNP and_CC Manning_NNP -LRB-_-LRB- 2010_CD -RRB-_-RRB- ._.
This_DT is_VBZ inefficient_JJ with_IN many_JJ copy_NN operations_NNS due_JJ to_TO unfications_NNS of_IN unnecessary_JJ features_NNS that_WDT do_VBP not_RB contribute_VB to_TO successful_JJ unification_NN -LSB-_-LRB- 6_CD -RSB-_-RRB- ._.
Thus_RB treatments_NNS such_JJ as_IN strategic_JJ unification_NN -LSB-_-LRB- 6_CD -RSB-_-RRB- have_VBP been_VBN developed_VBN ._.
As_IN it_PRP has_VBZ been_VBN noticed_VBN by_IN -LSB-_-LRB- Godden_NNP 90_CD -RSB-_-RRB- and_CC -LSB-_-LRB- Kogure_NNP 90_CD -RSB-_-RRB- ,_, the_DT key_JJ idea_NN of_IN avoiding_VBG ``_`` redundant_JJ copying_NN ''_'' is_VBZ to_TO do_VB copying_NN lazily.Copying_NN of_IN nodes_NNS will_MD be_VB delayed_VBN until_IN a_DT destructive_JJ change_NN is_VBZ about_IN to_TO take_VB place.Kogure_NN uses_VBZ a_DT revised_VBN copynode_NN procedure_NN which_WDT maintains_VBZ copy_NN dependency_NN information_NN in_IN order_NN to_TO avoid_VB immediate_JJ copying.Similarly_NN ,_, in_IN Kogure_NNP 's_POS approach_NN ,_, not_RB all_DT redundant_JJ copying_NN is_VBZ avoided_VBN in_IN cases_NNS where_WRB there_EX exists_VBZ a_DT feature_NN path_NN -LRB-_-LRB- a_DT sequence_NN of_IN nodes_NNS connected_VBN by_IN arcs_NNS -RRB-_-RRB- to_TO a_DT node_NN that_WDT needs_VBZ to_TO be_VB copied_VBN ._.
Several_JJ unsupervised_JJ POS_NN induction_NN systems_NNS make_VBP use_NN of_IN morphological_JJ features_NNS -LRB-_-LRB- Blunsom_NN and_CC Cohn_NNP ,_, 2011_CD ;_: Lee_NNP et_FW al._FW ,_, 2010_CD ;_: Berg-Kirkpatrick_NNP et_FW al._FW ,_, 2010_CD ;_: Clark_NNP ,_, 2003_CD ;_: Christodoulopoulos_NNP et_FW al._FW ,_, 2011_CD -RRB-_-RRB- Second_NNP ,_, learning_VBG categories_NNS has_VBZ been_VBN cast_VBN as_IN unsupervised_JJ part-of-speech_JJ tagging_NN task_NN -LRB-_-LRB- recent_JJ work_NN includes_VBZ Ravi_NNP and_CC Knight_NNP -LRB-_-LRB- 2009_CD -RRB-_-RRB- ,_, Lee_NNP et_FW al._FW -LRB-_-LRB- 2010_CD -RRB-_-RRB- ,_, Lamar_NNP et_FW al._FW ._.
Considering_VBG Question_NNP Topic_NNP includingfact-based_JJ QA_NN and_CC text_NN summarization_NN -LRB-_-LRB- Erkan_NNP andRadev_NNP ,_, 2004_CD ;_: Mihalcea_NNP and_CC Tarau_NNP ,_, 2004_CD ;_: Otter-bacher_JJ et_FW al._FW ,_, 2005_CD ;_: Wan_NNP and_CC Yang_NNP ,_, 2008_CD -RRB-_-RRB- ._.
and_CC sentence_NN retrieval_NN for_IN question_NN answering_NN -LRB-_-LRB- Otterbacher_NN et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ._.
These_DT algorithms_NNS are_VBP all_DT based_VBN on_IN the_DT query-sensitive_JJ LexRank_NNP -LRB-_-LRB- OtterBacher_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ._.
A_DT topic-sensitiveLexRank_NN is_VBZ proposed_VBN in_IN -LRB-_-LRB- Otterbacher_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ._.
As_IN in_IN LexRank_NNP ,_, the_DT set_NN of_IN sentences_NNS in_IN a_DT documentcluster_NN is_VBZ represented_VBN as_IN a_DT graph_NN ,_, where_WRB nodes_NNS aresentences_NNS and_CC links_NNS between_IN the_DT nodes_NNS are_VBP inducedby_JJ a_DT similarity_NN relation_NN between_IN the_DT sentences.Thenthe_NN system_NN ranked_VBD the_DT sentences_NNS according_VBG to_TO a_DT random_JJ walk_NN model_NN defined_VBN in_IN terms_NNS of_IN both_CC the_DT inter-sentence_NN similarities_NNS and_CC the_DT similarities_NNS of_IN the_DT sentences_NNS to_TO the_DT topic_NN description_NN or_CC question_NN ._.
A_DT topic_NN -_: sensitive_JJ LexRank_NNP is_VBZ proposed_VBN in_IN -LRB-_-LRB- Otterbacher_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ._.
To_TO apply_VB LexRank_NNP to_TO query-focused_JJ context_NN ,_, a_DT topic-sensitive_JJ version_NN of_IN LexRank_NNP is_VBZ proposed_VBN in_IN -LRB-_-LRB- Otterbacher_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ._.
Afterwards_RB ,_, our_PRP$ approach_NN is_VBZ evaluated_VBN against_IN two_CD existing_VBG approaches_NNS ,_, which_WDT rely_VBP on_IN the_DT conventional_JJ semantic_JJ network_NN and_CC are_VBP able_JJ to_TO capture_VB binary_JJ relations_NNS only.The_NN other_JJ one_CD is_VBZ based_VBN on_IN topic-sensitive_JJ LexRank_NNP -LRB-_-LRB- Otterbacher_NNP et_FW al._FW ,_, 2005_CD -RRB-_-RRB- ,_, called_VBN title-sensitive_JJ PageRank_NN here_RB ._.
We_PRP report_VBP in_IN Section_NN 2_CD on_IN our_PRP$ experiments_NNS on_IN the_DT assignment_NN of_IN part_NN of_IN speech_NN to_TO words_NNS in_IN text.The_NN effectiveness_NN of_IN such_JJ models_NNS is_VBZ well_RB known_VBN -LRB-_-LRB- DeRose_NNP 1988_CD ;_: Church_NNP 1988_CD ;_: Kupiec_JJ 1989_CD ;_: Jelinek_NNP 1985_CD -RRB-_-RRB- Similarly_RB ,_, -LRB-_-LRB- Sekine_NNP ,_, 2005_CD -RRB-_-RRB- improved_VBN information_NN retrieval_NN based_VBN on_IN pattern_NN recognition_NN by_IN introducing_VBG paraphrase_NN generation_NN ._.
To_TO date_NN ,_, the_DT majority_NN of_IN work_NN on_IN dialogue_NN act_VBP modeling_NN has_VBZ addressed_VBN spoken_VBN dialogue_NN -LRB-_-LRB- Samuel_NNP et_FW al._FW ,_, 1998_CD ;_: Stolcke_NNP et_FW al._FW ,_, 2000_CD ;_: Surendran_NNP and_CC Levow_NNP ,_, 2006_CD ;_: Bangalore_NNP et_FW al._FW ,_, 2008_CD ;_: Sridhar_NNP et_FW al._FW ,_, 2009_CD ;_: Di_NNP Eugenio_NNP et_FW al._FW ,_, 2010_CD -RRB-_-RRB- ._.
There_EX have_VBP also_RB been_VBN Dialogue_NNP Acts_VBZ modeling_NN approaches_NNS for_IN automatic_JJ tagging_NN and_CC recognition_NN of_IN conversational_JJ speech_NN -LRB-_-LRB- Stolcke_NNP et_FW al._FW ,_, 2000_CD -RRB-_-RRB- and_CC related_JJ work_NN in_IN corpus_NN linguistics_NNS where_WRB machine_NN learning_NN techniques_NNS have_VBP been_VBN used_VBN to_TO find_VB conversational_JJ patterns_NNS in_IN spoken_VBN transcripts_NNS of_IN dialogue_NN corpus_NN -LRB-_-LRB- Shawar_NN and_CC Atwell_NNP ,_, 2005_CD -RRB-_-RRB- ._.
dialogue_NN acts_VBZ such_JJ as_IN statements_NNS ,_, questions_NNS ,_, backchannels_NNS ,_, ..._: are_VBP detected_VBN using_VBG a_DT language_NN model_NN based_VBN detector_NN trained_VBN on_IN Switchboard_NN similar_JJ to_TO Stolcke_NNP et_FW al._FW -LRB-_-LRB- 2000_CD The_DT HMM_NN has_VBZ been_VBN widely_RB used_VBN in_IN many_JJ tagging_VBG problems.Stolcke_NN et_FW al._FW -LRB-_-LRB- Stolcke_NNP et_FW al._FW ,_, 2000_CD -RRB-_-RRB- used_VBD it_PRP for_IN dialog_NN act_VBP classification_NN ,_, where_WRB each_DT utterance_NN -LRB-_-LRB- or_CC dialog_NN act_NN -RRB-_-RRB- is_VBZ used_VBN as_IN the_DT observation_NN ._.
Chinese_JJ word_NN segmentation_NN is_VBZ the_DT initial_JJ stage_NN of_IN many_JJ Chinese_JJ language_NN processing_NN tasks_NNS ,_, and_CC has_VBZ received_VBN a_DT lot_NN of_IN attention_NN in_IN the_DT literature_NN -LRB-_-LRB- Sproat_NNP et_FW al._FW ,_, 1996_CD ;_: Sun_NNP and_CC Tsou_NNP ,_, 2001_CD ;_: Zhang_NNP et_FW al._FW ,_, 2003_CD ;_: Peng_NNP et_FW al._FW ,_, 2004_CD -RRB-_-RRB- ._.
Chi_NNP and_CC Geman_NNP -LRB-_-LRB- 1998_CD -RRB-_-RRB- proved_VBD that_IN any_DT PCFG_NN estimated_VBN from_IN a_DT treebank_NN with_IN the_DT relative_JJ frequency_NN estimator_NN is_VBZ tight_JJ ._.
When_WRB a_DT PCFG_NN probability_NN distribution_NN is_VBZ estimated_VBN from_IN training_NN data_NNS -LRB-_-LRB- in_IN our_PRP$ case_NN the_DT Penn_NNP tree-bank_NN -RRB-_-RRB- PCFGs_NNS de.ne_VBP a_DT tight_JJ -LRB-_-LRB- summing_VBG to_TO one_CD -RRB-_-RRB- probability_NN distribution_NN over_IN strings_NNS -LSB-_-LRB- 5_CD -RSB-_-RRB- ,_, thus_RB making_VBG them_PRP appropriate_JJ for_IN language_NN models_NNS ._.
Chi_NNP and_CC Geman_NNP -LRB-_-LRB- 1998_CD -RRB-_-RRB- studied_VBD the_DT question_NN for_IN Maximum_NNP Likelihood_NNP -LRB-_-LRB- ML_NNP -RRB-_-RRB- estimation_NN ,_, and_CC showed_VBD that_IN ML_NN es_VBZ 1033_CD timates_NNS are_VBP always_RB tight_JJ for_IN both_CC the_DT supervisedcase_NN -LRB-_-LRB- where_WRB the_DT input_NN consists_VBZ of_IN parse_NN trees_NNS -RRB-_-RRB- andthe_NN unsupervised_JJ case_NN -LRB-_-LRB- where_WRB the_DT input_NN consists_VBZ ofyields_NNS or_CC terminal_JJ strings_NNS -RRB-_-RRB- ._.
Measuring_VBG the_DT contextual_JJ fitness_NN of_IN a_DT term_NN in_IN its_PRP$ context_NN is_VBZ a_DT key_JJ component_NN in_IN different_JJ NLP_NN applications_NNS like_IN speech_NN recognition_NN -LRB-_-LRB- Inkpen_NN and_CC DeÂ_NN '_'' silets_NNS ,_, 2005_CD -RRB-_-RRB- ,_, optical_JJ character_NN recognition_NN -LRB-_-LRB- Wick_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ,_, co-reference_NN resolution_NN -LRB-_-LRB- Bean_NNP and_CC Riloff_NNP ,_, 2004_CD -RRB-_-RRB- Bean_NNP and_CC Riloff_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- present_VBP a_DT system_NN called_VBN BABAR_NNP that_WDT uses_VBZ contextual_JJ role_NN knowledge_NN to_TO do_VB coreference_NN resolution.They_NN apply_VB an_DT IE_JJ component_NN to_TO unannotated_JJ texts_NNS to_TO generate_VB a_DT set_NN of_IN extraction_NN caseframes.Each_NN caseframe_NN represents_VBZ a_DT linguistic_JJ expression_NN and_CC a_DT syntactic_JJ position_NN ,_, e.g._FW â_FW $_$ œmurder_CD of_IN <NP>_NN â_NN $_$ ,_, â_VB $_$ œkilled_JJ <patient>_NN â_NN $_$ ._.
From_IN the_DT case_NN -_: frames_NNS ,_, they_PRP derive_VBP different_JJ types_NNS of_IN contextual_JJ role_NN knowledge_NN for_IN resolution_NN ,_, for_IN example_NN ,_, whether_IN an_DT anaphor_NN and_CC an_DT antecedent_JJ candidate_NN can_MD be_VB filled_VBN into_IN co-occurring_VBG caseframes_NNS ,_, or_CC whether_IN they_PRP are_VBP substitutable_JJ for_IN each_DT other_JJ in_IN their_PRP$ caseframes_NNS ._.
Finally_RB ,_, several_JJ coreference_NN systems_NNS have_VBP successfully_RB incorporated_VBN anaphoricity_NN determination_NN modules_NNS -LRB-_-LRB- e.g._FW Ng_NN and_CC Cardie_NN -LRB-_-LRB- 2002a_NN -RRB-_-RRB- and_CC Bean_NNP and_CC Riloff_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- -RRB-_-RRB- ._.
It_PRP has_VBZ shown_VBN promise_NN in_IN improving_VBG the_DT performance_NN of_IN many_JJ tasks_NNS such_JJ as_IN name_NN tagging_NN -LRB-_-LRB- Miller_NNP et_FW al._FW ,_, 2004_CD -RRB-_-RRB- ,_, semantic_JJ class_NN extraction_NN -LRB-_-LRB- Lin_NNP et_FW al._FW ,_, 2003_CD -RRB-_-RRB- ,_, chunking_VBG -LRB-_-LRB- Ando_NNP and_CC Zhang_NNP ,_, 2005_CD -RRB-_-RRB- ,_, coreference_NN resolution_NN -LRB-_-LRB- Bean_NNP and_CC Riloff_NNP ,_, 2004_CD -RRB-_-RRB- Bean_NNP and_CC Riloff_NNP -LRB-_-LRB- 2004_CD -RRB-_-RRB- present_VBP a_DT system_NN ,_, which_WDT uses_VBZ contextual_JJ role_NN knowledge_NN to_TO aid_VB coreference_NN resolution.They_NN used_VBD lexical_JJ and_CC syntactic_JJ heuristics_NNS to_TO identify_VB high-confidence_JJ coreference_NN relations_NNS and_CC used_VBD them_PRP as_IN training_NN data_NNS for_IN learning_VBG contextual_JJ role_NN knowledge.They_NN got_VBD substantial_JJ gains_NNS on_IN articles_NNS in_IN two_CD specific_JJ domains_NNS ,_, terrorism_NN and_CC natural_JJ disasters_NNS ._.
Inspired_VBN by_IN work_NN of_IN Pang_NN -LSB-_-LRB- 4_CD -RSB-_-RRB- and_CC Su_FW -LSB-_-LRB- 5_CD -RSB-_-RRB- ,_, we_PRP also_RB use_VBP Minimum_NNP cut_NN -LRB-_-LRB- Mincut_NN -RRB-_-RRB- model_NN to_TO optimize_VB the_DT Two-stage_JJ SVM_NNP result_NN ._.
This_DT follows_VBZ on_RP from_IN the_DT success_NN of_IN these_DT methods_NNS in_IN general_JJ NLP_NN -LRB-_-LRB- see_VB for_IN example_NN Zhou_NNP et_FW al_FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- -RRB-_-RRB- ._.
In_IN building_VBG these_DT systems_NNS ,_, researchers_NNS used_VBD a_DT wide_JJ variety_NN of_IN features_NNS -LRB-_-LRB- Kambhatla_NNP ,_, 2004_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD ;_: Jiang_NNP and_CC Zhai_NNP ,_, 2007_CD -RRB-_-RRB- ._.
The_DT former_JJ is_VBZ Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- ,_, which_WDT uses_VBZ 51_CD different_JJ features_NNS ._.
Relation_NN Extraction_NN is_VBZ a_DT well-studied_JJ problem_NN -LRB-_-LRB- Miller_NNP et_FW al._FW ,_, 2000_CD ;_: Zhou_NNP et_FW al._FW ,_, 2005_CD ;_: Kambhatla_NNP ,_, 2004_CD ;_: Min_NNP et_FW al._FW ,_, 2012a_NN -RRB-_-RRB- ._.
In_IN addition_NN ,_, we_PRP cherry-picked_VBD the_DT following_VBG features_NNS which_WDT were_VBD not_RB included_VBN in_IN Zhou_NNP et_FW al._FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- but_CC were_VBD shown_VBN to_TO be_VB quite_RB effective_JJ for_IN relation_NN extraction_NN ._.
This_DT follows_VBZ on_RP from_IN the_DT success_NN of_IN these_DT methods_NNS in_IN general_JJ NLP_NN -LRB-_-LRB- see_VB for_IN example_NN Zhou_NNP et_FW al_FW -LRB-_-LRB- 2005_CD -RRB-_-RRB- -RRB-_-RRB- ._.
Sentences_NNS should_MD be_VB translated_VBN in_IN consistence_NN with_IN their_PRP$ topics_NNS -LRB-_-LRB- Zhao_NNP and_CC Xing_NNP ,_, 2006_CD ;_: Zhao_NNP and_CC Xing_NNP ,_, 2007_CD ;_: Tam_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ._.
Topic_NN modeling_NN has_VBZ received_VBN some_DT use_NN in_IN SMT_NNP ,_, for_IN instance_NN Bilingual_JJ LSA_NN adaptation_NN -LRB-_-LRB- Tam_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- ,_, and_CC the_DT BiTAM_NN model_NN -LRB-_-LRB- Zhao_NNP and_CC Xing_NNP ,_, 2006_CD -RRB-_-RRB- ,_, which_WDT uses_VBZ a_DT bilingual_JJ topic_NN model_NN for_IN learning_VBG alignment_NN ._.
To_TO avoid_VB the_DT need_NN for_IN hard_JJ decisions_NNS about_IN domain_NN membership_NN ,_, some_DT have_VBP used_VBN topic_NN modeling_NN to_TO improve_VB SMT_NNP performance_NN ,_, e.g._FW ,_, using_VBG latent_JJ semantic_JJ analysis_NN -LRB-_-LRB- Tam_NNP et_FW al._FW ,_, 2007_CD -RRB-_-RRB- or_CC â_VB $_$ ˜biTAMâ_JJ $_$ ™_CD -LRB-_-LRB- Zhao_NNP and_CC Xing_NNP ,_, 2006_CD -RRB-_-RRB- ._.
Levin_NNP 's_POS study_NN on_IN diathesis_NN alternations_NNS has_VBZ influenced_VBN recent_JJ work_NN on_IN word_NN sense_NN disamÂ_NN biguation_NN -LRB-_-LRB- Dorr_NN and_CC Jones_NNP ,_, 1996_CD -RRB-_-RRB- ,_, machine_NN translaÂ_NN tion_NN -LRB-_-LRB- Dang_NNP et_FW al._FW ,_, 1998_CD -RRB-_-RRB- ,_, and_CC automatic_JJ lexical_JJ acÂ_NN quisition_NN -LRB-_-LRB- McCarthy_NNP and_CC Korhonen_NNP ,_, 1998_CD ;_: Schulte_NNP im_NNP Walde_NNP ,_, 1998_CD -RRB-_-RRB- ._.
Halteren_NNP et_FW al_FW -LRB-_-LRB- 1998_CD -RRB-_-RRB- compare_VBP a_DT number_NN of_IN voting_VBG methods_NNS including_VBG a_DT Majority_NNP Vote_NN scheme_NN with_IN other_JJ combination_NN methods_NNS for_IN part_NN of_IN speech_NN tagging_NN ._.
Most_JJS work_NN on_IN anaphora_NN resolution_NN has_VBZ focused_VBN on_IN pronominal_JJ anaphora_NN ,_, often_RB achieving_VBG good_JJ accuracy.Kennedy_NN and_CC Boguraev_NN -LRB-_-LRB- 1996_CD -RRB-_-RRB- ,_, Mitkov_NNP -LRB-_-LRB- 1998_CD -RRB-_-RRB- ,_, and_CC Strube_NNP ,_, Rapp_NNP ,_, and_CC Mueller_NNP -LRB-_-LRB- 2002_CD -RRB-_-RRB- ,_, for_IN example_NN ,_, report_NN accuracies_NNS of_IN 75.0_CD %_NN ,_, 89.7_CD %_NN ,_, and_CC an_DT F-measure_NN of_IN 82.8_CD %_NN for_IN personal_JJ pronouns_NNS ,_, respectively_RB ._.
As_IN an_DT alternative_NN to_TO the_DT resource-intensive_JJ manual_JJ classifications_NNS ,_, automatic_JJ methods_NNS such_JJ as_IN classification_NN and_CC clustering_NN are_VBP applied_VBN to_TO induce_VB verb_VB classes_NNS from_IN corpus_NN data_NNS ,_, e.g._FW -LRB-_-LRB- Merlo_NNP and_CC Stevenson_NNP ,_, 2001_CD ;_: Joanis_NNP and_CC Stevenson_NNP ,_, 2003_CD ;_: Korhonen_NNP et_FW al._FW ,_, 2003_CD ;_: Stevenson_NNP and_CC Joanis_NNP ,_, 2003_CD ;_: Schulte_NNP im_NNP Walde_NNP ,_, 2003_CD ;_: Fer_SYM -_: rer_NN ,_, 2004_CD -RRB-_-RRB- ._.
Golding_NNP -LRB-_-LRB- 1995_CD -RRB-_-RRB- showed_VBD how_WRB methods_NNS used_VBN for_IN WSD_NN -LRB-_-LRB- decision_NN lists_NNS and_CC Bayesian_JJ classifiers_NNS -RRB-_-RRB- could_MD be_VB adapted_VBN to_TO detect_VB errors_NNS resulting_VBG from_IN common_JJ spelling_NN confusions_NNS among_IN sets_NNS such_JJ as_IN there_RB ,_, their_PRP$ ,_, and_CC they_PRP 're_VBP ._.
Take_VB the_DT case_NN of_IN context-sensitive_JJ spelling_NN error_NN detection_NN 3_CD ,_, which_WDT is_VBZ equivalent_JJ to_TO the_DT homophone_NN problem.For_NN that_WDT problem_NN ,_, some_DT statistical_JJ methods_NNS have_VBP been_VBN applied_VBN and_CC succeeded_VBN -LRB-_-LRB- Golding_NNP ,_, 1995_CD ;_: GoldÂ_NNP ing_NN and_CC Schabes_NNS ,_, 1996_CD -RRB-_-RRB- ._.
Most_JJS methods_NNS are_VBP trained_VBN and_CC tested_VBN on_IN Model_NNP Alta_NNP BNC_NNP Model_NNP Alta_NNP BNC_NNP f_FW -LRB-_-LRB- t_NN -RRB-_-RRB- 72.98_CD 70.00_CD f_FW -LRB-_-LRB- w1_NN ,_, t_NN ,_, w2_NN -RRB-_-RRB- /_: f_LS -LRB-_-LRB- t_NN -RRB-_-RRB- 87.77_CD 76.33_CD f_FW -LRB-_-LRB- w1_NN ,_, t_NN -RRB-_-RRB- 84.40_CD 83.02_CD f_FW -LRB-_-LRB- w1_NN ,_, w2_NN ,_, t_NN -RRB-_-RRB- /_: f_LS -LRB-_-LRB- t_NN -RRB-_-RRB- 86.27_CD 74.47_CD f_FW -LRB-_-LRB- t_NN ,_, w1_NN -RRB-_-RRB- 84.89_CD 82.74_CD f_FW -LRB-_-LRB- t_NN ,_, w2_NN ,_, w2_NN -RRB-_-RRB- /_: f_LS -LRB-_-LRB- t_NN -RRB-_-RRB- 84.94_CD 74.23_CD f_FW -LRB-_-LRB- w1_NN ,_, t_NN ,_, w2_NN -RRB-_-RRB- 89.24_CD #_# *_SYM 77.13_CD f_FW -LRB-_-LRB- w1_NN ,_, t_NN ,_, w2_NN -RRB-_-RRB- /_: f_LS -LRB-_-LRB- w1_NN ,_, t_NN -RRB-_-RRB- 80.70_CD 73.69_CD f_FW -LRB-_-LRB- t_NN ,_, w1_NN ,_, w2_NN -RRB-_-RRB- 84.68_CD 75.08_CD f_FW -LRB-_-LRB- w1_NN ,_, w2_NN ,_, t_NN -RRB-_-RRB- /_: f_LS -LRB-_-LRB- w2_NN ,_, t_NN -RRB-_-RRB- 72.11_CD 69.28_CD f_FW -LRB-_-LRB- w1_NN ,_, t_NN -RRB-_-RRB- /_: f_LS -LRB-_-LRB- t_NN -RRB-_-RRB- 82.81_CD 77.84_CD f_FW -LRB-_-LRB- t_NN ,_, w1_NN ,_, w2_NN -RRB-_-RRB- /_: f_LS -LRB-_-LRB- t_NN ,_, w1_NN -RRB-_-RRB- 75.65_CD 72.57_CD f_FW -LRB-_-LRB- t_NN ,_, w1_NN -RRB-_-RRB- /_: f_LS -LRB-_-LRB- t_NN -RRB-_-RRB- 77.49_CD 80.71_CD #_# Table_NNP 5_CD For_IN English_NNP ,_, a_DT number_NN of_IN methods_NNS have_VBP been_VBN proposed_VBN to_TO cope_VB with_IN real-word_JJ errors_NNS in_IN spelling_NN correction_NN -LRB-_-LRB- Golding_NN ,_, 1995_CD ;_: Golding_NNP and_CC Roth_NNP ,_, 1996_CD ;_: Golding_NNP and_CC Schabes_NNP ,_, 1993_CD ;_: Tong_NNP and_CC Evans_NNP ,_, 1996_CD -RRB-_-RRB- ._.
This_DT general_JJ scheme_NN has_VBZ been_VBN used_VBN to_TO deÂ_VB rive_JJ classifiers_NNS for_IN a_DT variety_NN of_IN natural_JJ lanÂ_NN guage_NN applications_NNS including_VBG speech_NN applicaÂ_NN tions_NNS -LRB-_-LRB- Rab89_NN -RRB-_-RRB- ,_, pos_NN tagging_NN -LRB-_-LRB- Kup92_NN ;_: Sch95_NN -RRB-_-RRB- ,_, word-sense_JJ ambiguation_NN -LRB-_-LRB- GCY93_NN -RRB-_-RRB- and_CC contextÂ_NN sensitive_JJ spelling_NN correction_NN -LRB-_-LRB- Gol95_NN -RRB-_-RRB- ._.
Previous_JJ work_NN has_VBZ addressed_VBN the_DT problem_NN of_IN CSSC_NNP from_IN a_DT machine_NN learning_VBG perspective_NN ,_, including_VBG Bayesian_JJ and_CC Decision_NN List_NN models_NNS -LRB-_-LRB- Golding_NNP ,_, 1995_CD -RRB-_-RRB- For_IN CSSC_NNP ,_, we_PRP tested_VBD our_PRP$ system_NN on_IN the_DT identical_JJ data_NNS from_IN the_DT Brown_JJ corpus_NN used_VBN by_IN Golding_NNP -LRB-_-LRB- 1995_CD -RRB-_-RRB- A_DT different_JJ body_NN of_IN work_NN -LRB-_-LRB- e.g._FW Golding_FW ,_, 1995_CD ;_: Golding_NNP and_CC Roth_NNP ,_, 1996_CD ;_: Mangu_NNP and_CC Brill_NNP ,_, 1997_CD -RRB-_-RRB- focused_VBD on_IN resolving_VBG a_DT limited_JJ number_NN of_IN cognitive_JJ substitution_NN errors_NNS ,_, in_IN the_DT framework_NN of_IN context_NN sensitive_JJ spelling_NN correction_NN -LRB-_-LRB- CSSC_NN -RRB-_-RRB- ._.
More_RBR generally_RB ,_, as_IN a_DT precursor_NN to_TO the_DT above_JJ -_: mentioned_VBN work_NN ,_, confusable_JJ disambiguation_NN has_VBZ been_VBN investigated_VBN in_IN a_DT string_NN of_IN papers_NNS discussing_VBG the_DT application_NN of_IN various_JJ machine_NN learning_VBG algorithms_NNS to_TO the_DT task_NN -LRB-_-LRB- Yarowsky_NNP ,_, 1994_CD ;_: Golding_NNP ,_, 1995_CD ;_: There_EX are_VBP also_RB other_JJ studies_NNS -LRB-_-LRB- Yarowsky_NNP ,_, 1994_CD ;_: Golding_NNP ,_, 1995_CD or_CC Golding_NNP and_CC Roth_NNP ,_, 1996_CD -RRB-_-RRB- that_WDT report_VBP the_DT application_NN of_IN decision_NN lists_NNS and_CC Bayesian_JJ classifiers_NNS for_IN spell_NN checking_NN ;_: however_RB ,_, these_DT models_NNS can_MD not_RB be_VB applied_VBN to_TO grammar_NN error_NN detection_NN ._.
Golding_VBG -LSB-_-LRB- 1995_CD -RSB-_-RRB- has_VBZ applied_VBN a_DT hybrid_NN Bayesian_JJ method_NN for_IN real-word_JJ error_NN correction_NN and_CC Golding_NNP and_CC Schabes_NNP -LSB-_-LRB- 1996_CD -RSB-_-RRB- have_VBP combined_VBN a_DT POS_NN trigram_NN and_CC Bayesian_JJ methods_NNS for_IN the_DT same_JJ purpose_NN ._.
Our_PRP$ module_NN used_VBN for_IN spelling_NN correction_NN was_VBD developed_VBN on_IN the_DT basis_NN of_IN works_NNS by_IN Brill_NNP -LSB-_-LRB- 1_CD -RSB-_-RRB- ,_, Brill_NNP and_CC Marcus_NNP -LSB-_-LRB- 2_LS -RRB-_-RRB- ,_, Golding_NN -LSB-_-LRB- 3_CD -RRB-_-RRB- ,_, Golding_NNP and_CC Schabes_NNP -LSB-_-LRB- 4_CD -RSB-_-RRB- ,_, and_CC Powers_NNP -LSB-_-LRB- 5_LS -RRB-_-RRB- ._.
